{
    "python_service/__init__.py": "# This file makes the python_service directory a Python package.",
    "python_service/adapters/__init__.py": "# python_service/adapters/__init__.py\n\nfrom .tvg_adapter import TVGAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .gbgb_api_adapter import GbgbApiAdapter\n\n# Define the public API for the adapters package, making it easy for the\n# orchestrator to discover and use them.\n__all__ = [\n    \"GbgbApiAdapter\",\n    \"TVGAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"AtTheRacesAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"SportingLifeAdapter\",\n    \"TimeformAdapter\",\n    \"HarnessAdapter\",\n    \"GreyhoundAdapter\",\n    \"TheRacingApiAdapter\",\n]",
    "python_service/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\nimport asyncio, structlog, httpx\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nfrom bs4 import BeautifulSoup, Tag\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return ' '.join(text.strip().split()) if text else None\n\nclass AtTheRacesAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"AtTheRaces\", base_url=\"https://www.attheraces.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response_html = await self.make_request(http_client, 'GET', '/racecards')\n        if not response_html: return []\n        soup = BeautifulSoup(response_html, \"html.parser\")\n        links = {a['href'] for a in soup.select(\"a.race-time-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response_html = await self.make_request(http_client, 'GET', url)\n            if not response_html: return None\n            soup = BeautifulSoup(response_html, \"html.parser\")\n            header = soup.select_one(\"h1.heading-racecard-title\").get_text()\n            track_name, race_time = [p.strip() for p in header.split(\"|\")[:2]]\n            active_link = soup.select_one(\"a.race-time-link.active\")\n            race_number = active_link.find_parent(\"div\", \"races\").select(\"a.race-time-link\").index(active_link) + 1\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time}\", \"%Y-%m-%d %H:%M\")\n            runners = [self._parse_runner(row) for row in soup.select(\"div.card-horse\")]\n            return Race(id=f\"atr_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\", venue=track_name, race_number=race_number, start_time=start_time, runners=[r for r in runners if r], source=self.source_name)\n        except Exception: return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"h3.horse-name a\").get_text())\n            num_str = _clean_text(row.select_one(\"span.horse-number\").get_text())\n            number = int(''.join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"button.best-odds\").get_text())\n            win_odds = Decimal(str(parse_odds(odds_str))) if odds_str else None\n            odds_data = {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())} if win_odds and win_odds < 999 else {}\n            return Runner(number=number, name=name, odds=odds_data)\n        except: return None\n",
    "python_service/adapters/base.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Base Adapter (v2 - Hardened with Tenacity)\n# ==============================================================================\n\nimport httpx\nimport structlog\nfrom datetime import datetime\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nfrom tenacity import retry, stop_after_attempt, wait_exponential, RetryError, AsyncRetrying\n\nlog = structlog.get_logger(__name__)\n\nclass BaseAdapter(ABC):\n    \"\"\"The resilient base class for all data source adapters.\"\"\"\n\n    def __init__(self, source_name: str, base_url: str, timeout: int = 20, max_retries: int = 3):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.timeout = timeout\n        self.max_retries = max_retries\n\n    @abstractmethod\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        raise NotImplementedError\n\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> Optional[Any]:\n        \"\"\"Makes a resilient HTTP request with automatic retries using Tenacity.\"\"\"\n        retryer = AsyncRetrying(\n            stop=stop_after_attempt(self.max_retries),\n            wait=wait_exponential(multiplier=1, min=2, max=10),\n            reraise=True\n        )\n        try:\n            async for attempt in retryer:\n                with attempt:\n                    try:\n                        full_url = url if url.startswith('http') else f\"{self.base_url}{url}\"\n                        log.info(f\"Requesting...\", adapter=self.source_name, method=method, url=full_url, attempt=attempt.retry_state.attempt_number)\n                        response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n                        response.raise_for_status()\n                        return response.json()\n                    except (httpx.RequestError, httpx.HTTPStatusError) as e:\n                        log.warning(\"Request failed, tenacity will retry...\", adapter=self.source_name, error=str(e))\n                        raise # Reraise to trigger tenacity's retry mechanism\n        except RetryError as e:\n            log.error(f\"Max retries exceeded for {self.source_name}. Aborting request.\", final_error=str(e))\n            return None # Return None on total failure\n\n    def get_status(self) -> Dict[str, Any]:\n        return {\"adapter_name\": self.source_name, \"status\": \"OK\"}\n\n    def _format_response(self, races: List, start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\n\nimport httpx\nimport structlog\nimport re\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom .betfair_auth_mixin import BetfairAuthMixin\nfrom ..models import Race, Runner\n\nlog = structlog.get_logger(__name__)\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"BetfairExchange\", base_url=\"https://api.betfair.com/exchange/betting/rest/v1.0/\")\n        self.config = config\n        self.app_key = self.config.BETFAIR_APP_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            await self._authenticate(http_client)\n            headers = {\"X-Application\": self.app_key, \"X-Authentication\": self.session_token, \"Content-Type\": \"application/json\"}\n            market_filter = {\"eventTypeIds\": [\"7\"], \"marketTypeCodes\": [\"WIN\"], \"marketStartTime\": {\"from\": f\"{date}T00:00:00Z\", \"to\": f\"{date}T23:59:59Z\"}}\n            market_catalogue = await self.make_request(http_client, 'POST', 'listMarketCatalogue/', headers=headers, json={\"filter\": market_filter, \"maxResults\": 1000, \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"]})\n            if not market_catalogue:\n                return self._format_response([], start_time, is_success=True, error_message=\"No markets found.\")\n            all_races = [self._parse_race(market) for market in market_catalogue]\n            return self._format_response(all_races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    def _parse_race(self, market: Dict[str, Any]) -> Race:\n        runners = [Runner(number=rd.get('sortPriority', 99), name=rd['runnerName'], selection_id=rd['selectionId']) for rd in market.get('runners', [])]\n        return Race(id=f\"bf_{market['marketId']}\", venue=market['event']['venue'], race_number=self._extract_race_number(market.get('marketName')), start_time=datetime.fromisoformat(market['marketStartTime'].replace('Z', '+00:00')), runners=runners, source=self.source_name)\n\n    def _extract_race_number(self, name: Optional[str]) -> int:\n        if not name: return 1\n        match = re.search(r'\\\\bR(\\\\d{1,2})\\\\b', name)\n        return int(match.group(1)) if match else 1\n\n    async def get_live_odds_for_market(self, market_id: str, http_client: httpx.AsyncClient) -> Dict[int, Decimal]:\n        \"\"\"TACTICAL method (Pillar 3). Gets live LTP for each runner in a market.\"\"\"\n        log.info(\"BetfairAdapter: Fetching live odds for market\", market_id=market_id)\n        try:\n            await self._authenticate(http_client)\n            headers = {\"X-Application\": self.app_key, \"X-Authentication\": self.session_token, \"Content-Type\": \"application/json\"}\n\n            params = {\"marketIds\": [market_id], \"priceProjection\": {\"priceData\": [\"EX_TRADED\"]}}\n            market_book = await self.make_request(\n                http_client,\n                'POST',\n                'listMarketBook/',\n                headers=headers,\n                json=params\n            )\n\n            live_odds = {}\n            if market_book and market_book[0].get('runners'):\n                for runner in market_book[0]['runners']:\n                    if runner.get('status') == 'ACTIVE' and runner.get('lastPriceTraded'):\n                        live_odds[runner['selectionId']] = Decimal(str(runner['lastPriceTraded']))\n            return live_odds\n        except httpx.HTTPError as e:\n            log.error(\"BetfairAdapter: Failed to get live odds\", market_id=market_id, error=str(e), exc_info=True)\n            return {} # Return empty dict on failure\n        except Exception as e:\n            log.error(\"BetfairAdapter: Unexpected error getting live odds\", market_id=market_id, error=str(e), exc_info=True)\n            return {} # Return empty dict on failure",
    "python_service/adapters/betfair_auth_mixin.py": "# python_service/adapters/betfair_auth_mixin.py\n\nimport httpx\nimport structlog\nfrom datetime import datetime, timedelta\nfrom typing import Optional\n\nlog = structlog.get_logger(__name__)\n\nclass BetfairAuthMixin:\n    \"\"\"Encapsulates Betfair authentication logic for reuse across adapters.\"\"\"\n    session_token: Optional[str] = None\n    token_expiry: Optional[datetime] = None\n\n    async def _authenticate(self, http_client: httpx.AsyncClient):\n        if self.session_token and self.token_expiry and self.token_expiry > (datetime.now() + timedelta(minutes=5)):\n            return\n        if not all([self.app_key, self.config.BETFAIR_USERNAME, self.config.BETFAIR_PASSWORD]):\n            raise ValueError(\"Betfair credentials not fully configured.\")\n\n        auth_url = \"https://identitysso.betfair.com/api/login\"\n        headers = {'X-Application': self.app_key, 'Content-Type': 'application/x-www-form-urlencoded'}\n        payload = f'username={self.config.BETFAIR_USERNAME}&password={self.config.BETFAIR_PASSWORD}'\n\n        log.info(f\"{self.__class__.__name__}: Authenticating...\")\n        response = await http_client.post(auth_url, headers=headers, content=payload, timeout=20)\n        response.raise_for_status()\n        data = response.json()\n        if data.get('status') == 'SUCCESS':\n            self.session_token = data.get('token')\n            self.token_expiry = datetime.now() + timedelta(hours=3)\n        else:\n            raise ConnectionError(f\"Betfair authentication failed: {data.get('error')}\")",
    "python_service/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\n\nimport httpx\nimport structlog\nimport re\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\n\nfrom .base import BaseAdapter\nfrom .betfair_auth_mixin import BetfairAuthMixin\nfrom ..models import Race, Runner\n\nlog = structlog.get_logger(__name__)\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"BetfairGreyhound\", base_url=\"https://api.betfair.com/exchange/betting/rest/v1.0/\")\n        self.config = config\n        self.app_key = self.config.BETFAIR_APP_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            await self._authenticate(http_client)\n            headers = {\"X-Application\": self.app_key, \"X-Authentication\": self.session_token, \"Content-Type\": \"application/json\"}\n            market_filter = {\"eventTypeIds\": [\"4339\"], \"marketTypeCodes\": [\"WIN\"], \"marketStartTime\": {\"from\": f\"{date}T00:00:00Z\", \"to\": f\"{date}T23:59:59Z\"}}\n            market_catalogue = await self.make_request(http_client, 'POST', 'listMarketCatalogue/', headers=headers, json={\"filter\": market_filter, \"maxResults\": 1000, \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"]})\n            if not market_catalogue:\n                return self._format_response([], start_time, is_success=True, error_message=\"No markets found.\")\n            all_races = [self._parse_race(market) for market in market_catalogue]\n            return self._format_response(all_races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    def _parse_race(self, market: Dict[str, Any]) -> Race:\n        runners = [Runner(number=rd.get('sortPriority', 99), name=rd['runnerName'], selection_id=rd['selectionId']) for rd in market.get('runners', [])]\n        return Race(id=f\"bfg_{market['marketId']}\", venue=market['event']['venue'], race_number=self._extract_race_number(market.get('marketName')), start_time=datetime.fromisoformat(market['marketStartTime'].replace('Z', '+00:00')), runners=runners, source=self.source_name)\n\n    def _extract_race_number(self, name: Optional[str]) -> int:\n        if not name: return 1\n        match = re.search(r'\\\\bR(\\\\d{1,2})\\\\b', name)\n        return int(match.group(1)) if match else 1",
    "python_service/adapters/brisnet_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass BrisnetAdapter(BaseAdapter):\n    \"\"\"Adapter for brisnet.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"Brisnet\", base_url=\"https://www.brisnet.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"BrisnetAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")",
    "python_service/adapters/drf_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass DRFAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping data from drf.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"DRF\", base_url=\"https://www.drf.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"DRFAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")",
    "python_service/adapters/equibase_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass EquibaseAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping data from equibase.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"Equibase\", base_url=\"https://www.equibase.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"EquibaseAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")",
    "python_service/adapters/fanduel_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass FanDuelAdapter(BaseAdapter):\n    \"\"\"Adapter for racing.fanduel.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"FanDuel\", base_url=\"https://racing.fanduel.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"FanDuelAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nimport structlog\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nimport httpx\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\n\nlog = structlog.get_logger(__name__)\n\nclass GbgbApiAdapter(BaseAdapter):\n    \"\"\"Adapter for the undocumented JSON API for the Greyhound Board of Great Britain.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"GBGB\",\n            base_url=\"https://api.gbgb.org.uk/api/\"\n        )\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            # The endpoint appears to be structured by date for all meetings\n            endpoint = f\"results/meeting/{date}\"\n            response_json = await self.make_request(http_client, 'GET', endpoint)\n\n            if not response_json:\n                return self._format_response([], start_time, is_success=True, error_message=\"No meetings found in API response.\")\n\n            all_races = self._parse_meetings(response_json)\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(f\"{self.source_name}: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(f\"{self.source_name}: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\")\n\n    def _parse_meetings(self, meetings_data: List[Dict[str, Any]]) -> List[Race]:\n        races = []\n        for meeting in meetings_data:\n            track_name = meeting.get('trackName')\n            for race_data in meeting.get('races', []):\n                try:\n                    races.append(self._parse_race(race_data, track_name))\n                except Exception as e:\n                    log.error(f\"{self.source_name}: Error parsing race\", race_id=race_data.get('raceId'), error=str(e))\n        return races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Race:\n        return Race(\n            id=f\"gbgb_{race_data['raceId']}\",\n            venue=track_name,\n            race_number=race_data['raceNumber'],\n            start_time=datetime.fromisoformat(race_data['raceTime'].replace('Z', '+00:00')),\n            runners=self._parse_runners(race_data.get('traps', [])),\n            source=self.source_name,\n            race_name=race_data.get('raceTitle'),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for runner_data in runners_data:\n            try:\n                # The API provides SP as a fraction, e.g., '5/2'\n                odds_data = {}\n                sp = runner_data.get('sp')\n                if sp:\n                    from .utils import parse_odds # Local import to avoid circular dependency issues at module level\n                    win_odds = Decimal(str(parse_odds(sp)))\n                    if win_odds < 999:\n                        odds_data[self.source_name] = OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())\n\n                runners.append(Runner(\n                    number=runner_data['trapNumber'],\n                    name=runner_data['dogName'],\n                    odds=odds_data,\n                ))\n            except Exception as e:\n                log.error(f\"{self.source_name}: Error parsing runner\", runner_name=runner_data.get('dogName'), error=str(e))\n        return runners\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': (datetime.now() - start_time).total_seconds()\n            }\n        }",
    "python_service/adapters/greyhound_adapter.py": "from datetime import datetime\nfrom typing import Any, Dict, List\nimport httpx\nfrom pydantic import ValidationError\nimport structlog\nfrom decimal import Decimal\n\nfrom ..models import Race, Runner, OddsData\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\nclass GreyhoundAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching Greyhound racing data. Activated by setting GREYHOUND_API_URL in .env\"\"\"\n\n    def __init__(self, config):\n        if not config.GREYHOUND_API_URL:\n            raise ValueError(\"GreyhoundAdapter cannot be initialized without GREYHOUND_API_URL.\")\n        super().__init__(\n            source_name=\"Greyhound Racing\",\n            base_url=config.GREYHOUND_API_URL\n        )\n        # Example for future use: self.api_key = config.GREYHOUND_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        \"\"\"Fetches upcoming greyhound races for the specified date.\"\"\"\n        start_time = datetime.now()\n        endpoint = f\"v1/cards/{date}\" # Using date parameter\n        try:\n            response_json = await self.make_request(http_client, 'GET', endpoint)\n            if not response_json or not response_json.get(\"cards\"):\n                log.warning(\"GreyhoundAdapter: No 'cards' in response or empty list.\")\n                return self._format_response([], start_time, is_success=True, error_message=\"No race cards found for date.\")\n\n            all_races = self._parse_cards(response_json[\"cards\"])\n            if not all_races:\n                return self._format_response([], start_time, is_success=True, error_message=\"Races found, but none could be parsed.\")\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"GreyhoundAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(\"GreyhoundAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {str(e)}\")\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }\n\n    def _parse_cards(self, cards: List[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses a list of cards and their races into Race objects.\"\"\"\n        all_races = []\n        for card in cards:\n            venue = card.get(\"track_name\", \"Unknown Venue\")\n            races_data = card.get(\"races\", [])\n            for race_data in races_data:\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race = Race(\n                        id=f\"greyhound_{race_data['race_id']}\",\n                        venue=venue,\n                        race_number=race_data[\"race_number\"],\n                        start_time=datetime.fromtimestamp(race_data[\"start_time\"]),\n                        runners=self._parse_runners(race_data[\"runners\"]),\n                        source=self.source_name\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    log.error(\n                        f\"GreyhoundAdapter: Error parsing race {race_data.get('race_id', 'N/A')}\",\n                        error=str(e),\n                        race_data=race_data\n                    )\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                if runner_data.get(\"scratched\", False):\n                    continue\n\n                odds_data = {}\n                # The directive's example was flawed. Correcting to a more realistic structure.\n                win_odds_val = runner_data.get(\"odds\", {}).get(\"win\")\n                if win_odds_val is not None:\n                    win_odds = Decimal(str(win_odds_val))\n                    if win_odds > 1:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds,\n                            source=self.source_name,\n                            last_updated=datetime.now()\n                        )\n\n                runner = Runner(\n                    number=runner_data[\"trap_number\"],\n                    name=runner_data[\"dog_name\"],\n                    scratched=runner_data.get(\"scratched\", False),\n                    odds=odds_data\n                )\n                runners.append(runner)\n            except (KeyError, ValidationError) as e:\n                 log.error(\"GreyhoundAdapter: Error parsing runner\", error=str(e), runner_data=runner_data)\n        return runners",
    "python_service/adapters/harness_adapter.py": "from datetime import datetime\nfrom typing import Any, Dict, List\nimport httpx\nfrom pydantic import ValidationError, Field\nimport structlog\nfrom decimal import Decimal\n\nfrom ..models import Race, Runner, OddsData\nfrom .base import BaseAdapter\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\nclass HarnessAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching Harness racing data from USTA.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"Harness Racing (USTA)\",\n            base_url=\"https://data.ustrotting.com/\"\n        )\n        # No API key required for this public endpoint\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        \"\"\"Fetches upcoming harness races for the specified date.\"\"\"\n        start_time = datetime.now()\n        endpoint = f\"api/racenet/racing/card/{date}\"\n        try:\n            response_json = await self.make_request(http_client, 'GET', endpoint)\n            if not response_json or \"meetings\" not in response_json:\n                log.warning(\"HarnessAdapter: No 'meetings' in response or empty response.\")\n                return self._format_response([], start_time, is_success=True, error_message=\"No meetings found for date.\")\n\n            all_races = self._parse_meetings(response_json[\"meetings\"])\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"HarnessAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(\"HarnessAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {str(e)}\")\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }\n\n    def _parse_meetings(self, meetings: List[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses a list of meetings and their races into Race objects.\"\"\"\n        all_races = []\n        for meeting in meetings:\n            venue = meeting.get(\"trackName\", \"Unknown Venue\")\n            races_data = meeting.get(\"races\", [])\n            for race_data in races_data:\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race = Race(\n                        id=f\"usta_{race_data['raceId']}\", # Correct field: id\n                        venue=venue,\n                        race_number=race_data[\"raceNumber\"],\n                        start_time=datetime.fromisoformat(race_data[\"startTime\"].replace(\"Z\", \"+00:00\")),\n                        runners=self._parse_runners(race_data[\"runners\"]),\n                        source=self.source_name\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    log.error(\n                        f\"HarnessAdapter: Error parsing race {race_data.get('raceId', 'N/A')}\",\n                        error=str(e),\n                        race_data=race_data\n                    )\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                # API provides number as 'postPosition'\n                runner_number = runner_data.get('postPosition')\n                if not runner_number:\n                    continue\n\n                # Adapt to the Runner model's odds structure\n                odds_data = {}\n                win_odds_str = runner_data.get(\"morningLineOdds\")\n                if win_odds_str:\n                    try:\n                        # The USTA API provides \"5\" for 5/1, which the original code handled as `Decimal('5') + 1`.\n                        # The central utility expects fractional format, so we ensure it exists.\n                        if '/' not in win_odds_str:\n                            win_odds_str = f\"{win_odds_str}/1\"\n\n                        parsed_float = parse_odds(win_odds_str)\n                        if parsed_float < 999.0:\n                            decimal_odds = Decimal(str(parsed_float))\n                            if decimal_odds > 1:\n                                odds_data[self.source_name] = OddsData(\n                                    win=decimal_odds,\n                                    source=self.source_name,\n                                    last_updated=datetime.now()\n                                )\n                    except (ValueError, TypeError):\n                         log.warning(\"Could not parse harness odds\", odds_str=win_odds_str)\n\n\n                runner = Runner(\n                    number=runner_number,\n                    name=runner_data[\"horseName\"],\n                    scratched=runner_data.get(\"scratched\", False),\n                    odds=odds_data\n                )\n                runners.append(runner)\n            except (KeyError, ValidationError) as e:\n                log.error(\"HarnessAdapter: Error parsing runner\", error=str(e), runner_data=runner_data)\n        return runners",
    "python_service/adapters/horseracingnation_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass HorseRacingNationAdapter(BaseAdapter):\n    \"\"\"Adapter for horseracingnation.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"HorseRacingNation\", base_url=\"https://www.horseracingnation.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"HorseRacingNationAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/nyrabets_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass NYRABetsAdapter(BaseAdapter):\n    \"\"\"Adapter for nyrabets.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"NYRABets\", base_url=\"https://nyrabets.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"NYRABetsAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/oddschecker_adapter.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Oddschecker Adapter (Canonized)\n# ==============================================================================\n# This adapter was sourced from the 'Live Odds Anthology' and has been modernized\n# to conform to the project's current BaseAdapter framework.\n# ==============================================================================\n\nimport httpx\nimport structlog\nimport asyncio\nfrom datetime import datetime\nfrom typing import List, Optional, Dict, Any\nfrom bs4 import BeautifulSoup, Tag\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\nclass OddscheckerAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping live horse racing odds from Oddschecker.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"Oddschecker\", base_url=\"https://www.oddschecker.com\")\n        self.config = config\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            meeting_links = await self._get_all_meeting_links(http_client)\n            if not meeting_links:\n                return self._format_response([], start_time, is_success=True, error_message=\"No meeting links found.\")\n\n            tasks = [self._fetch_single_meeting(link, http_client) for link in meeting_links]\n            races_from_all_meetings = await asyncio.gather(*tasks)\n\n            all_races = [race for sublist in races_from_all_meetings for race in sublist if race]\n            return self._format_response(all_races, start_time)\n        except Exception as e:\n            log.error(\"OddscheckerAdapter failed\", exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_all_meeting_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        html = await self.make_request(http_client, 'GET', '/horse-racing')\n        soup = BeautifulSoup(html, \"html.parser\")\n        links = {self.base_url + a['href'] for a in soup.select('a.meeting-title[href]')}\n        return sorted(list(links))\n\n    async def _fetch_single_meeting(self, url: str, client: httpx.AsyncClient) -> List[Optional[Race]]:\n        try:\n            html = await self.make_request(client, 'GET', url.replace(self.base_url, ''))\n            soup = BeautifulSoup(html, \"html.parser\")\n            race_links = {self.base_url + a['href'] for a in soup.select('a.race-time-link[href]')}\n            tasks = [self._fetch_and_parse_race_card(link, client) for link in race_links]\n            return await asyncio.gather(*tasks)\n        except Exception as e:\n            log.error(\"Oddschecker failed to fetch meeting\", url=url, error=e)\n            return []\n\n    async def _fetch_and_parse_race_card(self, url: str, client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            html = await self.make_request(client, 'GET', url.replace(self.base_url, ''))\n            soup = BeautifulSoup(html, \"html.parser\")\n            return self._parse_race_page(soup, url)\n        except Exception as e:\n            log.error(\"Oddschecker failed to parse race card\", url=url, error=e)\n            return None\n\n    def _parse_race_page(self, soup: BeautifulSoup, url: str) -> Optional[Race]:\n        track_name = soup.select_one('h1.meeting-name').get_text(strip=True) if soup.select_one('h1.meeting-name') else 'Unknown'\n        race_time = soup.select_one('span.race-time').get_text(strip=True) if soup.select_one('span.race-time') else None\n        race_number = int(url.split('-')[-1]) if 'race-' in url else 0\n\n        runners = []\n        for row in soup.select(\"tr.race-card-row\"):\n            runner = self._parse_runner_row(row)\n            if runner: runners.append(runner)\n\n        if not runners: return None\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{datetime.now().strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name, race_number=race_number, start_time=datetime.now(), # Placeholder time\n            runners=runners\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        name_tag = row.select_one('span.selection-name')\n        name = name_tag.get_text(strip=True) if name_tag else None\n        odds_tag = row.select_one('span.bet-button-odds-desktop, span.best-price')\n        odds_str = odds_tag.get_text(strip=True) if odds_tag else None\n        number_tag = row.select_one('td.runner-number')\n        number = int(number_tag.get_text(strip=True)) if number_tag else 0\n\n        if not name or not odds_str: return None\n\n        odds_val = parse_odds(odds_str)\n        odds_dict = {}\n        if odds_val:\n            odds_dict[self.source_name] = OddsData(win=Decimal(str(odds_val)), source=self.source_name, last_updated=datetime.now())\n\n        return Runner(number=number, name=name, odds=odds_dict)\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': [r.model_dump() for r in races],\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }",
    "python_service/adapters/pointsbet_greyhound_adapter.py": "# python_service/adapters/pointsbet_greyhound_adapter.py\n\nimport structlog\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\n\nlog = structlog.get_logger(__name__)\n\nclass PointsBetGreyhoundAdapter(BaseAdapter):\n    \"\"\"TODO: This is a placeholder adapter. It will not be active until the correct sportId is found.\"\"\"\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"PointsBet Greyhound\",\n            base_url=\"https://api.au.pointsbet.com\"\n        )\n        self.api_key = config.POINTSBET_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        # TODO: This adapter is a placeholder and is not registered in the engine.\n        # To enable, find the correct sportId for Greyhound Racing and register the adapter.\n        log.warning(\"PointsBetGreyhoundAdapter: This adapter is a non-functional placeholder.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Adapter is a placeholder.\")\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }",
    "python_service/adapters/punters_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass PuntersAdapter(BaseAdapter):\n    \"\"\"Adapter for punters.com.au.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"Punters\", base_url=\"https://www.punters.com.au\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"PuntersAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nimport os\nimport structlog\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner\n\nlog = structlog.get_logger(__name__)\n\nclass RacingAndSportsAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"Racing and Sports\",\n            base_url=\"https://api.racingandsports.com.au/\"\n        )\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        all_races: List[Race] = []\n        headers = {\"Authorization\": f\"Bearer {self.api_token}\", \"Accept\": \"application/json\"}\n\n        if not self.api_token:\n            return self._format_response([], start_time, is_success=False, error_message=\"ConfigurationError: Token not set\")\n\n        try:\n            meetings_url = \"v1/racing/meetings\"\n            params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n            meetings_data = await self.make_request(http_client, 'GET', meetings_url, headers=headers, params=params)\n\n            if not meetings_data or not meetings_data.get('meetings'):\n                return self._format_response(all_races, start_time, is_success=True)\n\n            for meeting in meetings_data['meetings']:\n                for race_summary in meeting.get('races', []):\n                    try:\n                        parsed_race = self._parse_ras_race(meeting, race_summary)\n                        all_races.append(parsed_race)\n                    except Exception as e:\n                        log.error(\"RacingAndSportsAdapter: Failed to parse race\", meeting=meeting.get('venueName'), error=str(e), exc_info=True)\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"RacingAndSportsAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(\"RacingAndSportsAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\")\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name, 'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races), 'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Race:\n        runners = [Runner(number=rd.get('runnerNumber'), name=rd.get('horseName', 'Unknown'), scratched=rd.get('isScratched', False)) for rd in race.get('runners', [])]\n\n        return Race(\n            id=f\"ras_{race.get('raceId')}\",\n            venue=meeting.get('venueName', 'Unknown Venue'),\n            race_number=race.get('raceNumber'),\n            start_time=datetime.fromisoformat(race.get('startTime')),\n            runners=runners,\n            source=self.source_name\n        )",
    "python_service/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\nimport os\nimport structlog\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner\n\nlog = structlog.get_logger(__name__)\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"Racing and Sports Greyhound\",\n            base_url=\"https://api.racingandsports.com.au/\"\n        )\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        all_races: List[Race] = []\n        headers = {\"Authorization\": f\"Bearer {self.api_token}\", \"Accept\": \"application/json\"}\n\n        if not self.api_token:\n            return self._format_response([], start_time, is_success=False, error_message=\"ConfigurationError: Token not set\")\n\n        try:\n            # HYPOTHESIS: The greyhound endpoint is parallel to the racing one.\n            meetings_url = \"v1/greyhound/meetings\"\n            params = {\"date\": date, \"jurisdiction\": \"AUS\"} # Jurisdiction may need to be adjusted\n            meetings_data = await self.make_request(http_client, 'GET', meetings_url, headers=headers, params=params)\n\n            if not meetings_data or not meetings_data.get('meetings'):\n                return self._format_response(all_races, start_time, is_success=True, error_message=\"No greyhound meetings found.\")\n\n            for meeting in meetings_data['meetings']:\n                for race_summary in meeting.get('races', []):\n                    try:\n                        parsed_race = self._parse_ras_race(meeting, race_summary)\n                        all_races.append(parsed_race)\n                    except Exception as e:\n                        log.error(\"RacingAndSportsGreyhoundAdapter: Failed to parse race\", meeting=meeting.get('venueName'), error=str(e), exc_info=True)\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"RacingAndSportsGreyhoundAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(\"RacingAndSportsGreyhoundAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\")\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name, 'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races), 'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Race:\n        runners = [Runner(number=rd.get('runnerNumber'), name=rd.get('horseName', 'Unknown'), scratched=rd.get('isScratched', False)) for rd in race.get('runners', [])]\n\n        return Race(\n            id=f\"rasg_{race.get('raceId')}\",\n            venue=meeting.get('venueName', 'Unknown Venue'),\n            race_number=race.get('raceNumber'),\n            start_time=datetime.fromisoformat(race.get('startTime')),\n            runners=runners,\n            source=self.source_name\n        )",
    "python_service/adapters/racingpost_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass RacingPostAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping data from racingpost.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"RacingPost\", base_url=\"https://www.racingpost.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"RacingPostAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/racingtv_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass RacingTVAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping data from racingtv.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"RacingTV\", base_url=\"https://www.racingtv.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"RacingTVAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/sporting_life_adapter.py": "# python_service/adapters/sporting_life_adapter.py\n\nimport asyncio, structlog, httpx\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nfrom bs4 import BeautifulSoup, Tag\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return ' '.join(text.strip().split()) if text else None\n\nclass SportingLifeAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"SportingLife\", base_url=\"https://www.sportinglife.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response_html = await self.make_request(http_client, 'GET', '/horse-racing/racecards')\n        if not response_html: return []\n        soup = BeautifulSoup(response_html, \"html.parser\")\n        links = {a['href'] for a in soup.select(\"a.hr-race-card-meeting__race-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response_html = await self.make_request(http_client, 'GET', url)\n            if not response_html: return None\n            soup = BeautifulSoup(response_html, \"html.parser\")\n            track_name = _clean_text(soup.select_one(\"a.hr-race-header-course-name__link\").get_text())\n            race_time_str = _clean_text(soup.select_one(\"span.hr-race-header-time__time\").get_text())\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            active_link = soup.select_one(\"a.hr-race-header-navigation-link--active\")\n            race_number = soup.select(\"a.hr-race-header-navigation-link\").index(active_link) + 1 if active_link else 1\n            runners = [self._parse_runner(row) for row in soup.select(\"div.hr-racing-runner-card\")]\n            return Race(id=f\"sl_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\", venue=track_name, race_number=race_number, start_time=start_time, runners=[r for r in runners if r], source=self.source_name)\n        except Exception: return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"a.hr-racing-runner-horse-name\").get_text())\n            num_str = _clean_text(row.select_one(\"span.hr-racing-runner-saddle-cloth-no\").get_text())\n            number = int(''.join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"span.hr-racing-runner-odds\").get_text())\n            win_odds = Decimal(str(parse_odds(odds_str))) if odds_str else None\n            odds_data = {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())} if win_odds and win_odds < 999 else {}\n            return Runner(number=number, name=name, odds=odds_data)\n        except: return None\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool, error_message: str = None) -> Dict[str, Any]:\n        return {'races': races, 'source_info': {'name': self.source_name, 'status': 'SUCCESS' if is_success else 'FAILED', 'races_fetched': len(races), 'error_message': error_message, 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/tab_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass TabAdapter(BaseAdapter):\n    \"\"\"Adapter for tab.com.au.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"TAB\", base_url=\"https://www.tab.com.au\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"TabAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/template_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# ==============================================================================\n#  Fortuna Faucet: Canonical Adapter Template\n# ==============================================================================\n# This file is the official template for creating new adapters. It is based on\n# the clean and simple design of the RacingAndSportsAdapter.\n# ==============================================================================\n\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner # Assuming standard models\n\nlog = structlog.get_logger(__name__)\n\nclass TemplateAdapter(BaseAdapter):\n    \"\"\"[IMPLEMENT ME] A brief description of the data source.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"[IMPLEMENT ME] Example Source\",\n            base_url=\"https://api.example.com\"\n        )\n        # self.api_key = config.EXAMPLE_API_KEY # Uncomment if needed\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        \"\"\"[IMPLEMENT ME] The core logic for fetching and parsing races.\"\"\"\n        start_time = datetime.now()\n        all_races: List[Race] = []\n\n        # --- Example Logic ---\n        # endpoint = f\"/v1/races/{date}\"\n        # headers = {\"X-Api-Key\": self.api_key}\n        # response_json = await self.make_request(http_client, 'GET', endpoint, headers=headers)\n        # if not response_json or 'data' not in response_json:\n        #     return self._format_response(all_races, start_time)\n        #\n        # for race_data in response_json['data']:\n        #     parsed_race = self._parse_race(race_data)\n        #     all_races.append(parsed_race)\n        # --- End Example ---\n\n        log.warning(\"TemplateAdapter.fetch_races is a stub and is not implemented.\")\n        return self._format_response(all_races, start_time)\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': [r.model_dump() for r in races],\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }\n\n    def _parse_race(self, race_data: Dict[str, Any]) -> Race:\n        \"\"\"[IMPLEMENT ME] Logic to parse a single race from the source's data structure.\"\"\"\n        # Example:\n        # runners = self._parse_runners(race_data.get('runners', []))\n        # return Race(\n        #     id=f\"template_{race_data['id']}\",\n        #     venue=race_data['venue_name'],\n        #     race_number=race_data['race_number'],\n        #     start_time=datetime.fromisoformat(race_data['start_time']),\n        #     runners=runners,\n        #     source=self.source_name\n        # )\n        raise NotImplementedError(\"'_parse_race' is not implemented in TemplateAdapter.\")\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"[IMPLEMENT ME] Logic to parse a list of runners.\"\"\"\n        raise NotImplementedError(\"'_parse_runners' is not implemented in TemplateAdapter.\")",
    "python_service/adapters/the_racing_api_adapter.py": "# python_service/adapters/theracingapi_adapter.py\n\nimport structlog\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nimport httpx\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\n\nlog = structlog.get_logger(__name__)\n\nclass TheRacingApiAdapter(BaseAdapter):\n    \"\"\"Adapter for the high-value JSON-based The Racing API.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"TheRacingAPI\",\n            base_url=\"https://api.theracingapi.com/v1/\"\n        )\n        self.api_key = config.THE_RACING_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        if not self.api_key:\n            return self._format_response([], start_time, is_success=False, error_message=\"ConfigurationError: THE_RACING_API_KEY not set\")\n\n        try:\n            endpoint = f\"racecards?date={date}&course=all&region=gb,ire\"\n            headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n            response_json = await self.make_request(http_client, 'GET', endpoint, headers=headers)\n\n            if not response_json or not response_json.get('racecards'):\n                return self._format_response([], start_time, is_success=True, error_message=\"No racecards found in API response.\")\n\n            all_races = self._parse_races(response_json['racecards'])\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(f\"{self.source_name}: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(f\"{self.source_name}: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\")\n\n    def _parse_races(self, racecards: List[Dict[str, Any]]) -> List[Race]:\n        races = []\n        for race_data in racecards:\n            try:\n                start_time = datetime.fromisoformat(race_data['off_time'].replace('Z', '+00:00'))\n\n                race = Race(\n                    id=f\"tra_{race_data['race_id']}\",\n                    venue=race_data['course'],\n                    race_number=race_data['race_no'],\n                    start_time=start_time,\n                    runners=self._parse_runners(race_data.get('runners', [])),\n                    source=self.source_name,\n                    race_name=race_data.get('race_name'),\n                    distance=race_data.get('distance_f'),\n                )\n                races.append(race)\n            except Exception as e:\n                log.error(f\"{self.source_name}: Error parsing race\", race_id=race_data.get('race_id'), error=str(e))\n        return races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for i, runner_data in enumerate(runners_data):\n            try:\n                odds_data = {}\n                if runner_data.get('odds'):\n                    win_odds = Decimal(str(runner_data['odds'][0]['odds_decimal']))\n                    odds_data[self.source_name] = OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())\n\n                runners.append(Runner(\n                    number=runner_data.get('number', i + 1),\n                    name=runner_data['horse'],\n                    odds=odds_data,\n                    jockey=runner_data.get('jockey'),\n                    trainer=runner_data.get('trainer'),\n                ))\n            except Exception as e:\n                log.error(f\"{self.source_name}: Error parsing runner\", runner_name=runner_data.get('horse'), error=str(e))\n        return runners\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': (datetime.now() - start_time).total_seconds()\n            }\n        }",
    "python_service/adapters/timeform_adapter.py": "# python_service/adapters/timeform_adapter.py\n\nimport asyncio, structlog, httpx\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nfrom bs4 import BeautifulSoup, Tag\nfrom decimal import Decimal\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return ' '.join(text.strip().split()) if text else None\n\nclass TimeformAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"Timeform\", base_url=\"https://www.timeform.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response_html = await self.make_request(http_client, 'GET', '/horse-racing/racecards')\n        if not response_html: return []\n        soup = BeautifulSoup(response_html, \"html.parser\")\n        links = {a['href'] for a in soup.select(\"a.rp-racecard-off-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response_html = await self.make_request(http_client, 'GET', url)\n            if not response_html: return None\n            soup = BeautifulSoup(response_html, \"html.parser\")\n            track_name = _clean_text(soup.select_one(\"h1.rp-raceTimeCourseName_name\").get_text())\n            race_time_str = _clean_text(soup.select_one(\"span.rp-raceTimeCourseName_time\").get_text())\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            all_times = [_clean_text(a.get_text()) for a in soup.select('a.rp-racecard-off-link')]\n            race_number = all_times.index(race_time_str) + 1 if race_time_str in all_times else 1\n            runners = [self._parse_runner(row) for row in soup.select(\"div.rp-horseTable_mainRow\")]\n            return Race(id=f\"tf_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\", venue=track_name, race_number=race_number, start_time=start_time, runners=[r for r in runners if r], source=self.source_name)\n        except Exception: return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"a.rp-horseTable_horse-name\").get_text())\n            num_str = _clean_text(row.select_one(\"span.rp-horseTable_horse-number\").get_text()).strip(\"()\")\n            number = int(''.join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"button.rp-bet-placer-btn__odds\").get_text())\n            win_odds = Decimal(str(parse_odds(odds_str))) if odds_str else None\n            odds_data = {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())} if win_odds and win_odds < 999 else {}\n            return Runner(number=number, name=name, odds=odds_data)\n        except: return None\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool, error_message: str = None) -> Dict[str, Any]:\n        return {'races': races, 'source_info': {'name': self.source_name, 'status': 'SUCCESS' if is_success else 'FAILED', 'races_fetched': len(races), 'error_message': error_message, 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/tvg_adapter.py": "# python_service/adapters/tvg_adapter.py\n\nimport os\nimport structlog\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Optional\nimport httpx\nfrom decimal import Decimal, InvalidOperation\n\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner, OddsData\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\ndef _parse_program_number(program_str: str) -> int:\n    \"\"\"Safely parses program numbers like '1A' into an integer.\"\"\"\n    return int(''.join(filter(str.isdigit, program_str))) if program_str else 99\n\nclass TVGAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(\n            source_name=\"TVG\",\n            base_url=\"https://api.tvg.com/v3/\"\n        )\n        self.api_key = config.TVG_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        all_races: List[Race] = []\n        headers = {\"Accept\": \"application/json\", \"X-API-Key\": self.api_key}\n\n        if not self.api_key:\n            log.warning(\"TVGAdapter: TVG_API_KEY not set. Skipping.\")\n            return self._format_response([], start_time, is_success=False, error_message=\"ConfigurationError: TVG_API_KEY not set\")\n\n        try:\n            tracks_url = \"tracks\"\n            tracks_params = {\"date\": date, \"country\": \"US\"}\n            tracks_response = await self.make_request(http_client, 'GET', tracks_url, headers=headers, params=tracks_params)\n\n            if not tracks_response or 'tracks' not in tracks_response:\n                log.warning(\"TVG: No tracks found for the given date.\")\n                return self._format_response(all_races, start_time, is_success=True)\n\n            for track in tracks_response['tracks']:\n                try:\n                    races_url = f\"tracks/{track['code']}/races\"\n                    races_params = {\"date\": date}\n                    races_response = await self.make_request(http_client, 'GET', races_url, headers=headers, params=races_params)\n\n                    for race_summary in races_response.get('races', []):\n                        race_detail_url = f\"tracks/{track['code']}/races/{race_summary['number']}\"\n                        race_detail = await self.make_request(http_client, 'GET', race_detail_url, headers=headers)\n                        if race_detail:\n                            parsed_race = self._parse_tvg_race(track, race_detail)\n                            all_races.append(parsed_race)\n                except httpx.HTTPError as e:\n                    log.error(\"TVGAdapter: Failed to process track, skipping.\", track_name=track.get('name'), error=str(e))\n                    continue # Continue to the next track\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"TVGAdapter: Initial HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=\"API request failed after multiple retries.\")\n        except Exception as e:\n            log.error(\"TVGAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\")\n\n    def _format_response(self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            'races': races,\n            'source_info': {\n                'name': self.source_name,\n                'status': 'SUCCESS' if is_success else 'FAILED',\n                'races_fetched': len(races),\n                'error_message': error_message,\n                'fetch_duration': fetch_duration\n            }\n        }\n\n    def _parse_tvg_race(self, track: Dict[str, Any], race_data: Dict[str, Any]) -> Race:\n        runners = []\n        for runner_data in race_data.get('runners', []):\n            if not runner_data.get('scratched'):\n                current_odds_str = runner_data.get('odds', {}).get('current') or runner_data.get('odds', {}).get('morningLine')\n                win_odds = self._parse_tvg_odds(current_odds_str)\n\n                odds_dict = {}\n                if win_odds:\n                    odds_dict[self.source_name] = OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())\n\n                runners.append(Runner(\n                    number=_parse_program_number(runner_data.get('programNumber')),\n                    name=runner_data.get('horseName', 'Unknown Runner'),\n                    scratched=False,\n                    odds=odds_dict\n                ))\n\n        race_id = f\"{track.get('code', 'UNK').lower()}_{race_data['postTime'].split('T')[0]}_R{race_data['number']}\"\n\n        return Race(\n            id=race_id,\n            venue=track.get('name', 'Unknown Venue'),\n            race_number=race_data.get('number'),\n            start_time=datetime.fromisoformat(race_data.get('postTime')),\n            runners=runners,\n            source=self.source_name\n        )\n\n    def _parse_tvg_odds(self, odds_string: str) -> Optional[Decimal]:\n        if not odds_string or odds_string == \"SCR\":\n            return None\n        try:\n            # Utilize the centralized parsing utility which handles fractions, evens, and decimals.\n            parsed_float = parse_odds(odds_string)\n            # The utility returns a high number on failure, which we can filter out.\n            if parsed_float >= 999.0:\n                return None\n            return Decimal(str(parsed_float))\n        except (ValueError, InvalidOperation):\n            log.warning(\"Could not convert parsed TVG odds to Decimal\", odds_str=odds_string)\n            return None",
    "python_service/adapters/twinspires_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass TwinSpiresAdapter(BaseAdapter):\n    \"\"\"Adapter for twinspires.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"TwinSpires\", base_url=\"https://www.twinspires.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"TwinSpiresAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'Not Implemented', 'fetch_duration': (datetime.now() - start_time).total_seconds()}}",
    "python_service/adapters/universal_adapter.py": "import json\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom typing import Dict, Any, List\nfrom .base import BaseAdapter\nfrom ..models import Race, Runner # Assuming models are updated\n\nlog = structlog.get_logger(__name__)\n\nclass UniversalAdapter(BaseAdapter):\n    \"\"\"An adapter that executes logic from a declarative JSON definition file.\"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, 'r') as f:\n            self.definition = json.load(f)\n\n        super().__init__(\n            source_name=self.definition['adapter_name'],\n            base_url=self.definition['base_url']\n        )\n        self.config = config\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        # NOTE: This is a simplified proof-of-concept implementation.\n        # It does not handle all cases from the JSON definition.\n        log.info(f\"Executing Universal Adapter for {self.source_name}\")\n\n        # Step 1: Get Track Links (as defined in equibase_v2.json)\n        start_url = self.definition['steps'][0]['selector']\n        response = await self.make_request(http_client, 'GET', self.definition['start_url'])\n        soup = BeautifulSoup(response, 'html.parser')\n        track_links = [self.base_url + a['href'] for a in soup.select(self.definition['steps'][0]['selector'])]\n\n        all_races = []\n        for link in track_links:\n            try:\n                track_response = await self.make_request(http_client, 'GET', link.replace(self.base_url, ''))\n                track_soup = BeautifulSoup(track_response, 'html.parser')\n                race_containers = track_soup.select(self.definition['steps'][1]['list_selector'])\n\n                for container in race_containers:\n                    # Simplified parsing logic for this PoC\n                    track_name = container.select_one('div.track-name h1').text.strip()\n                    race_number = int(container.select_one('h3.race-number').text.strip().split()[-1])\n                    # ... further parsing would be implemented here ...\n                    # This PoC demonstrates the principle, not a full implementation.\n                    pass # Placeholder\n\n            except Exception as e:\n                log.error(\"Failed to process track link\", link=link, error=e)\n\n        # This is a placeholder return for the PoC\n        return {'races': [], 'source_info': {'name': self.source_name, 'status': 'SUCCESS', 'races_fetched': 0, 'error_message': 'PoC Complete', 'fetch_duration': 0.0}}",
    "python_service/adapters/utils.py": "# ==============================================================================\n# == Centralized Adapter Utilities\n# ==============================================================================\n# This module provides shared, battle-tested functions for all adapters to use,\n# ensuring consistency and adhering to the DRY principle.\n# ==============================================================================\n\nfrom typing import Union\n\ndef parse_odds(odds: Union[str, int, float]) -> float:\n    \"\"\"\n    Parses various odds formats (e.g., fractional '10/1', decimal 11.0)\n    into a standardized decimal float.\n\n    Returns a default high odds value on failure to prevent crashes.\n    \"\"\"\n    if isinstance(odds, (int, float)):\n        return float(odds)\n\n    if isinstance(odds, str):\n        try:\n            # Handle fractional odds (e.g., \"10/1\", \"5/2\")\n            if \"/\" in odds:\n                numerator, denominator = map(int, odds.split('/'))\n                if denominator == 0: return 999.0\n                return 1.0 + (numerator / denominator)\n\n            # Handle \"evens\"\n            if odds.lower() in ['evs', 'evens']:\n                return 2.0\n\n            # Handle simple decimal strings\n            return float(odds)\n        except (ValueError, TypeError):\n            # Return a high, but valid, number for unparseable odds\n            return 999.0\n\n    return 999.0",
    "python_service/adapters/xpressbet_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Dict, Any, List\nimport httpx\nimport structlog\nfrom .base import BaseAdapter\nfrom ..models import Race\nlog = structlog.get_logger(__name__)\nclass XpressbetAdapter(BaseAdapter):\n    \"\"\"Adapter for xpressbet.com.\"\"\"\n    def __init__(self, config):\n        super().__init__(source_name=\"Xpressbet\", base_url=\"https://www.xpressbet.com\")\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"XpressbetAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")",
    "python_service/analyzer.py": "from abc import ABC, abstractmethod\nfrom typing import List, Dict, Type, Optional, Any\nimport structlog\nfrom decimal import Decimal\n\nfrom python_service.models import Race, Runner\n\nlog = structlog.get_logger(__name__)\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    # Filter out invalid or placeholder odds (e.g., > 999)\n    valid_odds = [o.win for o in runner.odds.values() if o.win is not None and o.win < 999]\n\n    if not valid_odds:\n        return None\n\n    return min(valid_odds)\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n    def __init__(self, max_field_size: int = 10, min_favorite_odds: float = 2.5, min_second_favorite_odds: float = 4.0):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n\n    def qualify_races(self, races: List[Race]) -> Dict[str, Any]:\n        \"\"\"Filters and scores races, returning a dictionary with criteria and a sorted list of qualified races.\"\"\"\n        qualified_races = []\n        for race in races:\n            score = self._evaluate_race(race)\n            if score is not None:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n\n        criteria = {\n            \"max_field_size\": self.max_field_size,\n            \"min_favorite_odds\": float(self.min_favorite_odds),\n            \"min_second_favorite_odds\": float(self.min_second_favorite_odds)\n        }\n\n        log.info(\"Qualification and scoring complete\", qualified_count=len(qualified_races), criteria=criteria)\n        return {\"criteria\": criteria, \"races\": qualified_races}\n\n    def _evaluate_race(self, race: Race) -> Optional[float]:\n        \"\"\"Evaluates a single race and returns a qualification score if it passes, else None.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2: return None\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Apply the Trifecta of Factors as hard filters ---\n        if len(active_runners) > self.max_field_size: return None\n        if favorite_odds < self.min_favorite_odds: return None\n        if second_favorite_odds < self.min_second_favorite_odds: return None\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        return round(final_score * 100, 2)\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer('trifecta', TrifectaAnalyzer)\n        log.info(\"AnalyzerEngine discovered plugins\", available_analyzers=list(self.analyzers.keys()))\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)",
    "python_service/api.py": "# python_service/api.py\n\nimport structlog\nfrom datetime import datetime, date\nfrom typing import List, Optional\nfrom fastapi import FastAPI, HTTPException, Request, Depends, Query\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.middleware import SlowAPIMiddleware\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\nfrom contextlib import asynccontextmanager\n\nfrom .config import get_settings\nfrom .engine import OddsEngine\nfrom .models import Race, AggregatedResponse, QualifiedRacesResponse\nfrom .security import verify_api_key\nfrom .logging_config import configure_logging\nfrom .analyzer import AnalyzerEngine\n\nlog = structlog.get_logger()\n\n# Define the lifespan context manager for robust startup/shutdown\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"\n    Manage the application's lifespan. On startup, it initializes the OddsEngine\n    with validated settings and attaches it to the app state. On shutdown, it\n    properly closes the engine's resources.\n    \"\"\"\n    configure_logging()\n    settings = get_settings()\n    app.state.engine = OddsEngine(config=settings)\n    app.state.analyzer_engine = AnalyzerEngine()\n    log.info(\"Server startup: Configuration validated and OddsEngine initialized.\")\n    yield\n    # Clean up the engine resources\n    await app.state.engine.close()\n    log.info(\"Server shutdown: HTTP client resources closed.\")\n\nlimiter = Limiter(key_func=get_remote_address)\n\n# Pass the lifespan manager to the FastAPI app\napp = FastAPI(title=\"Checkmate Ultimate Solo API\", version=\"2.1\", lifespan=lifespan)\napp.add_middleware(SlowAPIMiddleware)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\nsettings = get_settings()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=settings.ALLOWED_ORIGINS,\n    allow_credentials=True, allow_methods=[\"GET\"], allow_headers=[\"*\"]\n)\n\n# Dependency function to get the engine instance from the app state\ndef get_engine(request: Request) -> OddsEngine:\n    return request.app.state.engine\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"ok\", \"timestamp\": datetime.now().isoformat()}\n\n@app.get(\"/api/adapters/status\")\n@limiter.limit(\"60/minute\")\nasync def get_all_adapter_statuses(request: Request, engine: OddsEngine = Depends(get_engine), _=Depends(verify_api_key)):\n    \"\"\"Provides a list of health statuses for all adapters, required by the new frontend blueprint.\"\"\"\n    try:\n        statuses = engine.get_all_adapter_statuses()\n        return statuses\n    except Exception as e:\n        log.error(\"Error in /api/adapters/status\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@app.get(\"/api/races/qualified/{analyzer_name}\", response_model=QualifiedRacesResponse)\n@limiter.limit(\"30/minute\")\nasync def get_qualified_races(\n    analyzer_name: str,\n    request: Request,\n    race_date: Optional[date] = None,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key),\n    # --- Dynamic Analyzer Parameters ---\n    max_field_size: Optional[int] = Query(None, description=\"Override the max field size for the analyzer.\"),\n    min_favorite_odds: Optional[float] = Query(None, description=\"Override the min favorite odds.\"),\n    min_second_favorite_odds: Optional[float] = Query(None, description=\"Override the min second favorite odds.\")\n):\n    \"\"\"\n    Gets all races for a given date, filters them for qualified betting\n    opportunities, and returns the qualified races.\n    \"\"\"\n    try:\n        if race_date is None:\n            race_date = datetime.now().date()\n        date_str = race_date.strftime('%Y-%m-%d')\n        aggregated_data = await engine.fetch_all_odds(date_str)\n\n        # The engine now correctly returns validated Pydantic models.\n        # No re-validation is necessary.\n        races = aggregated_data.get('races', [])\n\n        analyzer_engine = request.app.state.analyzer_engine\n        # Collect any provided optional parameters into a dictionary\n        analyzer_params = {\n            \"max_field_size\": max_field_size,\n            \"min_favorite_odds\": min_favorite_odds,\n            \"min_second_favorite_odds\": min_second_favorite_odds\n        }\n        # Filter out any parameters that were not provided by the user\n        custom_params = {k: v for k, v in analyzer_params.items() if v is not None}\n\n        analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params)\n        result = analyzer.qualify_races(races)\n        return QualifiedRacesResponse(**result)\n    except ValueError as e:\n        # Correctly map a missing analyzer to a 404 Not Found error\n        log.warning(\"Requested analyzer not found\", analyzer_name=analyzer_name)\n        raise HTTPException(status_code=404, detail=str(e))\n    except Exception as e:\n        log.error(\"Error in /api/races/qualified\", error=str(e), exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n\n@app.get(\"/api/races\", response_model=AggregatedResponse)\n@limiter.limit(\"30/minute\")\nasync def get_races(\n    request: Request,\n    race_date: Optional[date] = None,\n    source: Optional[str] = None,\n    engine: OddsEngine = Depends(get_engine),\n    _=Depends(verify_api_key)\n):\n    try:\n        if race_date is None:\n            race_date = datetime.now().date()\n        date_str = race_date.strftime('%Y-%m-%d')\n        aggregated_data = await engine.fetch_all_odds(date_str, source)\n        return aggregated_data\n    except Exception as e:\n        log.error(\"Error in /api/races\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")",
    "python_service/config.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Centralized Configuration\n# =================================\u00e1=============================================\n# This module, restored by the Great Correction, provides a centralized and\n# validated source for all application settings using pydantic-settings.\n# ==============================================================================\n\nfrom pydantic_settings import BaseSettings\nfrom functools import lru_cache\nfrom typing import List, Optional\n\nclass Settings(BaseSettings):\n    # --- Application Security ---\n    API_KEY: str\n\n    # --- Betfair API Credentials ---\n    BETFAIR_APP_KEY: str = \"\"\n    BETFAIR_USERNAME: str = \"\"\n    BETFAIR_PASSWORD: str = \"\"\n\n    # --- Other Adapter Keys ---\n    TVG_API_KEY: str = \"\"\n    RACING_AND_SPORTS_TOKEN: str = \"\"\n    POINTSBET_API_KEY: str = \"\"\n    GREYHOUND_API_URL: Optional[str] = None\n    THE_RACING_API_KEY: Optional[str] = None\n\n    # --- Placeholder keys for restored scrapers (not currently used but good practice) ---\n    AT_THE_RACES_KEY: Optional[str] = None\n    SPORTING_LIFE_KEY: Optional[str] = None\n    TIMEFORM_KEY: Optional[str] = None\n\n    # --- Caching Configuration ---\n    REDIS_URL: str = \"redis://localhost\"\n\n    # --- CORS Configuration ---\n    ALLOWED_ORIGINS: List[str] = [\"http://localhost:3000\", \"http://localhost:3001\"]\n\n    model_config = {\n        \"env_file\": \".env\",\n        \"case_sensitive\": True\n    }\n\n@lru_cache()\ndef get_settings() -> Settings:\n    \"\"\"Returns a cached instance of the application settings.\"\"\"\n    return Settings()",
    "python_service/engine.py": "# python_service/engine.py\n\nimport asyncio\nimport structlog\nimport httpx\nimport json\nimport redis.asyncio as redis\nfrom datetime import datetime\nfrom typing import Dict, Any, List, Tuple\n\nfrom .models import Race, AggregatedResponse\nfrom .adapters.base import BaseAdapter\nfrom .adapters.betfair_adapter import BetfairAdapter\nfrom .adapters.betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .adapters.racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.at_the_races_adapter import AtTheRacesAdapter\nfrom .adapters.sporting_life_adapter import SportingLifeAdapter\nfrom .adapters.timeform_adapter import TimeformAdapter\nfrom .adapters.harness_adapter import HarnessAdapter\nfrom .adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom .adapters.gbgb_api_adapter import GbgbApiAdapter\n\nlog = structlog.get_logger(__name__)\n\nclass OddsEngine:\n    def __init__(self, config):\n        self.config = config\n        self.log = structlog.get_logger(self.__class__.__name__)\n        self.adapters: List[BaseAdapter] = [\n            BetfairAdapter(config=self.config),\n            BetfairGreyhoundAdapter(config=self.config),\n            TVGAdapter(config=self.config),\n            RacingAndSportsAdapter(config=self.config),\n            RacingAndSportsGreyhoundAdapter(config=self.config),\n            AtTheRacesAdapter(config=self.config),\n            SportingLifeAdapter(config=self.config),\n            TimeformAdapter(config=self.config),\n            TheRacingApiAdapter(config=self.config),\n            GbgbApiAdapter(config=self.config),\n            HarnessAdapter(config=self.config)\n        ]\n        self.http_client = httpx.AsyncClient()\n        self.redis_client = redis.from_url(self.config.REDIS_URL, decode_responses=True)\n        self.log.info(\"Redis client initialized\", redis_url=self.config.REDIS_URL)\n\n    async def close(self):\n        await self.http_client.aclose()\n        await self.redis_client.aclose() # Use aclose() for async client\n\n    def get_all_adapter_statuses(self) -> List[Dict[str, Any]]:\n        return [adapter.get_status() for adapter in self.adapters]\n\n    async def _time_adapter_fetch(self, adapter: BaseAdapter, date: str) -> Tuple[str, Dict[str, Any], float]:\n        start_time = datetime.now()\n        result = await adapter.fetch_races(date, self.http_client)\n        duration = (datetime.now() - start_time).total_seconds()\n        return (adapter.source_name, result, duration)\n\n    def _race_key(self, race: Race) -> str:\n        return f\"{race.venue.lower().strip()}|{race.race_number}|{race.start_time.strftime('%H:%M')}\"\n\n    def _dedupe_races(self, races: List[Race]) -> List[Race]:\n        race_map: Dict[str, Race] = {}\n        for race in races:\n            key = self._race_key(race)\n            if key not in race_map:\n                race_map[key] = race\n            else:\n                existing_race = race_map[key]\n                runner_map = {r.number: r for r in existing_race.runners}\n                for new_runner in race.runners:\n                    if new_runner.number in runner_map:\n                        runner_map[new_runner.number].odds.update(new_runner.odds)\n                    else:\n                        existing_race.runners.append(new_runner)\n        return list(race_map.values())\n\n    async def fetch_all_odds(self, date: str, source_filter: str = None) -> Dict[str, Any]:\n        cache_key = f\"fortuna:races:{date}\"\n        if not source_filter: # Only use cache for 'all sources' requests\n            try:\n                cached_data = await self.redis_client.get(cache_key)\n                if cached_data:\n                    self.log.info(\"CACHE HIT\", key=cache_key)\n                    # Pydantic can validate directly from the JSON string\n                    return AggregatedResponse.model_validate_json(cached_data).model_dump()\n            except Exception as e:\n                self.log.error(\"Redis GET failed\", error=str(e))\n\n        self.log.info(\"CACHE MISS\", key=cache_key)\n        target_adapters = self.adapters\n        if source_filter:\n            target_adapters = [a for a in self.adapters if a.source_name.lower() == source_filter.lower()]\n\n        tasks = [self._time_adapter_fetch(adapter, date) for adapter in target_adapters]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        source_infos = []\n        all_races = []\n        for result in results:\n            if isinstance(result, Exception):\n                self.log.error(\"Adapter fetch failed\", error=result, exc_info=False)\n                continue\n            adapter_name, adapter_result, duration = result\n            source_info = adapter_result.get('source_info', {})\n            source_info['fetch_duration'] = round(duration, 2)\n            source_infos.append(source_info)\n            if source_info.get('status') == 'SUCCESS':\n                all_races.extend(adapter_result.get('races', []))\n\n        deduped_races = self._dedupe_races(all_races)\n\n        response_obj = AggregatedResponse(\n            date=datetime.strptime(date, '%Y-%m-%d').date(),\n            races=deduped_races,\n            sources=source_infos,\n            metadata={\n                'fetch_time': datetime.now(),\n                'sources_queried': [a.source_name for a in target_adapters],\n                'sources_successful': len([s for s in source_infos if s['status'] == 'SUCCESS']),\n                'total_races': len(deduped_races)\n            }\n        )\n\n        if not source_filter: # Only set cache for 'all sources' requests\n            try:\n                # Cache the result for 5 minutes (300 seconds)\n                await self.redis_client.set(cache_key, response_obj.model_dump_json(), ex=300)\n                self.log.info(\"CACHE SET\", key=cache_key, expiry=300)\n            except Exception as e:\n                self.log.error(\"Redis SET failed\", error=str(e))\n\n        return response_obj.model_dump()",
    "python_service/logging_config.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Logging Configuration\n# ==============================================================================\n# This module, restored by the Great Correction, provides a centralized\n# configuration for structured logging using structlog.\n# ==============================================================================\n\nimport logging\nimport sys\nimport structlog\n\ndef configure_logging():\n    \"\"\"Configures structlog for JSON-based structured logging.\"\"\"\n    logging.basicConfig(\n        format=\"%(message)s\",\n        stream=sys.stdout,\n        level=logging.INFO,\n    )\n\n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.StackInfoRenderer(),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )",
    "python_service/models.py": "# python_service/models.py\n\nfrom pydantic import BaseModel, Field, field_validator\nfrom typing import List, Optional, Dict, Any\nfrom datetime import datetime, date\nfrom decimal import Decimal\n\nclass OddsData(BaseModel):\n    win: Optional[Decimal] = None\n    source: str\n    last_updated: datetime\n\n    @field_validator('win')\n    def win_must_be_positive(cls, v):\n        if v is not None and v <= Decimal(\"1.0\"):\n            raise ValueError('Odds must be greater than 1.0')\n        return v\n\nclass Runner(BaseModel):\n    number: int = Field(..., gt=0, lt=100)\n    name: str = Field(..., max_length=100)\n    scratched: bool = False\n    selection_id: Optional[int] = None # For Betfair Exchange integration\n    odds: Dict[str, OddsData] = Field(default_factory=dict)\n    jockey: Optional[str] = None\n    trainer: Optional[str] = None\n\nclass Race(BaseModel):\n    id: str\n    venue: str\n    race_number: int = Field(..., gt=0, lt=21)\n    start_time: datetime\n    runners: List[Runner]\n    source: str\n    qualification_score: Optional[float] = None\n    race_name: Optional[str] = None\n    distance: Optional[str] = None\n\n    @field_validator('runners')\n    def runner_numbers_must_be_unique(cls, v):\n        numbers = [r.number for r in v]\n        if len(numbers) != len(set(numbers)):\n            raise ValueError('Runner numbers must be unique within a race')\n        return v\n\nclass SourceInfo(BaseModel):\n    name: str\n    status: str\n    races_fetched: int\n    error_message: Optional[str] = None\n    fetch_duration: float\n\nclass FetchMetadata(BaseModel):\n    fetch_time: datetime\n    sources_queried: List[str]\n    sources_successful: int\n    total_races: int\n\nclass AggregatedResponse(BaseModel):\n    date: date\n    races: List[Race]\n    sources: List[SourceInfo]\n    metadata: FetchMetadata\n\nclass QualifiedRacesResponse(BaseModel):\n    criteria: Dict[str, Any]\n    races: List[Race]",
    "python_service/requirements.txt": "requests==2.31.0\npython-dotenv==1.0.0\npydantic==2.5.2\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\naiohttp==3.9.0\nhttpx==0.24.1\npytest==8.4.2\n\nstructlog\nrespx\npytest-asyncio\nstreamlit\npandas\ntabula-py\nlxml\nbeautifulsoup4\npikepdf\npydantic-settings==2.1.0\nslowapi==0.1.8\n\ntenacity\n\n# Caching Layer\nredis==5.0.1\nfakeredis==2.20.0 # For testing",
    "python_service/security.py": "# python_service/security.py\n\nimport secrets\nfrom fastapi import Security, HTTPException, status, Depends\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings, get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\nasync def verify_api_key(\n    key: str = Security(api_key_header),\n    settings: Settings = Depends(get_settings)\n):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n    \"\"\"\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Invalid or missing API Key\"\n        )"
}