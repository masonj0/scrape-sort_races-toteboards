{
    "python_service/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass GbgbApiAdapter(BaseAdapter):\n    \"\"\"Adapter for the undocumented JSON API for the Greyhound Board of Great Britain.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"GBGB\", base_url=\"https://api.gbgb.org.uk/api/\", config=config)\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            # The endpoint appears to be structured by date for all meetings\n            endpoint = f\"results/meeting/{date}\"\n            response = await self.make_request(http_client, \"GET\", endpoint)\n\n            if not response:\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No meetings found in API response.\"\n                )\n\n            all_races = self._parse_meetings(response.json())\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(f\"{self.source_name}: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(f\"{self.source_name}: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _parse_meetings(self, meetings_data: List[Dict[str, Any]]) -> List[Race]:\n        races = []\n        if meetings_data is None:\n            return races\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    races.append(self._parse_race(race_data, track_name))\n                except Exception as e:\n                    log.error(f\"{self.source_name}: Error parsing race\", race_id=race_data.get(\"raceId\"), error=str(e))\n        return races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Race:\n        return Race(\n            id=f\"gbgb_{race_data['raceId']}\",\n            venue=track_name,\n            race_number=race_data[\"raceNumber\"],\n            start_time=datetime.fromisoformat(race_data[\"raceTime\"].replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for runner_data in runners_data:\n            try:\n                # The API provides SP as a fraction, e.g., '5/2'\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                win_odds = parse_odds_to_decimal(sp)\n                if win_odds and win_odds < 999:\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds, source=self.source_name, last_updated=datetime.now()\n                    )\n\n                runners.append(\n                    Runner(\n                        number=runner_data[\"trapNumber\"],\n                        name=runner_data[\"dogName\"],\n                        odds=odds_data,\n                    )\n                )\n            except Exception as e:\n                log.error(\n                    f\"{self.source_name}: Error parsing runner\", runner_name=runner_data.get(\"dogName\"), error=str(e)\n                )\n        return runners\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/timeform_adapter.py": "# python_service/adapters/timeform_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return \" \".join(text.strip().split()) if text else None\n\n\nclass TimeformAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"Timeform\", base_url=\"https://www.timeform.com\", config=config)\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response = await self.make_request(http_client, \"GET\", \"/horse-racing/racecards\")\n        if not response:\n            return []\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        links = {a[\"href\"] for a in soup.select(\"a.rp-racecard-off-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response = await self.make_request(http_client, \"GET\", url)\n            if not response:\n                return None\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            track_name = _clean_text(soup.select_one(\"h1.rp-raceTimeCourseName_name\").get_text())\n            race_time_str = _clean_text(soup.select_one(\"span.rp-raceTimeCourseName_time\").get_text())\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            all_times = [_clean_text(a.get_text()) for a in soup.select(\"a.rp-racecard-off-link\")]\n            race_number = all_times.index(race_time_str) + 1 if race_time_str in all_times else 1\n            runners = [self._parse_runner(row) for row in soup.select(\"div.rp-horseTable_mainRow\")]\n            return Race(\n                id=f\"tf_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                venue=track_name,\n                race_number=race_number,\n                start_time=start_time,\n                runners=[r for r in runners if r],\n                source=self.source_name,\n            )\n        except Exception as e:\n            log.error(\"Error parsing race from Timeform\", url=url, exc_info=e)\n            return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"a.rp-horseTable_horse-name\").get_text())\n            num_str = _clean_text(row.select_one(\"span.rp-horseTable_horse-number\").get_text()).strip(\"()\")\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"button.rp-bet-placer-btn__odds\").get_text())\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())}\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except Exception as e:\n            log.warning(\"Failed to parse runner from Timeform\", exc_info=e)\n            return None\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool, error_message: str = None\n    ) -> Dict[str, Any]:\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/racingpost_adapter.py": "# python_service/adapters/racingpost_adapter.py\nfrom datetime import datetime\nfrom typing import AsyncGenerator\n\nfrom selectolax.parser import HTMLParser\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base import BaseAdapter\n\n\nclass RacingPostAdapter(BaseAdapter):\n    \"\"\"A production-ready adapter for scraping Racing Post racecards.\"\"\"\n\n    SOURCE_NAME = \"RacingPost\"\n    BASE_URL = \"https://www.racingpost.com\"\n\n    def __init__(self, config=None):\n        super().__init__(self.SOURCE_NAME, self.BASE_URL)\n\n    async def fetch_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Fetches all UK & Ireland races for a given date from racingpost.com.\n        \"\"\"\n        race_card_urls = await self._get_race_card_urls(date)\n        for url in race_card_urls:\n            try:\n                response = await self.http_client.get(url, headers=self._get_headers())\n                response.raise_for_status()\n                parser = HTMLParser(response.text)\n\n                venue_raw = parser.css_first('a[data-test-selector=\"RC-course__name\"]').text(strip=True)\n                venue = normalize_venue_name(venue_raw)\n\n                race_time_str = parser.css_first('span[data-test-selector=\"RC-course__time\"]').text(strip=True)\n                race_datetime_str = f\"{date} {race_time_str}\"\n                start_time = datetime.strptime(race_datetime_str, \"%Y-%m-%d %H:%M\")\n\n                runners = self._parse_runners(parser)\n\n                if venue and runners:\n                    race_number = self._get_race_number(parser, start_time)\n                    yield Race(\n                        id=f\"rp_{venue.lower().replace(' ', '')}_{date}_{race_number}\",\n                        venue=venue,\n                        race_number=race_number,\n                        start_time=start_time,\n                        runners=runners,\n                        source=self.SOURCE_NAME,\n                    )\n\n            except Exception:\n                # Assuming a logger is available, as per standard practice in the project.\n                # If self.logger is not on BaseAdapter, this would need to be structlog.\n                # self.logger.error(f\"Failed to process race card at {url}\", exc_info=True)\n                continue\n\n    async def _get_race_card_urls(self, date: str) -> list[str]:\n        \"\"\"Gets all individual race card URLs for a given date.\"\"\"\n        url = f\"{self.BASE_URL}/racecards/{date}\"\n        response = await self.http_client.get(url, headers=self._get_headers())\n        parser = HTMLParser(response.text)\n        links = parser.css('a[data-test-selector^=\"RC-meetingItem__link_race\"]')\n        return [f\"{self.BASE_URL}{link.attributes['href']}\" for link in links]\n\n    def _get_race_number(self, parser: HTMLParser, start_time: datetime) -> int:\n        \"\"\"Derives the race number by finding the active time in the nav bar.\"\"\"\n        time_str_to_find = start_time.strftime(\"%H:%M\")\n        time_links = parser.css('a[data-test-selector=\"RC-raceTime\"]')\n        for i, link in enumerate(time_links):\n            if link.text(strip=True) == time_str_to_find:\n                return i + 1\n        return 1  # Fallback\n\n    def _parse_runners(self, parser: HTMLParser) -> list[Runner]:\n        \"\"\"Parses all runners from a single race card page.\"\"\"\n        runners = []\n        runner_nodes = parser.css('div[data-test-selector=\"RC-runnerCard\"]')\n        for node in runner_nodes:\n            try:\n                number_node = node.css_first('span[data-test-selector=\"RC-runnerNumber\"]')\n                name_node = node.css_first('a[data-test-selector=\"RC-runnerName\"]')\n                odds_node = node.css_first('span[data-test-selector=\"RC-runnerPrice\"]')\n\n                if not all([number_node, name_node, odds_node]):\n                    continue\n\n                number_str = clean_text(number_node.text())\n                number = int(number_str) if number_str and number_str.isdigit() else 0\n                name = clean_text(name_node.text())\n                odds_str = clean_text(odds_node.text())\n                scratched = \"NR\" in odds_str.upper() or not odds_str\n\n                odds = {}\n                if not scratched:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds and win_odds < 999:\n                        odds = {\n                            self.SOURCE_NAME: OddsData(\n                                win=win_odds, source=self.SOURCE_NAME, last_updated=datetime.now()\n                            )\n                        }\n\n                runners.append(Runner(number=number, name=name, odds=odds, scratched=scratched))\n            except (ValueError, AttributeError):\n                continue\n        return runners\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/horseracingnation_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass HorseRacingNationAdapter(BaseAdapter):\n    \"\"\"Adapter for horseracingnation.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"HorseRacingNation\", base_url=\"https://www.horseracingnation.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"HorseRacingNationAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {\n            \"races\": [],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\",\n                \"races_fetched\": 0,\n                \"error_message\": \"Not Implemented\",\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/xpressbet_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\n\nimport httpx\nimport structlog\n\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass XpressbetAdapter(BaseAdapter):\n    \"\"\"Adapter for xpressbet.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"Xpressbet\", base_url=\"https://www.xpressbet.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"XpressbetAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\nfrom datetime import datetime\nfrom typing import Any, List\n\nfrom ..models import Race, Runner\nfrom .base_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching horse racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairExchange\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for a given date.\"\"\"\n        await self._authenticate()\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        return await self.make_request(\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"7\"],  # Horse Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\", \"US\", \"FR\", \"ZA\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\"from\": start_time.isoformat(), \"to\": end_time.isoformat()}\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"]\n            }\n        )\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                races.append(self._parse_race(market))\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market['marketId']\n        event = market['event']\n        start_time = datetime.fromisoformat(market['marketStartTime'].replace('Z', '+00:00'))\n\n        runners = [\n            Runner(\n                number=runner.get('sortPriority', i + 1),\n                name=runner['runnerName'],\n                scratched=runner['status'] != 'ACTIVE',\n                selection_id=runner['selectionId']\n            )\n            for i, runner in enumerate(market.get('runners', []))\n        ]\n\n        return Race(\n            id=f\"bf_{market_id}\",\n            venue=event.get('venue', 'Unknown Venue'),\n            race_number=self._extract_race_number(market.get('marketName', '')),\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME\n        )",
    "python_service/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass RacingAndSportsAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"Racing and Sports\", base_url=\"https://api.racingandsports.com.au/\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        all_races: List[Race] = []\n        headers = {\"Authorization\": f\"Bearer {self.api_token}\", \"Accept\": \"application/json\"}\n\n        if not self.api_token:\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"ConfigurationError: Token not set\"\n            )\n\n        try:\n            meetings_url = \"v1/racing/meetings\"\n            params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n            meetings_data = await self.make_request(http_client, \"GET\", meetings_url, headers=headers, params=params)\n\n            if not meetings_data or not meetings_data.get(\"meetings\"):\n                return self._format_response(all_races, start_time, is_success=True)\n\n            for meeting in meetings_data[\"meetings\"]:\n                for race_summary in meeting.get(\"races\", []):\n                    try:\n                        parsed_race = self._parse_ras_race(meeting, race_summary)\n                        all_races.append(parsed_race)\n                    except Exception as e:\n                        log.error(\n                            \"RacingAndSportsAdapter: Failed to parse race\",\n                            meeting=meeting.get(\"venueName\"),\n                            error=str(e),\n                            exc_info=True,\n                        )\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"RacingAndSportsAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(\"RacingAndSportsAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Race:\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\"),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n        ]\n\n        return Race(\n            id=f\"ras_{race.get('raceId')}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race.get(\"raceNumber\"),\n            start_time=datetime.fromisoformat(race.get(\"startTime\")),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/base_v3.py": "# python_service/adapters/base_v3.py\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import AsyncGenerator, Any, List\n\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter # Inherit to retain retry logic, logging, circuit breaker state, etc.\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    An architecturally superior abstract base class for data adapters.\n\n    This class enforces a rigid, standardized implementation pattern by requiring all\n    subclasses to implement their own `_fetch_data` and `_parse_races` methods.\n    It also includes a built-in circuit breaker to enhance resilience.\n    \"\"\"\n    def __init__(self, source_name: str, base_url: str, timeout: int = 20, max_retries: int = 3):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.timeout = timeout\n        self.max_retries = max_retries\n        self.logger = structlog.get_logger(adapter_name=source_name)\n        # Circuit Breaker State\n        self.circuit_breaker_tripped = False\n        self.circuit_breaker_failure_count = 0\n        self.circuit_breaker_last_failure = 0\n        self.FAILURE_THRESHOLD = 3\n        self.COOLDOWN_PERIOD_SECONDS = 300  # 5 minutes\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should interact with the network.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data fetched by _fetch_data into a list of Race objects.\n        This method should be pure and contain no network logic.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        The public-facing method to get races. Orchestrates the fetch and parse process.\n        Includes a circuit breaker to prevent repeated calls to a failing adapter.\n        Subclasses should NOT override this method.\n        \"\"\"\n        # Check Circuit Breaker state\n        if self.circuit_breaker_tripped:\n            if time.time() - self.circuit_breaker_last_failure < self.COOLDOWN_PERIOD_SECONDS:\n                self.logger.warning(f\"Circuit breaker for {self.SOURCE_NAME} is tripped. Skipping fetch.\")\n                return\n            else:\n                self.logger.info(f\"Cooldown period for {self.SOURCE_NAME} has passed. Resetting circuit breaker.\")\n                self.circuit_breaker_failure_count = 0\n                self.circuit_breaker_tripped = False\n\n        try:\n            raw_data = await self._fetch_data(date)\n            if raw_data is None:\n                self.logger.warning(f\"Fetching data for {self.SOURCE_NAME} on {date} returned None.\")\n                return\n\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n            # Reset failure count on success\n            self.circuit_breaker_failure_count = 0\n\n        except Exception:\n            self.logger.error(\n                f\"An unexpected error occurred in the get_races pipeline for {self.SOURCE_NAME}.\",\n                exc_info=True\n            )\n            # Handle circuit breaker logic on failure\n            self.circuit_breaker_failure_count += 1\n            self.circuit_breaker_last_failure = time.time()\n            if self.circuit_breaker_failure_count >= self.FAILURE_THRESHOLD:\n                self.circuit_breaker_tripped = True\n                self.logger.critical(f\"Circuit breaker for {self.SOURCE_NAME} has been tripped after {self.FAILURE_THRESHOLD} failures.\")\n            return\n",
    "python_service/adapters/betfair_datascientist_adapter.py": "# python_service/adapters/betfair_datascientist_adapter.py\n\nfrom datetime import datetime\nfrom io import StringIO\nfrom typing import Any\nfrom typing import List\n\nimport pandas as pd\nimport requests\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.text import normalize_course_name\nfrom .base_v3 import BaseAdapterV3\n\n\nclass BetfairDataScientistAdapter(BaseAdapterV3):\n    ADAPTER_NAME = \"BetfairDataScientist\"\n\n    def __init__(self, model_name: str, url: str, enabled: bool = True, priority: int = 100, config=None):\n        source_name = f\"{self.ADAPTER_NAME}_{model_name}\"\n        super().__init__(source_name=source_name, base_url=url)\n        self.model_name = model_name\n        self.url = url\n        self._enabled = enabled\n        self._priority = priority\n        self.config = config\n\n    async def _fetch_data(self, date: str) -> Any:\n        if not self._enabled:\n            self.logger.debug(f\"Adapter '{self.source_name}' is disabled. Skipping.\")\n            return None\n\n        try:\n            full_url = self._build_url(date)\n            self.logger.info(f\"Fetching data from {full_url}\")\n            response = await asyncio.to_thread(requests.get, full_url)\n            response.raise_for_status()\n            return StringIO(response.text)\n        except Exception as e:\n            self.logger.error(f\"An unexpected error in {self.source_name}: {e}\", exc_info=True)\n            return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        df = pd.read_csv(raw_data)\n        df = df.rename(\n            columns={\n                \"meetings.races.bfExchangeMarketId\": \"market_id\",\n                \"meetings.races.runners.bfExchangeSelectionId\": \"selection_id\",\n                \"meetings.races.runners.ratedPrice\": \"rated_price\",\n                \"meetings.races.raceName\": \"race_name\",\n                \"meetings.name\": \"meeting_name\",\n                \"meetings.races.raceNumber\": \"race_number\",\n                \"meetings.races.runners.runnerName\": \"runner_name\",\n                \"meetings.races.runners.clothNumber\": \"saddle_cloth\",\n            }\n        )\n        races = []\n        for market_id, group in df.groupby(\"market_id\"):\n            race_info = group.iloc[0]\n            runners = [\n                Runner(\n                    name=str(row.get(\"runner_name\")),\n                    number=int(row.get(\"saddle_cloth\", 0)),\n                    odds=float(row.get(\"rated_price\", 0.0)),\n                )\n                for _, row in group.iterrows()\n            ]\n            race = Race(\n                id=str(market_id),\n                venue=normalize_course_name(str(race_info.get(\"meeting_name\", \"\"))),\n                race_number=int(race_info.get(\"race_number\", 0)),\n                start_time=datetime.now(),\n                runners=runners,\n                source=self.source_name,\n            )\n            races.append(race)\n        self.logger.info(f\"Normalized {len(races)} races from {self.model_name}.\")\n        return races\n\n    def _build_url(self, date: str) -> str:\n        return f\"{self.url}{date}&presenter=RatingsPresenter&csv=true\"\n",
    "python_service/adapters/pointsbet_greyhound_adapter.py": "# python_service/adapters/pointsbet_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass PointsBetGreyhoundAdapter(BaseAdapter):\n    \"\"\"TODO: This is a placeholder adapter. It will not be active until the correct sportId is found.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"PointsBet Greyhound\", base_url=\"https://api.au.pointsbet.com\")\n        self.api_key = config.POINTSBET_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        # TODO: This adapter is a placeholder and is not registered in the engine.\n        # To enable, find the correct sportId for Greyhound Racing and register the adapter.\n        log.warning(\"PointsBetGreyhoundAdapter: This adapter is a non-functional placeholder.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Adapter is a placeholder.\")\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n",
    "python_service/adapters/__init__.py": "# python_service/adapters/__init__.py\n\nfrom .at_the_races_adapter import AtTheRacesAdapter\nfrom .betfair_adapter import BetfairAdapter\nfrom .betfair_greyhound_adapter import BetfairGreyhoundAdapter\nfrom .gbgb_api_adapter import GbgbApiAdapter\nfrom .greyhound_adapter import GreyhoundAdapter\nfrom .harness_adapter import HarnessAdapter\nfrom .pointsbet_greyhound_adapter import PointsBetGreyhoundAdapter\nfrom .racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .racing_and_sports_greyhound_adapter import RacingAndSportsGreyhoundAdapter\nfrom .sporting_life_adapter import SportingLifeAdapter\nfrom .the_racing_api_adapter import TheRacingApiAdapter\nfrom .timeform_adapter import TimeformAdapter\nfrom .tvg_adapter import TVGAdapter\n\n# Define the public API for the adapters package, making it easy for the\n# orchestrator to discover and use them.\n__all__ = [\n    \"GbgbApiAdapter\",\n    \"TVGAdapter\",\n    \"BetfairAdapter\",\n    \"BetfairGreyhoundAdapter\",\n    \"RacingAndSportsGreyhoundAdapter\",\n    \"AtTheRacesAdapter\",\n    \"PointsBetGreyhoundAdapter\",\n    \"RacingAndSportsAdapter\",\n    \"SportingLifeAdapter\",\n    \"TimeformAdapter\",\n    \"HarnessAdapter\",\n    \"GreyhoundAdapter\",\n    \"TheRacingApiAdapter\",\n]\n",
    "python_service/adapters/oddschecker_adapter.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Oddschecker Adapter (Canonized)\n# ==============================================================================\n# This adapter was sourced from the 'Live Odds Anthology' and has been modernized\n# to conform to the project's current BaseAdapter framework.\n# ==============================================================================\n\nimport asyncio\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddscheckerAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping live horse racing odds from Oddschecker.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"Oddschecker\", base_url=\"https://www.oddschecker.com\")\n        self.config = config\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            meeting_links = await self._get_all_meeting_links(http_client)\n            if not meeting_links:\n                return self._format_response([], start_time, is_success=True, error_message=\"No meeting links found.\")\n\n            tasks = [self._fetch_single_meeting(link, http_client) for link in meeting_links]\n            races_from_all_meetings = await asyncio.gather(*tasks)\n\n            all_races = [race for sublist in races_from_all_meetings for race in sublist if race]\n            return self._format_response(all_races, start_time)\n        except Exception as e:\n            log.error(\"OddscheckerAdapter failed\", exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_all_meeting_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        html = await self.make_request(http_client, \"GET\", \"/horse-racing\")\n        soup = BeautifulSoup(html, \"html.parser\")\n        links = {self.base_url + a[\"href\"] for a in soup.select(\"a.meeting-title[href]\")}\n        return sorted(list(links))\n\n    async def _fetch_single_meeting(self, url: str, client: httpx.AsyncClient) -> List[Optional[Race]]:\n        try:\n            html = await self.make_request(client, \"GET\", url.replace(self.base_url, \"\"))\n            soup = BeautifulSoup(html, \"html.parser\")\n            race_links = {self.base_url + a[\"href\"] for a in soup.select(\"a.race-time-link[href]\")}\n            tasks = [self._fetch_and_parse_race_card(link, client) for link in race_links]\n            return await asyncio.gather(*tasks)\n        except Exception as e:\n            log.error(\"Oddschecker failed to fetch meeting\", url=url, error=e)\n            return []\n\n    async def _fetch_and_parse_race_card(self, url: str, client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            html = await self.make_request(client, \"GET\", url.replace(self.base_url, \"\"))\n            soup = BeautifulSoup(html, \"html.parser\")\n            return self._parse_race_page(soup, url)\n        except Exception as e:\n            log.error(\"Oddschecker failed to parse race card\", url=url, error=e)\n            return None\n\n    def _parse_race_page(self, soup: BeautifulSoup, url: str) -> Optional[Race]:\n        track_name = (\n            soup.select_one(\"h1.meeting-name\").get_text(strip=True) if soup.select_one(\"h1.meeting-name\") else \"Unknown\"\n        )\n        race_time_str = (\n            soup.select_one(\"span.race-time\").get_text(strip=True) if soup.select_one(\"span.race-time\") else None\n        )\n        race_number = int(url.split(\"-\")[-1]) if \"race-\" in url else 0\n\n        runners = []\n        for row in soup.select(\"tr.race-card-row\"):\n            runner = self._parse_runner_row(row)\n            if runner:\n                runners.append(runner)\n\n        if not runners:\n            return None\n\n        start_time = datetime.now()  # Default to now\n        if race_time_str:\n            try:\n                today_str = datetime.now().strftime(\"%Y-%m-%d\")\n                start_time = datetime.strptime(f\"{today_str} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            except ValueError:\n                log.warning(\"Could not parse race time\", time_str=race_time_str)\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{start_time.strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        name_tag = row.select_one(\"span.selection-name\")\n        name = name_tag.get_text(strip=True) if name_tag else None\n        odds_tag = row.select_one(\"span.bet-button-odds-desktop, span.best-price\")\n        odds_str = odds_tag.get_text(strip=True) if odds_tag else None\n        number_tag = row.select_one(\"td.runner-number\")\n        number = int(number_tag.get_text(strip=True)) if number_tag else 0\n\n        if not name or not odds_str:\n            return None\n\n        odds_val = parse_odds(odds_str)\n        odds_dict = {}\n        if odds_val:\n            odds_dict[self.source_name] = OddsData(\n                win=Decimal(str(odds_val)), source=self.source_name, last_updated=datetime.now()\n            )\n\n        return Runner(number=number, name=name, odds=odds_dict)\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": [r.model_dump() for r in races],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n",
    "python_service/adapters/racing_and_sports_greyhound_adapter.py": "# python_service/adapters/racing_and_sports_greyhound_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass RacingAndSportsGreyhoundAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"Racing and Sports Greyhound\", base_url=\"https://api.racingandsports.com.au/\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        all_races: List[Race] = []\n        headers = {\"Authorization\": f\"Bearer {self.api_token}\", \"Accept\": \"application/json\"}\n\n        if not self.api_token:\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"ConfigurationError: Token not set\"\n            )\n\n        try:\n            # HYPOTHESIS: The greyhound endpoint is parallel to the racing one.\n            meetings_url = \"v1/greyhound/meetings\"\n            params = {\"date\": date, \"jurisdiction\": \"AUS\"}  # Jurisdiction may need to be adjusted\n            meetings_data = await self.make_request(http_client, \"GET\", meetings_url, headers=headers, params=params)\n\n            if not meetings_data or not meetings_data.get(\"meetings\"):\n                return self._format_response(\n                    all_races, start_time, is_success=True, error_message=\"No greyhound meetings found.\"\n                )\n\n            for meeting in meetings_data[\"meetings\"]:\n                for race_summary in meeting.get(\"races\", []):\n                    try:\n                        parsed_race = self._parse_ras_race(meeting, race_summary)\n                        all_races.append(parsed_race)\n                    except Exception as e:\n                        log.error(\n                            \"RacingAndSportsGreyhoundAdapter: Failed to parse race\",\n                            meeting=meeting.get(\"venueName\"),\n                            error=str(e),\n                            exc_info=True,\n                        )\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"RacingAndSportsGreyhoundAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(\"RacingAndSportsGreyhoundAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Race:\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\"),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n        ]\n\n        return Race(\n            id=f\"rasg_{race.get('raceId')}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race.get(\"raceNumber\"),\n            start_time=datetime.fromisoformat(race.get(\"startTime\")),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass AtTheRacesAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"AtTheRaces\", base_url=\"https://www.attheraces.com\", config=config)\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            log.error(f\"Error fetching races from AtTheRaces: {e}\", exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response = await self.make_request(http_client, \"GET\", \"/racecards\")\n        if not response:\n            return []\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        links = {a[\"href\"] for a in soup.select(\"a.race-time-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response = await self.make_request(http_client, \"GET\", url)\n            if response is None:\n                return None\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            header = soup.select_one(\"h1.heading-racecard-title\").get_text()\n            track_name_raw, race_time = [p.strip() for p in header.split(\"|\")[:2]]\n            track_name = normalize_venue_name(track_name_raw)\n            active_link = soup.select_one(\"a.race-time-link.active\")\n            race_number = active_link.find_parent(\"div\", \"races\").select(\"a.race-time-link\").index(active_link) + 1\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time}\", \"%Y-%m-%d %H:%M\")\n            runners = [self._parse_runner(row) for row in soup.select(\"div.card-horse\")]\n            return Race(\n                id=f\"atr_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                venue=track_name,\n                race_number=race_number,\n                start_time=start_time,\n                runners=[r for r in runners if r],\n                source=self.source_name,\n            )\n        except Exception as e:\n            log.error(\"Error parsing race from AtTheRaces\", url=url, exc_info=e)\n            return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = clean_text(row.select_one(\"h3.horse-name a\").get_text())\n            num_str = clean_text(row.select_one(\"span.horse-number\").get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n            odds_str = clean_text(row.select_one(\"button.best-odds\").get_text())\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())}\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except Exception as e:\n            log.warning(\"Failed to parse runner\", exc_info=e)\n            return None\n",
    "python_service/adapters/greyhound_adapter.py": "from datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom pydantic import ValidationError\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass GreyhoundAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching Greyhound racing data. Activated by setting GREYHOUND_API_URL in .env\"\"\"\n\n    def __init__(self, config):\n        if not config.GREYHOUND_API_URL:\n            raise ValueError(\"GreyhoundAdapter cannot be initialized without GREYHOUND_API_URL.\")\n        super().__init__(source_name=\"Greyhound Racing\", base_url=config.GREYHOUND_API_URL, config=config)\n        # Example for future use: self.api_key = config.GREYHOUND_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        \"\"\"Fetches upcoming greyhound races for the specified date.\"\"\"\n        start_time = datetime.now()\n        endpoint = f\"v1/cards/{date}\"  # Using date parameter\n        try:\n            response = await self.make_request(http_client, \"GET\", endpoint)\n            if not response:\n                log.warning(\"GreyhoundAdapter: No response from make_request.\")\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No data received from provider.\"\n                )\n\n            response_json = response.json()\n            if not response_json or not response_json.get(\"cards\"):\n                log.warning(\"GreyhoundAdapter: No 'cards' in response or empty list.\")\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No race cards found for date.\"\n                )\n\n            all_races = self._parse_cards(response_json[\"cards\"])\n            if not all_races:\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"Races found, but none could be parsed.\"\n                )\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"GreyhoundAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(\"GreyhoundAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {str(e)}\"\n            )\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n\n    def _parse_cards(self, cards: List[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses a list of cards and their races into Race objects.\"\"\"\n        all_races = []\n        if cards is None:\n            return all_races\n        for card in cards:\n            venue = card.get(\"track_name\", \"Unknown Venue\")\n            races_data = card.get(\"races\", [])\n            for race_data in races_data:\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race = Race(\n                        id=f\"greyhound_{race_data['race_id']}\",\n                        venue=venue,\n                        race_number=race_data[\"race_number\"],\n                        start_time=datetime.fromtimestamp(race_data[\"start_time\"]),\n                        runners=self._parse_runners(race_data[\"runners\"]),\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    log.error(\n                        f\"GreyhoundAdapter: Error parsing race {race_data.get('race_id', 'N/A')}\",\n                        error=str(e),\n                        race_data=race_data,\n                    )\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                if runner_data.get(\"scratched\", False):\n                    continue\n\n                odds_data = {}\n                # The directive's example was flawed. Correcting to a more realistic structure.\n                win_odds_val = runner_data.get(\"odds\", {}).get(\"win\")\n                if win_odds_val is not None:\n                    win_odds = Decimal(str(win_odds_val))\n                    if win_odds > 1:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds, source=self.source_name, last_updated=datetime.now()\n                        )\n\n                runner = Runner(\n                    number=runner_data[\"trap_number\"],\n                    name=runner_data[\"dog_name\"],\n                    scratched=runner_data.get(\"scratched\", False),\n                    odds=odds_data,\n                )\n                runners.append(runner)\n            except (KeyError, ValidationError) as e:\n                log.error(\"GreyhoundAdapter: Error parsing runner\", error=str(e), runner_data=runner_data)\n        return runners\n",
    "python_service/adapters/tab_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass TabAdapter(BaseAdapter):\n    \"\"\"Adapter for tab.com.au.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"TAB\", base_url=\"https://www.tab.com.au\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"TabAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {\n            \"races\": [],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\",\n                \"races_fetched\": 0,\n                \"error_message\": \"Not Implemented\",\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/brisnet_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\n\nimport httpx\nimport structlog\n\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass BrisnetAdapter(BaseAdapter):\n    \"\"\"Adapter for brisnet.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"Brisnet\", base_url=\"https://www.brisnet.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"BrisnetAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")\n",
    "python_service/adapters/template_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# ==============================================================================\n#  Fortuna Faucet: Canonical Adapter Template\n# ==============================================================================\n# This file is the official template for creating new adapters. It is based on\n# the clean and simple design of the RacingAndSportsAdapter.\n# ==============================================================================\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race  # Assuming standard models\nfrom ..models import Runner  # Assuming standard models\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass TemplateAdapter(BaseAdapter):\n    \"\"\"[IMPLEMENT ME] A brief description of the data source.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"[IMPLEMENT ME] Example Source\", base_url=\"https://api.example.com\")\n        # self.api_key = config.EXAMPLE_API_KEY # Uncomment if needed\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        \"\"\"[IMPLEMENT ME] The core logic for fetching and parsing races.\"\"\"\n        start_time = datetime.now()\n        all_races: List[Race] = []\n\n        # --- Example Logic ---\n        # endpoint = f\"/v1/races/{date}\"\n        # headers = {\"X-Api-Key\": self.api_key}\n        # response_json = await self.make_request(http_client, 'GET', endpoint, headers=headers)\n        # if not response_json or 'data' not in response_json:\n        #     return self._format_response(all_races, start_time)\n        #\n        # for race_data in response_json['data']:\n        #     parsed_race = self._parse_race(race_data)\n        #     all_races.append(parsed_race)\n        # --- End Example ---\n\n        log.warning(\"TemplateAdapter.fetch_races is a stub and is not implemented.\")\n        return self._format_response(all_races, start_time)\n\n    def _parse_race(self, race_data: Dict[str, Any]) -> Race:\n        \"\"\"[IMPLEMENT ME] Logic to parse a single race from the source's data structure.\"\"\"\n        # Example:\n        # runners = self._parse_runners(race_data.get('runners', []))\n        # return Race(\n        #     id=f\"template_{race_data['id']}\",\n        #     venue=race_data['venue_name'],\n        #     race_number=race_data['race_number'],\n        #     start_time=datetime.fromisoformat(race_data['start_time']),\n        #     runners=runners,\n        #     source=self.source_name\n        # )\n        raise NotImplementedError(\"'_parse_race' is not implemented in TemplateAdapter.\")\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"[IMPLEMENT ME] Logic to parse a list of runners.\"\"\"\n        raise NotImplementedError(\"'_parse_runners' is not implemented in TemplateAdapter.\")\n",
    "python_service/adapters/universal_adapter.py": "import json\nfrom typing import Any\nfrom typing import Dict\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\n\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass UniversalAdapter(BaseAdapter):\n    \"\"\"An adapter that executes logic from a declarative JSON definition file.\"\"\"\n\n    def __init__(self, config, definition_path: str):\n        with open(definition_path, \"r\") as f:\n            self.definition = json.load(f)\n\n        super().__init__(source_name=self.definition[\"adapter_name\"], base_url=self.definition[\"base_url\"])\n        self.config = config\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        # NOTE: This is a simplified proof-of-concept implementation.\n        # It does not handle all cases from the JSON definition.\n        log.info(f\"Executing Universal Adapter for {self.source_name}\")\n\n        # Step 1: Get Track Links (as defined in equibase_v2.json)\n        response = await self.make_request(http_client, \"GET\", self.definition[\"start_url\"])\n        soup = BeautifulSoup(response, \"html.parser\")\n        track_links = [self.base_url + a[\"href\"] for a in soup.select(self.definition[\"steps\"][0][\"selector\"])]\n\n        for link in track_links:\n            try:\n                track_response = await self.make_request(http_client, \"GET\", link.replace(self.base_url, \"\"))\n                track_soup = BeautifulSoup(track_response, \"html.parser\")\n                track_soup.select(self.definition[\"steps\"][1][\"list_selector\"])\n\n            except Exception as e:\n                log.error(\"Failed to process track link\", link=link, error=e)\n\n        # This is a placeholder return for the PoC\n        return {\n            \"races\": [],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\",\n                \"races_fetched\": 0,\n                \"error_message\": \"PoC Complete\",\n                \"fetch_duration\": 0.0,\n            },\n        }\n",
    "python_service/adapters/tvg_adapter.py": "# python_service/adapters/tvg_adapter.py\nfrom datetime import datetime\nfrom typing import Any, List, Optional\n\nfrom ..models import Race, Runner\nfrom ..utils.text import clean_text\nfrom .base_v3 import BaseAdapterV3\n\nclass TVGAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US racing data from the TVG API, using BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"TVG\"\n    BASE_URL = \"https://api.tvg.com/v2/races/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL)\n        self.config = config or {}\n        self.tvg_api_key = self.config.TVG_API_KEY\n        if not self.tvg_api_key:\n            self.logger.warning(\"TVG_API_KEY is not set. Adapter will be non-functional.\")\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches all race details for a given date by first getting tracks.\"\"\"\n        if not self.tvg_api_key:\n            return None\n\n        headers = {\"X-Api-Key\": self.tvg_api_key}\n        tracks_response = await self.http_client.get(f\"{self.BASE_URL}summary?date={date}&country=USA\", headers=headers)\n        tracks_response.raise_for_status()\n        tracks_data = tracks_response.json()\n\n        all_race_details = []\n        for track in tracks_data.get('tracks', []):\n            track_id = track.get('id')\n            for race in track.get('races', []):\n                race_id = race.get('id')\n                if track_id and race_id:\n                    details_response = await self.http_client.get(f\"{self.BASE_URL}{track_id}/{race_id}\", headers=headers)\n                    if details_response.status_code == 200:\n                        all_race_details.append(details_response.json())\n        return all_race_details\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the list of detailed race JSON objects into Race models.\"\"\"\n        races = []\n        for race_detail in raw_data:\n            try:\n                track = race_detail.get('track', {})\n                race_info = race_detail.get('race', {})\n\n                runners = []\n                for runner_data in race_detail.get('runners', []):\n                    if runner_data.get('scratched'):\n                        continue\n\n                    odds = runner_data.get('odds', {})\n                    current_odds = odds.get('currentPrice', {})\n                    odds_str = current_odds.get('fractional') or odds.get('morningLinePrice', {}).get('fractional')\n\n                    runners.append(Runner(\n                        number=int(runner_data.get('programNumber', '0').replace('A', '')),\n                        name=clean_text(runner_data.get('name')),\n                        odds=odds_str,\n                        scratched=False\n                    ))\n\n                if runners:\n                    race = Race(\n                        id=f\"tvg_{track.get('code', 'UNK')}_{race_info.get('date', 'NODATE')}_{race_info.get('number', 0)}\",\n                        venue=track.get('name'),\n                        race_number=race_info.get('number'),\n                        start_time=datetime.fromisoformat(race_info.get('postTime').replace('Z', '+00:00')),\n                        runners=runners,\n                        source=self.SOURCE_NAME\n                    )\n                    races.append(race)\n            except (ValueError, AttributeError):\n                self.logger.warning(\"Failed to parse a TVG race detail.\", exc_info=True)\n                continue\n        return races\n\n    async def fetch_races(self, date: str, http_client):\n        pass\n",
    "python_service/adapters/drf_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\n\nimport httpx\nimport structlog\n\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass DRFAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping data from drf.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"DRF\", base_url=\"https://www.drf.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"DRFAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")\n",
    "python_service/adapters/racingtv_adapter.py": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass RacingTVAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping data from racingtv.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"RacingTV\", base_url=\"https://www.racingtv.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"RacingTVAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {\n            \"races\": [],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\",\n                \"races_fetched\": 0,\n                \"error_message\": \"Not Implemented\",\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/base.py": "# python_service/adapters/base.py\nimport httpx\nimport structlog\nfrom tenacity import AsyncRetrying, stop_after_attempt, wait_exponential\n\nclass BaseAdapter:\n    \"\"\"The base class for all data adapters, now with enhanced error handling.\"\"\"\n\n    def __init__(self, source_name: str, base_url: str = \"\", config: dict = None):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.config = config or {}\n        self.logger = structlog.get_logger(self.__class__.__name__)\n        self.retryer = AsyncRetrying(\n            stop=stop_after_attempt(3),\n            wait=wait_exponential(multiplier=1, min=2, max=10)\n        )\n        # Circuit Breaker State\n        self.circuit_breaker_tripped = False\n        self.circuit_breaker_failure_count = 0\n        self.circuit_breaker_last_failure = 0\n        self.FAILURE_THRESHOLD = 3\n        self.COOLDOWN_PERIOD_SECONDS = 300  # 5 minutes\n\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs):\n        full_url = url if url.startswith('http') else f\"{self.base_url}{url}\"\n\n        async def _make_request():\n            response = await http_client.request(method, full_url, **kwargs)\n            response.raise_for_status()\n            # Note: Previously, this returned response.json(), but that prevents\n            # the Timeform adapter from reading .text for HTML parsing.\n            # Returning the full response object is more flexible.\n            return response\n\n        try:\n            async for attempt in self.retryer:\n                with attempt:\n                    return await _make_request()\n        except httpx.HTTPStatusError as e:\n            self.logger.error(\n                \"http_error\",\n                adapter=self.source_name,\n                status_code=e.response.status_code,\n                url=full_url,\n            )\n            self._show_windows_toast(\n                \"Adapter HTTP Error\", f\"{self.source_name}: Received status {e.response.status_code} from {full_url}\"\n            )\n            return None\n        except httpx.RequestError as e:\n            self.logger.error(\"request_error\", adapter=self.source_name, error=str(e), url=full_url)\n            self._show_windows_toast(\"Adapter Network Error\", f\"{self.source_name}: Could not connect to {full_url}\")\n            return None\n        except Exception as e:\n            self.logger.error(\"unexpected_adapter_error\", adapter=self.source_name, error=str(e), exc_info=True)\n            self._show_windows_toast(\"Adapter Unexpected Error\", f\"{self.source_name}: An unknown error occurred.\")\n            return None\n\n    def _show_windows_toast(self, title: str, message: str):\n        try:\n            from windows_toasts import Toast, WindowsToaster\n            toaster = WindowsToaster(title)\n            new_toast = Toast()\n            new_toast.text_fields = [message]\n            toaster.show_toast(new_toast)\n        except (ImportError, RuntimeError):\n            # Fail silently if not on Windows or if notifier fails\n            pass",
    "python_service/adapters/fanduel_adapter.py": "# python_service/adapters/fanduel_adapter.py\n\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger()\n\n\nclass FanDuelAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching horse racing odds from FanDuel's private API.\"\"\"\n\n    source_name = \"FanDuel\"\n    API_URL = \"https://sb-api.nj.sportsbook.fanduel.com/api/markets?_ak=Fh2e68s832c41d4b&eventId=\"\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> List[Race]:\n        \"\"\"Fetches races for a given date. Note: FanDuel API is event-based, not date-based.\"\"\"\n        # This is a placeholder for a more robust event discovery mechanism.\n        # For now, we'll use a known event ID for a major race day as a proof of concept.\n        # A full implementation would need to first find the relevant event IDs for the day.\n        event_id = \"38183.3\"  # Example: A major race event\n\n        log.info(\"Fetching races from FanDuel\", event_id=event_id)\n        start_time = datetime.now()\n        try:\n            response = await http_client.get(self.API_URL + event_id)\n            response.raise_for_status()\n            data = response.json()\n            races = self._parse_races(data)\n            return self._format_response(races, start_time, is_success=True)\n        except httpx.HTTPStatusError as e:\n            log.error(\"FanDuel API request failed\", status_code=e.response.status_code, response=e.response.text)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n        except Exception as e:\n            log.error(\"An unexpected error occurred fetching FanDuel data\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    def _parse_races(self, data: Dict[str, Any]) -> List[Race]:\n        races = []\n        if \"marketGroups\" not in data:\n            log.warning(\"FanDuel response missing 'marketGroups' key\")\n            return []\n\n        for group in data[\"marketGroups\"]:\n            if group.get(\"marketGroupName\") == \"Win\":\n                for market in group.get(\"markets\", []):\n                    try:\n                        race = self._parse_single_race(market)\n                        if race:\n                            races.append(race)\n                    except Exception as e:\n                        log.error(\"Failed to parse a FanDuel market\", market=market, error=str(e), exc_info=True)\n        return races\n\n    def _parse_single_race(self, market: Dict[str, Any]) -> Race | None:\n        market_name = market.get(\"marketName\", \"\")\n        if not market_name.startswith(\"Race\"):\n            return None\n\n        # Extract race number and track from market name (e.g., \"Race 5 - Churchill Downs\")\n        parts = market_name.split(\" - \")\n        if len(parts) < 2:\n            return None\n\n        race_number_str = parts[0].replace(\"Race \", \"\")\n        track_name = parts[1]\n\n        # Placeholder for start_time - FanDuel's market API doesn't provide it directly\n        start_time = datetime.now(timezone.utc) + timedelta(hours=int(race_number_str))\n\n        runners = []\n        for runner_data in market.get(\"runners\", []):\n            runner_name = runner_data.get(\"runnerName\")\n            win_odds = runner_data.get(\"winRunnerOdds\", {}).get(\"currentPrice\")\n            if not runner_name or not win_odds:\n                continue\n\n            try:\n                # Price is given as a fraction string, e.g., \"12/5\"\n                numerator, denominator = map(int, win_odds.split(\"/\"))\n                decimal_odds = Decimal(numerator) / Decimal(denominator) + 1\n            except (ValueError, ZeroDivisionError):\n                log.warning(\"Could not parse FanDuel odds\", odds_str=win_odds, runner=runner_name)\n                continue\n\n            odds = OddsData(win=decimal_odds, source=self.source_name, last_updated=datetime.now(timezone.utc))\n\n            # Placeholder for program number\n            program_number_str = runner_name.split(\".\")[0].strip()\n\n            runner = Runner(\n                name=runner_name.split(\".\")[1].strip(),\n                number=int(program_number_str) if program_number_str.isdigit() else None,\n                odds={self.source_name: odds},\n            )\n            runners.append(runner)\n\n        if not runners:\n            return None\n\n        race_id = f\"FD-{track_name.replace(' ', '')[:5].upper()}-{start_time.strftime('%Y%m%d')}-R{race_number_str}\"\n\n        return Race(\n            id=race_id,\n            venue=track_name,\n            race_number=int(race_number_str),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/harness_adapter.py": "# python_service/adapters/harness_adapter.py\nfrom datetime import datetime\nfrom typing import AsyncGenerator\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\n\nclass HarnessAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching US harness racing data from data.ustrotting.com.\"\"\"\n\n    SOURCE_NAME = \"USTrotting\"\n    BASE_URL = \"https://data.ustrotting.com/api/racenet/racing/\"\n\n    def __init__(self, config=None):\n        super().__init__(self.SOURCE_NAME, self.BASE_URL)\n\n    async def fetch_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"Fetches all harness races for a given date.\"\"\"\n        card_data = await self.make_request(method=\"get\", url=f\"{self.BASE_URL}card/{date}\")\n        if not card_data or not card_data.get(\"meetings\"):\n            return\n\n        for meeting in card_data[\"meetings\"]:\n            track_name = meeting.get(\"track\", {}).get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                yield self._parse_race(race_data, track_name, date)\n\n    def _parse_race(self, race_data: dict, track_name: str, date: str) -> Race:\n        \"\"\"Parses a single race from the USTA API into a Race object.\"\"\"\n        race_number = race_data.get(\"raceNumber\", 0)\n        post_time_str = race_data.get(\"postTime\", \"00:00 AM\")\n        start_time = self._parse_post_time(date, post_time_str)\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            odds_str = runner_data.get(\"morningLineOdds\", \"\")\n            # Ensure odds are fractional for parsing\n            if \"/\" not in odds_str and odds_str.isdigit():\n                odds_str = f\"{odds_str}/1\"\n\n            odds = {}\n            win_odds = parse_odds_to_decimal(odds_str)\n            if win_odds and win_odds < 999:\n                odds = {self.SOURCE_NAME: OddsData(win=win_odds, source=self.SOURCE_NAME, last_updated=datetime.now())}\n\n            runners.append(\n                Runner(\n                    number=runner_data.get(\"postPosition\", 0),\n                    name=runner_data.get(\"horse\", {}).get(\"name\", \"Unknown Horse\"),\n                    odds=odds,\n                    scratched=runner_data.get(\"scratched\", False),\n                )\n            )\n\n        return Race(\n            id=f\"ust_{track_name.lower().replace(' ', '')}_{date}_{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date: str, post_time: str) -> datetime:\n        \"\"\"Parses a time string like '07:00 PM' into a timezone-aware datetime object.\"\"\"\n        from zoneinfo import ZoneInfo\n\n        dt_str = f\"{date} {post_time}\"\n        naive_dt = datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n        # Assume Eastern Time for USTA data, a common standard for US racing.\n        eastern = ZoneInfo(\"America/New_York\")\n        return naive_dt.replace(tzinfo=eastern)\n",
    "python_service/adapters/equibase_adapter.py": "# python_service/adapters/equibase_adapter.py\nfrom datetime import datetime\nfrom typing import AsyncGenerator\n\nfrom selectolax.parser import HTMLParser\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom .base import BaseAdapter\n\n\nclass EquibaseAdapter(BaseAdapter):\n    \"\"\"A production-ready adapter for scraping Equibase race entries.\"\"\"\n\n    SOURCE_NAME = \"Equibase\"\n    BASE_URL = \"https://www.equibase.com\"\n\n    def __init__(self, config=None):\n        super().__init__(self.SOURCE_NAME, self.BASE_URL)\n\n    async def fetch_races(self, date_str: str, http_client) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        Fetches all US & Canadian races for a given date from equibase.com.\n        \"\"\"\n        entry_urls = await self._get_entry_urls(date_str, http_client)\n        for url in entry_urls:\n            try:\n                response = await http_client.get(url, headers=self._get_headers())\n                response.raise_for_status()\n                parser = HTMLParser(response.text)\n                race_links = parser.css(\"a.program-race-link\")\n                for link in race_links:\n                    race_url = f\"{self.BASE_URL}{link.attributes['href']}\"\n                    yield await self._parse_race(race_url, date_str, http_client)\n\n            except Exception:\n                # self.logger.error(f\"Failed to process entry page at {url}\", exc_info=True)\n                continue\n\n    async def _get_entry_urls(self, date_str: str, http_client) -> list[str]:\n        \"\"\"Gets all individual track entry page URLs for a given date.\"\"\"\n        d = datetime.strptime(date_str, \"%Y-%m-%d\").date()\n        url = f\"{self.BASE_URL}/entries/Entries.cfm?ELEC_DATE={d.month}/{d.day}/{d.year}&STYLE=EQB\"\n        response = await http_client.get(url, headers=self._get_headers())\n        parser = HTMLParser(response.text)\n        links = parser.css(\"div.track-information a\")\n        return [\n            f\"{self.BASE_URL}{link.attributes['href']}\"\n            for link in links\n            if \"race=\" not in link.attributes.get(\"href\", \"\")\n        ]\n\n    async def _parse_race(self, url: str, date_str: str, http_client) -> Race:\n        \"\"\"Parses a single race card page.\"\"\"\n        response = await http_client.get(url, headers=self._get_headers())\n        parser = HTMLParser(response.text)\n\n        venue = clean_text(parser.css_first(\"div.track-information strong\").text())\n        race_number = int(parser.css_first(\"div.race-information strong\").text().replace(\"Race\", \"\").strip())\n        post_time_str = parser.css_first(\"p.post-time span\").text().strip()\n        start_time = self._parse_post_time(date_str, post_time_str)\n\n        runners = []\n        runner_nodes = parser.css(\"table.entries-table tbody tr\")\n        for node in runner_nodes:\n            try:\n                number = int(node.css_first(\"td:nth-child(1)\").text(strip=True))\n                name = clean_text(node.css_first(\"td:nth-child(3)\").text())\n                odds_str = clean_text(node.css_first(\"td:nth-child(10)\").text())\n                scratched = \"scratched\" in node.attributes.get(\"class\", \"\").lower()\n\n                odds = {}\n                if not scratched:\n                    win_odds = parse_odds_to_decimal(odds_str)\n                    if win_odds and win_odds < 999:\n                        odds = {\n                            self.SOURCE_NAME: OddsData(\n                                win=win_odds, source=self.SOURCE_NAME, last_updated=datetime.now()\n                            )\n                        }\n\n                runners.append(Runner(number=number, name=name, odds=odds, scratched=scratched))\n            except (ValueError, AttributeError):\n                continue\n\n        return Race(\n            id=f\"eqb_{venue.lower().replace(' ', '')}_{date_str}_{race_number}\",\n            venue=venue,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date_str: str, time_str: str) -> datetime:\n        \"\"\"Parses a time string like 'Post Time: 12:30 PM ET' into a datetime object.\"\"\"\n        time_part = time_str.split(\" \")[-2] + \" \" + time_str.split(\" \")[-1]\n        dt_str = f\"{date_str} {time_part}\"\n        return datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n\n    def _get_headers(self) -> dict:\n        return {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/107.0.0.0 Safari/537.36\"\n            )\n        }\n",
    "python_service/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nfrom datetime import datetime\nfrom typing import Any, List\n\nfrom ..models import Race, Runner\nfrom .base_v3 import BaseAdapterV3\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapterV3):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API, using V3 architecture.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches the raw market catalogue for greyhound races on a given date.\"\"\"\n        await self._authenticate()\n        if not self.session_token:\n            self.logger.error(\"Authentication failed, cannot fetch data.\")\n            return None\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        return await self.make_request(\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\", \"AU\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\"from\": start_time.isoformat(), \"to\": end_time.isoformat()}\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"]\n            }\n        )\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the raw market catalogue into a list of Race objects.\"\"\"\n        if not raw_data:\n            return []\n\n        races = []\n        for market in raw_data:\n            try:\n                races.append(self._parse_race(market))\n            except (KeyError, TypeError):\n                self.logger.warning(\"Failed to parse a Betfair Greyhound market.\", exc_info=True, market=market)\n                continue\n        return races\n\n    def _parse_race(self, market: dict) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market['marketId']\n        event = market['event']\n        start_time = datetime.fromisoformat(market['marketStartTime'].replace('Z', '+00:00'))\n\n        runners = [\n            Runner(\n                number=runner.get('sortPriority', i + 1),\n                name=runner['runnerName'],\n                scratched=runner['status'] != 'ACTIVE',\n                selection_id=runner['selectionId']\n            )\n            for i, runner in enumerate(market.get('runners', []))\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get('venue', 'Unknown Venue'),\n            race_number=self._extract_race_number(market.get('marketName', '')),\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME\n        )",
    "python_service/adapters/betfair_auth_mixin.py": "# python_service/adapters/betfair_auth_mixin.py\n\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import Optional\n\nimport httpx\nimport structlog\n\nlog = structlog.get_logger(__name__)\n\n\nclass BetfairAuthMixin:\n    \"\"\"Encapsulates Betfair authentication logic for reuse across adapters.\"\"\"\n\n    session_token: Optional[str] = None\n    token_expiry: Optional[datetime] = None\n\n    async def _authenticate(self, http_client: httpx.AsyncClient):\n        if self.session_token and self.token_expiry and self.token_expiry > (datetime.now() + timedelta(minutes=5)):\n            return\n        if not all([self.app_key, self.config.BETFAIR_USERNAME, self.config.BETFAIR_PASSWORD]):\n            raise ValueError(\"Betfair credentials not fully configured.\")\n\n        auth_url = \"https://identitysso.betfair.com/api/login\"\n        headers = {\"X-Application\": self.app_key, \"Content-Type\": \"application/x-www-form-urlencoded\"}\n        payload = f\"username={self.config.BETFAIR_USERNAME}&password={self.config.BETFAIR_PASSWORD}\"\n\n        log.info(f\"{self.__class__.__name__}: Authenticating...\")\n        response = await http_client.post(auth_url, headers=headers, content=payload, timeout=20)\n        response.raise_for_status()\n        data = response.json()\n        if data.get(\"status\") == \"SUCCESS\":\n            self.session_token = data.get(\"token\")\n            self.token_expiry = datetime.now() + timedelta(hours=3)\n        else:\n            raise ConnectionError(f\"Betfair authentication failed: {data.get('error')}\")\n",
    "python_service/adapters/punters_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass PuntersAdapter(BaseAdapter):\n    \"\"\"Adapter for punters.com.au.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"Punters\", base_url=\"https://www.punters.com.au\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"PuntersAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {\n            \"races\": [],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\",\n                \"races_fetched\": 0,\n                \"error_message\": \"Not Implemented\",\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/twinspires_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass TwinSpiresAdapter(BaseAdapter):\n    \"\"\"Adapter for twinspires.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"TwinSpires\", base_url=\"https://www.twinspires.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"TwinSpiresAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time)\n\n    def _format_response(self, races: List[Race], start_time: datetime, **kwargs) -> Dict[str, Any]:\n        return {\n            \"races\": [],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\",\n                \"races_fetched\": 0,\n                \"error_message\": \"Not Implemented\",\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/nyrabets_adapter.py": "#!/usr/bin/env python3\n# This file was generated from the canonical adapter template.\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\n\nimport httpx\nimport structlog\n\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass NYRABetsAdapter(BaseAdapter):\n    \"\"\"Adapter for nyrabets.com.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"NYRABets\", base_url=\"https://nyrabets.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        log.warning(\"NYRABetsAdapter.fetch_races is a stub.\")\n        return self._format_response([], start_time, is_success=True, error_message=\"Not Implemented\")\n",
    "python_service/adapters/utils.py": "# This file is intentionally left blank after the refactoring in \"Operation: The A+ Trifecta\".\n# The odds parsing logic has been centralized in python_service/utils/odds.py.\n# The text normalization logic has been centralized in python_service/utils/text.py.\n",
    "python_service/adapters/the_racing_api_adapter.py": "# python_service/adapters/theracingapi_adapter.py\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass TheRacingApiAdapter(BaseAdapter):\n    \"\"\"Adapter for the high-value JSON-based The Racing API.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"TheRacingAPI\", base_url=\"https://api.theracingapi.com/v1/\", config=config)\n        self.api_key = config.THE_RACING_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        if not self.api_key:\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"ConfigurationError: THE_RACING_API_KEY not set\"\n            )\n\n        try:\n            endpoint = f\"racecards?date={date}&course=all&region=gb,ire\"\n            headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n            response = await self.make_request(http_client, \"GET\", endpoint, headers=headers)\n\n            if not response:\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No response from API.\"\n                )\n\n            response_json = response.json()\n            if not response_json or not response_json.get(\"racecards\"):\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No racecards found in API response.\"\n                )\n\n            all_races = self._parse_races(response_json[\"racecards\"])\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(f\"{self.source_name}: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(f\"{self.source_name}: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _parse_races(self, racecards: List[Dict[str, Any]]) -> List[Race]:\n        races = []\n        for race_data in racecards:\n            try:\n                start_time = datetime.fromisoformat(race_data[\"off_time\"].replace(\"Z\", \"+00:00\"))\n\n                race = Race(\n                    id=f\"tra_{race_data['race_id']}\",\n                    venue=race_data[\"course\"],\n                    race_number=race_data[\"race_no\"],\n                    start_time=start_time,\n                    runners=self._parse_runners(race_data.get(\"runners\", [])),\n                    source=self.source_name,\n                    race_name=race_data.get(\"race_name\"),\n                    distance=race_data.get(\"distance_f\"),\n                )\n                races.append(race)\n            except Exception as e:\n                log.error(f\"{self.source_name}: Error parsing race\", race_id=race_data.get(\"race_id\"), error=str(e))\n        return races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for i, runner_data in enumerate(runners_data):\n            try:\n                odds_data = {}\n                if runner_data.get(\"odds\"):\n                    win_odds = Decimal(str(runner_data[\"odds\"][0][\"odds_decimal\"]))\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds, source=self.source_name, last_updated=datetime.now()\n                    )\n\n                runners.append(\n                    Runner(\n                        number=runner_data.get(\"number\", i + 1),\n                        name=runner_data[\"horse\"],\n                        odds=odds_data,\n                        jockey=runner_data.get(\"jockey\"),\n                        trainer=runner_data.get(\"trainer\"),\n                    )\n                )\n            except Exception as e:\n                log.error(\n                    f\"{self.source_name}: Error parsing runner\", runner_name=runner_data.get(\"horse\"), error=str(e)\n                )\n        return runners\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/sporting_life_adapter.py": "# python_service/adapters/sporting_life_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return \" \".join(text.strip().split()) if text else None\n\n\nclass SportingLifeAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"SportingLife\", base_url=\"https://www.sportinglife.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response_html = await self.make_request(http_client, \"GET\", \"/horse-racing/racecards\")\n        if not response_html:\n            return []\n        soup = BeautifulSoup(response_html, \"html.parser\")\n        links = {a[\"href\"] for a in soup.select(\"a.hr-race-card-meeting__race-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response_html = await self.make_request(http_client, \"GET\", url)\n            if not response_html:\n                return None\n            soup = BeautifulSoup(response_html, \"html.parser\")\n            track_name = _clean_text(soup.select_one(\"a.hr-race-header-course-name__link\").get_text())\n            race_time_str = _clean_text(soup.select_one(\"span.hr-race-header-time__time\").get_text())\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            active_link = soup.select_one(\"a.hr-race-header-navigation-link--active\")\n            race_number = soup.select(\"a.hr-race-header-navigation-link\").index(active_link) + 1 if active_link else 1\n            runners = [self._parse_runner(row) for row in soup.select(\"div.hr-racing-runner-card\")]\n            return Race(\n                id=f\"sl_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                venue=track_name,\n                race_number=race_number,\n                start_time=start_time,\n                runners=[r for r in runners if r],\n                source=self.source_name,\n            )\n        except Exception as e:\n            log.error(\"Error parsing race from SportingLife\", url=url, exc_info=e)\n            return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"a.hr-racing-runner-horse-name\").get_text())\n            num_str = _clean_text(row.select_one(\"span.hr-racing-runner-saddle-cloth-no\").get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"span.hr-racing-runner-odds\").get_text())\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())}\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except Exception as e:\n            log.warning(\"Failed to parse runner from SportingLife\", exc_info=e)\n            return None\n"
}