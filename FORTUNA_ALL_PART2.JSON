{
    "python_service/adapters/at_the_races_adapter.py": "# python_service/adapters/at_the_races_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom ..utils.text import clean_text\nfrom ..utils.text import normalize_venue_name\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass AtTheRacesAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"AtTheRaces\", base_url=\"https://www.attheraces.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            log.error(f\"Error fetching races from AtTheRaces: {e}\", exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response = await self.make_request(http_client, \"GET\", \"/racecards\")\n        if not response:\n            return []\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        links = {a[\"href\"] for a in soup.select(\"a.race-time-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response = await self.make_request(http_client, \"GET\", url)\n            if response is None:\n                return None\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            header = soup.select_one(\"h1.heading-racecard-title\").get_text()\n            track_name_raw, race_time = [p.strip() for p in header.split(\"|\")[:2]]\n            track_name = normalize_venue_name(track_name_raw)\n            active_link = soup.select_one(\"a.race-time-link.active\")\n            race_number = active_link.find_parent(\"div\", \"races\").select(\"a.race-time-link\").index(active_link) + 1\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time}\", \"%Y-%m-%d %H:%M\")\n            runners = [self._parse_runner(row) for row in soup.select(\"div.card-horse\")]\n            return Race(\n                id=f\"atr_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                venue=track_name,\n                race_number=race_number,\n                start_time=start_time,\n                runners=[r for r in runners if r],\n                source=self.source_name,\n            )\n        except Exception as e:\n            log.error(\"Error parsing race from AtTheRaces\", url=url, exc_info=e)\n            return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = clean_text(row.select_one(\"h3.horse-name a\").get_text())\n            num_str = clean_text(row.select_one(\"span.horse-number\").get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n            odds_str = clean_text(row.select_one(\"button.best-odds\").get_text())\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())}\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except Exception as e:\n            log.warning(\"Failed to parse runner\", exc_info=e)\n            return None\n",
    "python_service/adapters/base.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Base Adapter (v2 - Hardened with Tenacity)\n# ==============================================================================\n\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom tenacity import AsyncRetrying\nfrom tenacity import RetryError\nfrom tenacity import stop_after_attempt\nfrom tenacity import wait_exponential\n\nlog = structlog.get_logger(__name__)\n\n\nclass BaseAdapter(ABC):\n    \"\"\"The resilient base class for all data source adapters.\"\"\"\n\n    def __init__(self, source_name: str, base_url: str, timeout: int = 20, max_retries: int = 3):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.timeout = timeout\n        self.max_retries = max_retries\n        self.logger = structlog.get_logger(adapter_name=source_name)\n        # Circuit Breaker State\n        self.circuit_breaker_tripped = False\n        self.circuit_breaker_failure_count = 0\n        self.circuit_breaker_last_failure = 0\n        self.FAILURE_THRESHOLD = 3\n        self.COOLDOWN_PERIOD_SECONDS = 300  # 5 minutes\n\n    @abstractmethod\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        raise NotImplementedError\n\n    async def make_request(self, http_client: httpx.AsyncClient, method: str, url: str, **kwargs) -> Optional[Any]:\n        \"\"\"Makes a resilient HTTP request with automatic retries using Tenacity.\"\"\"\n        retryer = AsyncRetrying(\n            stop=stop_after_attempt(self.max_retries), wait=wait_exponential(multiplier=1, min=2, max=10), reraise=True\n        )\n        try:\n            async for attempt in retryer:\n                with attempt:\n                    try:\n                        full_url = url if url.startswith(\"http\") else f\"{self.base_url}{url}\"\n                        log.info(\n                            \"Requesting...\",\n                            adapter=self.source_name,\n                            method=method,\n                            url=full_url,\n                            attempt=attempt.retry_state.attempt_number,\n                        )\n                        response = await http_client.request(method, full_url, timeout=self.timeout, **kwargs)\n                        response.raise_for_status()\n                        return response.json()\n                    except (httpx.RequestError, httpx.HTTPStatusError) as e:\n                        log.warning(\"Request failed, tenacity will retry...\", adapter=self.source_name, error=str(e))\n                        raise  # Reraise to trigger tenacity's retry mechanism\n        except RetryError as e:\n            log.error(f\"Max retries exceeded for {self.source_name}. Aborting request.\", final_error=str(e))\n            return None  # Return None on total failure\n\n    def get_status(self) -> Dict[str, Any]:\n        return {\"adapter_name\": self.source_name, \"status\": \"OK\"}\n\n    def _format_response(\n        self, races: List, start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n",
    "python_service/adapters/base_v3.py": "# python_service/adapters/base_v3.py\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import AsyncGenerator, Any, List\n\nimport structlog\n\nfrom ..models import Race\nfrom .base import BaseAdapter # Inherit to retain retry logic, logging, circuit breaker state, etc.\n\nclass BaseAdapterV3(ABC):\n    \"\"\"\n    An architecturally superior abstract base class for data adapters.\n\n    This class enforces a rigid, standardized implementation pattern by requiring all\n    subclasses to implement their own `_fetch_data` and `_parse_races` methods.\n    It also includes a built-in circuit breaker to enhance resilience.\n    \"\"\"\n    def __init__(self, source_name: str, base_url: str, timeout: int = 20, max_retries: int = 3):\n        self.source_name = source_name\n        self.base_url = base_url\n        self.timeout = timeout\n        self.max_retries = max_retries\n        self.logger = structlog.get_logger(adapter_name=source_name)\n        # Circuit Breaker State\n        self.circuit_breaker_tripped = False\n        self.circuit_breaker_failure_count = 0\n        self.circuit_breaker_last_failure = 0\n        self.FAILURE_THRESHOLD = 3\n        self.COOLDOWN_PERIOD_SECONDS = 300  # 5 minutes\n\n    @abstractmethod\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"\n        Fetches the raw data (e.g., HTML, JSON) for the given date.\n        This is the only method that should interact with the network.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"\n        Parses the raw data fetched by _fetch_data into a list of Race objects.\n        This method should be pure and contain no network logic.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"\n        The public-facing method to get races. Orchestrates the fetch and parse process.\n        Includes a circuit breaker to prevent repeated calls to a failing adapter.\n        Subclasses should NOT override this method.\n        \"\"\"\n        # Check Circuit Breaker state\n        if self.circuit_breaker_tripped:\n            if time.time() - self.circuit_breaker_last_failure < self.COOLDOWN_PERIOD_SECONDS:\n                self.logger.warning(f\"Circuit breaker for {self.SOURCE_NAME} is tripped. Skipping fetch.\")\n                return\n            else:\n                self.logger.info(f\"Cooldown period for {self.SOURCE_NAME} has passed. Resetting circuit breaker.\")\n                self.circuit_breaker_failure_count = 0\n                self.circuit_breaker_tripped = False\n\n        try:\n            raw_data = await self._fetch_data(date)\n            if raw_data is None:\n                self.logger.warning(f\"Fetching data for {self.SOURCE_NAME} on {date} returned None.\")\n                return\n\n            parsed_races = self._parse_races(raw_data)\n            for race in parsed_races:\n                yield race\n\n            # Reset failure count on success\n            self.circuit_breaker_failure_count = 0\n\n        except Exception:\n            self.logger.error(\n                f\"An unexpected error occurred in the get_races pipeline for {self.SOURCE_NAME}.\",\n                exc_info=True\n            )\n            # Handle circuit breaker logic on failure\n            self.circuit_breaker_failure_count += 1\n            self.circuit_breaker_last_failure = time.time()\n            if self.circuit_breaker_failure_count >= self.FAILURE_THRESHOLD:\n                self.circuit_breaker_tripped = True\n                self.logger.critical(f\"Circuit breaker for {self.SOURCE_NAME} has been tripped after {self.FAILURE_THRESHOLD} failures.\")\n            return\n",
    "python_service/adapters/betfair_adapter.py": "# python_service/adapters/betfair_adapter.py\n\nimport re\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import Optional\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\nlog = structlog.get_logger(__name__)\n\n\nclass BetfairAdapter(BetfairAuthMixin, BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"BetfairExchange\", base_url=\"https://api.betfair.com/exchange/betting/rest/v1.0/\")\n        self.config = config\n        self.app_key = self.config.BETFAIR_APP_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            await self._authenticate(http_client)\n            headers = {\n                \"X-Application\": self.app_key,\n                \"X-Authentication\": self.session_token,\n                \"Content-Type\": \"application/json\",\n            }\n            market_filter = {\n                \"eventTypeIds\": [\"7\"],\n                \"marketTypeCodes\": [\"WIN\"],\n                \"marketStartTime\": {\"from\": f\"{date}T00:00:00Z\", \"to\": f\"{date}T23:59:59Z\"},\n            }\n            response = await self.make_request(\n                http_client,\n                \"POST\",\n                \"listMarketCatalogue/\",\n                headers=headers,\n                json={\"filter\": market_filter, \"maxResults\": 1000, \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"]},\n            )\n            if not response:\n                return self._format_response([], start_time, is_success=True, error_message=\"No markets found.\")\n            market_catalogue = response.json()\n            all_races = [self._parse_race(market) for market in market_catalogue]\n            return self._format_response(all_races, start_time, is_success=True)\n        except Exception as e:\n            log.error(f\"Error fetching races from Betfair: {e}\", exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    def _parse_race(self, market: Dict[str, Any]) -> Race | None:\n        if market is None:\n            return None\n        runners = [\n            Runner(number=rd.get(\"sortPriority\", 99), name=rd[\"runnerName\"], selection_id=rd[\"selectionId\"])\n            for rd in market.get(\"runners\", [])\n        ]\n        return Race(\n            id=f\"bf_{market['marketId']}\",\n            venue=market[\"event\"][\"venue\"],\n            race_number=self._extract_race_number(market.get(\"marketName\")),\n            start_time=datetime.fromisoformat(market[\"marketStartTime\"].replace(\"Z\", \"+00:00\")),\n            runners=runners,\n            source=self.source_name,\n        )\n\n    def _extract_race_number(self, name: Optional[str]) -> int:\n        if not name:\n            return 1\n        match = re.search(r\"\\bR(\\d{1,2})\\b\", name)\n        return int(match.group(1)) if match else 1\n\n    # The duplicated method has been removed.\n    async def close(self):\n        \"\"\"Closes the underlying HTTP client to release resources.\"\"\"\n        if self.http_client:\n            await self.http_client.aclose()\n",
    "python_service/adapters/betfair_datascientist_adapter.py": "# python_service/adapters/betfair_datascientist_adapter.py\n\nfrom datetime import datetime\nfrom io import StringIO\nfrom typing import Any\nfrom typing import List\n\nimport pandas as pd\nimport requests\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.text import normalize_course_name\nfrom .base_v3 import BaseAdapterV3\n\n\nclass BetfairDataScientistAdapter(BaseAdapterV3):\n    ADAPTER_NAME = \"BetfairDataScientist\"\n\n    def __init__(self, model_name: str, url: str, enabled: bool = True, priority: int = 100, config=None):\n        source_name = f\"{self.ADAPTER_NAME}_{model_name}\"\n        super().__init__(source_name=source_name, base_url=url)\n        self.model_name = model_name\n        self.url = url\n        self._enabled = enabled\n        self._priority = priority\n        self.config = config\n\n    async def _fetch_data(self, date: str) -> Any:\n        if not self._enabled:\n            self.logger.debug(f\"Adapter '{self.source_name}' is disabled. Skipping.\")\n            return None\n\n        try:\n            full_url = self._build_url(date)\n            self.logger.info(f\"Fetching data from {full_url}\")\n            response = await asyncio.to_thread(requests.get, full_url)\n            response.raise_for_status()\n            return StringIO(response.text)\n        except Exception as e:\n            self.logger.error(f\"An unexpected error in {self.source_name}: {e}\", exc_info=True)\n            return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        df = pd.read_csv(raw_data)\n        df = df.rename(\n            columns={\n                \"meetings.races.bfExchangeMarketId\": \"market_id\",\n                \"meetings.races.runners.bfExchangeSelectionId\": \"selection_id\",\n                \"meetings.races.runners.ratedPrice\": \"rated_price\",\n                \"meetings.races.raceName\": \"race_name\",\n                \"meetings.name\": \"meeting_name\",\n                \"meetings.races.raceNumber\": \"race_number\",\n                \"meetings.races.runners.runnerName\": \"runner_name\",\n                \"meetings.races.runners.clothNumber\": \"saddle_cloth\",\n            }\n        )\n        races = []\n        for market_id, group in df.groupby(\"market_id\"):\n            race_info = group.iloc[0]\n            runners = [\n                Runner(\n                    name=str(row.get(\"runner_name\")),\n                    number=int(row.get(\"saddle_cloth\", 0)),\n                    odds=float(row.get(\"rated_price\", 0.0)),\n                )\n                for _, row in group.iterrows()\n            ]\n            race = Race(\n                id=str(market_id),\n                venue=normalize_course_name(str(race_info.get(\"meeting_name\", \"\"))),\n                race_number=int(race_info.get(\"race_number\", 0)),\n                start_time=datetime.now(),\n                runners=runners,\n                source=self.source_name,\n            )\n            races.append(race)\n        self.logger.info(f\"Normalized {len(races)} races from {self.model_name}.\")\n        return races\n\n    def _build_url(self, date: str) -> str:\n        return f\"{self.url}{date}&presenter=RatingsPresenter&csv=true\"\n",
    "python_service/adapters/betfair_greyhound_adapter.py": "# python_service/adapters/betfair_greyhound_adapter.py\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom decimal import Decimal\nfrom typing import AsyncGenerator\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\nfrom .betfair_auth_mixin import BetfairAuthMixin\n\n\nclass BetfairGreyhoundAdapter(BetfairAuthMixin, BaseAdapter):\n    \"\"\"Adapter for fetching greyhound racing data from the Betfair Exchange API.\"\"\"\n\n    SOURCE_NAME = \"BetfairGreyhounds\"\n    BASE_URL = \"https://api.betfair.com/exchange/betting/rest/v1.0/\"\n\n    def __init__(self, config=None):\n        super().__init__(self.SOURCE_NAME, self.BASE_URL)\n        if config:\n            self.betfair_app_key = config.BETFAIR_APP_KEY\n            self.betfair_username = config.BETFAIR_USERNAME\n            self.betfair_password = config.BETFAIR_PASSWORD\n\n    async def fetch_races(self, date: str, http_client) -> AsyncGenerator[Race, None]:\n        \"\"\"Fetches all greyhound races for a given date.\"\"\"\n        await self._authenticate(http_client)\n        if not self.session_token:\n            # self.logger.error(\"Authentication failed, cannot fetch races.\")\n            return\n\n        start_time, end_time = self._get_datetime_range(date)\n\n        market_catalogue = await self.make_request(\n            http_client=http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketCatalogue/\",\n            json={\n                \"filter\": {\n                    \"eventTypeIds\": [\"4339\"],  # Greyhound Racing\n                    \"marketCountries\": [\"GB\", \"IE\"],\n                    \"marketTypeCodes\": [\"WIN\"],\n                    \"marketStartTime\": {\"from\": start_time.isoformat() + \"Z\", \"to\": end_time.isoformat() + \"Z\"},\n                },\n                \"maxResults\": 1000,\n                \"marketProjection\": [\"EVENT\", \"RUNNER_DESCRIPTION\"],\n            },\n        )\n\n        if not market_catalogue:\n            return\n\n        for market in market_catalogue:\n            yield await self._parse_race(market, http_client)\n\n    async def _parse_race(self, market: dict, http_client) -> Race:\n        \"\"\"Parses a single market from the Betfair API into a Race object.\"\"\"\n        market_id = market[\"marketId\"]\n        event = market[\"event\"]\n        start_time = datetime.fromisoformat(market[\"marketStartTime\"].replace(\"Z\", \"+00:00\"))\n\n        odds_data = await self._get_odds_for_market(market_id, http_client)\n\n        runners = [\n            Runner(\n                number=runner.get(\"sortPriority\", i + 1),\n                name=runner[\"runnerName\"],\n                scratched=runner[\"status\"] != \"ACTIVE\",\n                selection_id=runner[\"selectionId\"],\n                odds=odds_data.get(runner[\"selectionId\"], {}),\n            )\n            for i, runner in enumerate(market.get(\"runners\", []))\n        ]\n\n        return Race(\n            id=f\"bfg_{market_id}\",\n            venue=event.get(\"venue\", \"Unknown Venue\"),\n            race_number=self._extract_race_number(market.get(\"marketName\", \"\")),\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    async def _get_odds_for_market(self, market_id: str, http_client) -> dict:\n        \"\"\"Fetches the latest odds for a given market.\"\"\"\n        market_book = await self.make_request(\n            http_client=http_client,\n            method=\"post\",\n            url=f\"{self.BASE_URL}listMarketBook/\",\n            json={\"marketIds\": [market_id], \"priceProjection\": {\"priceData\": [\"EX_BEST_OFFERS\"]}},\n        )\n\n        odds_data = {}\n        if market_book and market_book[0].get(\"runners\"):\n            for runner in market_book[0][\"runners\"]:\n                selection_id = runner[\"selectionId\"]\n                if runner[\"status\"] == \"ACTIVE\" and runner[\"ex\"][\"availableToBack\"]:\n                    win_odds = Decimal(str(runner[\"ex\"][\"availableToBack\"][0][\"price\"]))\n                    odds_data[selection_id] = {\n                        self.SOURCE_NAME: OddsData(win=win_odds, source=self.SOURCE_NAME, last_updated=datetime.now())\n                    }\n        return odds_data\n\n    def _get_datetime_range(self, date_str: str):\n        start_of_day = datetime.strptime(date_str, \"%Y-%m-%d\")\n        end_of_day = start_of_day + timedelta(days=1)\n        return start_of_day, end_of_day\n\n    def _extract_race_number(self, market_name: str) -> int:\n        import re\n\n        match = re.search(r\"R(\\d+)\", market_name)\n        return int(match.group(1)) if match else 0\n",
    "python_service/adapters/fanduel_adapter.py": "# python_service/adapters/fanduel_adapter.py\n\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger()\n\n\nclass FanDuelAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching horse racing odds from FanDuel's private API.\"\"\"\n\n    source_name = \"FanDuel\"\n    API_URL = \"https://sb-api.nj.sportsbook.fanduel.com/api/markets?_ak=Fh2e68s832c41d4b&eventId=\"\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> List[Race]:\n        \"\"\"Fetches races for a given date. Note: FanDuel API is event-based, not date-based.\"\"\"\n        # This is a placeholder for a more robust event discovery mechanism.\n        # For now, we'll use a known event ID for a major race day as a proof of concept.\n        # A full implementation would need to first find the relevant event IDs for the day.\n        event_id = \"38183.3\"  # Example: A major race event\n\n        log.info(\"Fetching races from FanDuel\", event_id=event_id)\n        start_time = datetime.now()\n        try:\n            response = await http_client.get(self.API_URL + event_id)\n            response.raise_for_status()\n            data = response.json()\n            races = self._parse_races(data)\n            return self._format_response(races, start_time, is_success=True)\n        except httpx.HTTPStatusError as e:\n            log.error(\"FanDuel API request failed\", status_code=e.response.status_code, response=e.response.text)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n        except Exception as e:\n            log.error(\"An unexpected error occurred fetching FanDuel data\", error=str(e), exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    def _parse_races(self, data: Dict[str, Any]) -> List[Race]:\n        races = []\n        if \"marketGroups\" not in data:\n            log.warning(\"FanDuel response missing 'marketGroups' key\")\n            return []\n\n        for group in data[\"marketGroups\"]:\n            if group.get(\"marketGroupName\") == \"Win\":\n                for market in group.get(\"markets\", []):\n                    try:\n                        race = self._parse_single_race(market)\n                        if race:\n                            races.append(race)\n                    except Exception as e:\n                        log.error(\"Failed to parse a FanDuel market\", market=market, error=str(e), exc_info=True)\n        return races\n\n    def _parse_single_race(self, market: Dict[str, Any]) -> Race | None:\n        market_name = market.get(\"marketName\", \"\")\n        if not market_name.startswith(\"Race\"):\n            return None\n\n        # Extract race number and track from market name (e.g., \"Race 5 - Churchill Downs\")\n        parts = market_name.split(\" - \")\n        if len(parts) < 2:\n            return None\n\n        race_number_str = parts[0].replace(\"Race \", \"\")\n        track_name = parts[1]\n\n        # Placeholder for start_time - FanDuel's market API doesn't provide it directly\n        start_time = datetime.now(timezone.utc) + timedelta(hours=int(race_number_str))\n\n        runners = []\n        for runner_data in market.get(\"runners\", []):\n            runner_name = runner_data.get(\"runnerName\")\n            win_odds = runner_data.get(\"winRunnerOdds\", {}).get(\"currentPrice\")\n            if not runner_name or not win_odds:\n                continue\n\n            try:\n                # Price is given as a fraction string, e.g., \"12/5\"\n                numerator, denominator = map(int, win_odds.split(\"/\"))\n                decimal_odds = Decimal(numerator) / Decimal(denominator) + 1\n            except (ValueError, ZeroDivisionError):\n                log.warning(\"Could not parse FanDuel odds\", odds_str=win_odds, runner=runner_name)\n                continue\n\n            odds = OddsData(win=decimal_odds, source=self.source_name, last_updated=datetime.now(timezone.utc))\n\n            # Placeholder for program number\n            program_number_str = runner_name.split(\".\")[0].strip()\n\n            runner = Runner(\n                name=runner_name.split(\".\")[1].strip(),\n                number=int(program_number_str) if program_number_str.isdigit() else None,\n                odds={self.source_name: odds},\n            )\n            runners.append(runner)\n\n        if not runners:\n            return None\n\n        race_id = f\"FD-{track_name.replace(' ', '')[:5].upper()}-{start_time.strftime('%Y%m%d')}-R{race_number_str}\"\n\n        return Race(\n            id=race_id,\n            venue=track_name,\n            race_number=int(race_number_str),\n            start_time=start_time,\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/gbgb_api_adapter.py": "# python_service/adapters/gbgb_api_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass GbgbApiAdapter(BaseAdapter):\n    \"\"\"Adapter for the undocumented JSON API for the Greyhound Board of Great Britain.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"GBGB\", base_url=\"https://api.gbgb.org.uk/api/\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            # The endpoint appears to be structured by date for all meetings\n            endpoint = f\"results/meeting/{date}\"\n            response = await self.make_request(http_client, \"GET\", endpoint)\n\n            if not response:\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No meetings found in API response.\"\n                )\n            \n            all_races = self._parse_meetings(response)\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(f\"{self.source_name}: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(f\"{self.source_name}: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _parse_meetings(self, meetings_data: List[Dict[str, Any]]) -> List[Race]:\n        races = []\n        if meetings_data is None:\n            return races\n        for meeting in meetings_data:\n            track_name = meeting.get(\"trackName\")\n            for race_data in meeting.get(\"races\", []):\n                try:\n                    races.append(self._parse_race(race_data, track_name))\n                except Exception as e:\n                    log.error(f\"{self.source_name}: Error parsing race\", race_id=race_data.get(\"raceId\"), error=str(e))\n        return races\n\n    def _parse_race(self, race_data: Dict[str, Any], track_name: str) -> Race:\n        return Race(\n            id=f\"gbgb_{race_data['raceId']}\",\n            venue=track_name,\n            race_number=race_data[\"raceNumber\"],\n            start_time=datetime.fromisoformat(race_data[\"raceTime\"].replace(\"Z\", \"+00:00\")),\n            runners=self._parse_runners(race_data.get(\"traps\", [])),\n            source=self.source_name,\n            race_name=race_data.get(\"raceTitle\"),\n            distance=f\"{race_data.get('raceDistance')}m\",\n        )\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for runner_data in runners_data:\n            try:\n                # The API provides SP as a fraction, e.g., '5/2'\n                odds_data = {}\n                sp = runner_data.get(\"sp\")\n                win_odds = parse_odds_to_decimal(sp)\n                if win_odds and win_odds < 999:\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds, source=self.source_name, last_updated=datetime.now()\n                    )\n\n                runners.append(\n                    Runner(\n                        number=runner_data[\"trapNumber\"],\n                        name=runner_data[\"dogName\"],\n                        odds=odds_data,\n                    )\n                )\n            except Exception as e:\n                log.error(\n                    f\"{self.source_name}: Error parsing runner\", runner_name=runner_data.get(\"dogName\"), error=str(e)\n                )\n        return runners\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/greyhound_adapter.py": "from datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\nfrom pydantic import ValidationError\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass GreyhoundAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching Greyhound racing data. Activated by setting GREYHOUND_API_URL in .env\"\"\"\n\n    def __init__(self, config):\n        if not config.GREYHOUND_API_URL:\n            raise ValueError(\"GreyhoundAdapter cannot be initialized without GREYHOUND_API_URL.\")\n        super().__init__(source_name=\"Greyhound Racing\", base_url=config.GREYHOUND_API_URL)\n        # Example for future use: self.api_key = config.GREYHOUND_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        \"\"\"Fetches upcoming greyhound races for the specified date.\"\"\"\n        start_time = datetime.now()\n        endpoint = f\"v1/cards/{date}\"  # Using date parameter\n        try:\n            response = await self.make_request(http_client, \"GET\", endpoint)\n            if not response:\n                log.warning(\"GreyhoundAdapter: No response from make_request.\")\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No data received from provider.\"\n                )\n\n            response_json = response.json()\n            if not response_json or not response_json.get(\"cards\"):\n                log.warning(\"GreyhoundAdapter: No 'cards' in response or empty list.\")\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No race cards found for date.\"\n                )\n            \n            all_races = self._parse_cards(response_json[\"cards\"])\n            if not all_races:\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"Races found, but none could be parsed.\"\n                )\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"GreyhoundAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(\"GreyhoundAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {str(e)}\"\n            )\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n\n    def _parse_cards(self, cards: List[Dict[str, Any]]) -> List[Race]:\n        \"\"\"Parses a list of cards and their races into Race objects.\"\"\"\n        all_races = []\n        if cards is None:\n            return all_races\n        for card in cards:\n            venue = card.get(\"track_name\", \"Unknown Venue\")\n            races_data = card.get(\"races\", [])\n            for race_data in races_data:\n                try:\n                    if not race_data.get(\"runners\"):\n                        continue\n\n                    race = Race(\n                        id=f\"greyhound_{race_data['race_id']}\",\n                        venue=venue,\n                        race_number=race_data[\"race_number\"],\n                        start_time=datetime.fromtimestamp(race_data[\"start_time\"]),\n                        runners=self._parse_runners(race_data[\"runners\"]),\n                        source=self.source_name,\n                    )\n                    all_races.append(race)\n                except (ValidationError, KeyError) as e:\n                    log.error(\n                        f\"GreyhoundAdapter: Error parsing race {race_data.get('race_id', 'N/A')}\",\n                        error=str(e),\n                        race_data=race_data,\n                    )\n        return all_races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        \"\"\"Parses a list of runner dictionaries into Runner objects.\"\"\"\n        runners = []\n        for runner_data in runners_data:\n            try:\n                if runner_data.get(\"scratched\", False):\n                    continue\n\n                odds_data = {}\n                # The directive's example was flawed. Correcting to a more realistic structure.\n                win_odds_val = runner_data.get(\"odds\", {}).get(\"win\")\n                if win_odds_val is not None:\n                    win_odds = Decimal(str(win_odds_val))\n                    if win_odds > 1:\n                        odds_data[self.source_name] = OddsData(\n                            win=win_odds, source=self.source_name, last_updated=datetime.now()\n                        )\n\n                runner = Runner(\n                    number=runner_data[\"trap_number\"],\n                    name=runner_data[\"dog_name\"],\n                    scratched=runner_data.get(\"scratched\", False),\n                    odds=odds_data,\n                )\n                runners.append(runner)\n            except (KeyError, ValidationError) as e:\n                log.error(\"GreyhoundAdapter: Error parsing runner\", error=str(e), runner_data=runner_data)\n        return runners\n",
    "python_service/adapters/harness_adapter.py": "# python_service/adapters/harness_adapter.py\nfrom datetime import datetime\nfrom typing import AsyncGenerator\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\n\nclass HarnessAdapter(BaseAdapter):\n    \"\"\"Adapter for fetching US harness racing data from data.ustrotting.com.\"\"\"\n\n    SOURCE_NAME = \"USTrotting\"\n    BASE_URL = \"https://data.ustrotting.com/api/racenet/racing/\"\n\n    def __init__(self, config=None):\n        super().__init__(self.SOURCE_NAME, self.BASE_URL)\n\n    async def fetch_races(self, date: str) -> AsyncGenerator[Race, None]:\n        \"\"\"Fetches all harness races for a given date.\"\"\"\n        card_data = await self.make_request(method=\"get\", url=f\"{self.BASE_URL}card/{date}\")\n        if not card_data or not card_data.get(\"meetings\"):\n            return\n\n        for meeting in card_data[\"meetings\"]:\n            track_name = meeting.get(\"track\", {}).get(\"name\")\n            for race_data in meeting.get(\"races\", []):\n                yield self._parse_race(race_data, track_name, date)\n\n    def _parse_race(self, race_data: dict, track_name: str, date: str) -> Race:\n        \"\"\"Parses a single race from the USTA API into a Race object.\"\"\"\n        race_number = race_data.get(\"raceNumber\", 0)\n        post_time_str = race_data.get(\"postTime\", \"00:00 AM\")\n        start_time = self._parse_post_time(date, post_time_str)\n\n        runners = []\n        for runner_data in race_data.get(\"runners\", []):\n            odds_str = runner_data.get(\"morningLineOdds\", \"\")\n            # Ensure odds are fractional for parsing\n            if \"/\" not in odds_str and odds_str.isdigit():\n                odds_str = f\"{odds_str}/1\"\n\n            odds = {}\n            win_odds = parse_odds_to_decimal(odds_str)\n            if win_odds and win_odds < 999:\n                odds = {self.SOURCE_NAME: OddsData(win=win_odds, source=self.SOURCE_NAME, last_updated=datetime.now())}\n\n            runners.append(\n                Runner(\n                    number=runner_data.get(\"postPosition\", 0),\n                    name=runner_data.get(\"horse\", {}).get(\"name\", \"Unknown Horse\"),\n                    odds=odds,\n                    scratched=runner_data.get(\"scratched\", False),\n                )\n            )\n\n        return Race(\n            id=f\"ust_{track_name.lower().replace(' ', '')}_{date}_{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n            source=self.SOURCE_NAME,\n        )\n\n    def _parse_post_time(self, date: str, post_time: str) -> datetime:\n        \"\"\"Parses a time string like '07:00 PM' into a timezone-aware datetime object.\"\"\"\n        from zoneinfo import ZoneInfo\n\n        dt_str = f\"{date} {post_time}\"\n        naive_dt = datetime.strptime(dt_str, \"%Y-%m-%d %I:%M %p\")\n        # Assume Eastern Time for USTA data, a common standard for US racing.\n        eastern = ZoneInfo(\"America/New_York\")\n        return naive_dt.replace(tzinfo=eastern)\n",
    "python_service/adapters/oddschecker_adapter.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Oddschecker Adapter (Canonized)\n# ==============================================================================\n# This adapter was sourced from the 'Live Odds Anthology' and has been modernized\n# to conform to the project's current BaseAdapter framework.\n# ==============================================================================\n\nimport asyncio\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\nfrom .utils import parse_odds\n\nlog = structlog.get_logger(__name__)\n\n\nclass OddscheckerAdapter(BaseAdapter):\n    \"\"\"Adapter for scraping live horse racing odds from Oddschecker.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"Oddschecker\", base_url=\"https://www.oddschecker.com\")\n        self.config = config\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            meeting_links = await self._get_all_meeting_links(http_client)\n            if not meeting_links:\n                return self._format_response([], start_time, is_success=True, error_message=\"No meeting links found.\")\n\n            tasks = [self._fetch_single_meeting(link, http_client) for link in meeting_links]\n            races_from_all_meetings = await asyncio.gather(*tasks)\n\n            all_races = [race for sublist in races_from_all_meetings for race in sublist if race]\n            return self._format_response(all_races, start_time)\n        except Exception as e:\n            log.error(\"OddscheckerAdapter failed\", exc_info=True)\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_all_meeting_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        html = await self.make_request(http_client, \"GET\", \"/horse-racing\")\n        soup = BeautifulSoup(html, \"html.parser\")\n        links = {self.base_url + a[\"href\"] for a in soup.select(\"a.meeting-title[href]\")}\n        return sorted(list(links))\n\n    async def _fetch_single_meeting(self, url: str, client: httpx.AsyncClient) -> List[Optional[Race]]:\n        try:\n            html = await self.make_request(client, \"GET\", url.replace(self.base_url, \"\"))\n            soup = BeautifulSoup(html, \"html.parser\")\n            race_links = {self.base_url + a[\"href\"] for a in soup.select(\"a.race-time-link[href]\")}\n            tasks = [self._fetch_and_parse_race_card(link, client) for link in race_links]\n            return await asyncio.gather(*tasks)\n        except Exception as e:\n            log.error(\"Oddschecker failed to fetch meeting\", url=url, error=e)\n            return []\n\n    async def _fetch_and_parse_race_card(self, url: str, client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            html = await self.make_request(client, \"GET\", url.replace(self.base_url, \"\"))\n            soup = BeautifulSoup(html, \"html.parser\")\n            return self._parse_race_page(soup, url)\n        except Exception as e:\n            log.error(\"Oddschecker failed to parse race card\", url=url, error=e)\n            return None\n\n    def _parse_race_page(self, soup: BeautifulSoup, url: str) -> Optional[Race]:\n        track_name = (\n            soup.select_one(\"h1.meeting-name\").get_text(strip=True) if soup.select_one(\"h1.meeting-name\") else \"Unknown\"\n        )\n        race_time_str = (\n            soup.select_one(\"span.race-time\").get_text(strip=True) if soup.select_one(\"span.race-time\") else None\n        )\n        race_number = int(url.split(\"-\")[-1]) if \"race-\" in url else 0\n\n        runners = []\n        for row in soup.select(\"tr.race-card-row\"):\n            runner = self._parse_runner_row(row)\n            if runner:\n                runners.append(runner)\n\n        if not runners:\n            return None\n\n        start_time = datetime.now()  # Default to now\n        if race_time_str:\n            try:\n                today_str = datetime.now().strftime(\"%Y-%m-%d\")\n                start_time = datetime.strptime(f\"{today_str} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            except ValueError:\n                log.warning(\"Could not parse race time\", time_str=race_time_str)\n\n        return Race(\n            id=f\"oc_{track_name.lower().replace(' ', '')}_{start_time.strftime('%Y%m%d')}_r{race_number}\",\n            venue=track_name,\n            race_number=race_number,\n            start_time=start_time,\n            runners=runners,\n        )\n\n    def _parse_runner_row(self, row: Tag) -> Optional[Runner]:\n        name_tag = row.select_one(\"span.selection-name\")\n        name = name_tag.get_text(strip=True) if name_tag else None\n        odds_tag = row.select_one(\"span.bet-button-odds-desktop, span.best-price\")\n        odds_str = odds_tag.get_text(strip=True) if odds_tag else None\n        number_tag = row.select_one(\"td.runner-number\")\n        number = int(number_tag.get_text(strip=True)) if number_tag else 0\n\n        if not name or not odds_str:\n            return None\n\n        odds_val = parse_odds(odds_str)\n        odds_dict = {}\n        if odds_val:\n            odds_dict[self.source_name] = OddsData(\n                win=Decimal(str(odds_val)), source=self.source_name, last_updated=datetime.now()\n            )\n\n        return Runner(number=number, name=name, odds=odds_dict)\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        \"\"\"Formats the adapter's response consistently.\"\"\"\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": [r.model_dump() for r in races],\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n",
    "python_service/adapters/racing_and_sports_adapter.py": "# python_service/adapters/racing_and_sports_adapter.py\n\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass RacingAndSportsAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"Racing and Sports\", base_url=\"https://api.racingandsports.com.au/\")\n        self.api_token = config.RACING_AND_SPORTS_TOKEN\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        all_races: List[Race] = []\n        headers = {\"Authorization\": f\"Bearer {self.api_token}\", \"Accept\": \"application/json\"}\n\n        if not self.api_token:\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"ConfigurationError: Token not set\"\n            )\n\n        try:\n            meetings_url = \"v1/racing/meetings\"\n            params = {\"date\": date, \"jurisdiction\": \"AUS\"}\n            meetings_data = await self.make_request(http_client, \"GET\", meetings_url, headers=headers, params=params)\n\n            if not meetings_data or not meetings_data.get(\"meetings\"):\n                return self._format_response(all_races, start_time, is_success=True)\n\n            for meeting in meetings_data[\"meetings\"]:\n                for race_summary in meeting.get(\"races\", []):\n                    try:\n                        parsed_race = self._parse_ras_race(meeting, race_summary)\n                        all_races.append(parsed_race)\n                    except Exception as e:\n                        log.error(\n                            \"RacingAndSportsAdapter: Failed to parse race\",\n                            meeting=meeting.get(\"venueName\"),\n                            error=str(e),\n                            exc_info=True,\n                        )\n\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(\"RacingAndSportsAdapter: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(\"RacingAndSportsAdapter: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        fetch_duration = (datetime.now() - start_time).total_seconds()\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": fetch_duration,\n            },\n        }\n\n    def _parse_ras_race(self, meeting: Dict[str, Any], race: Dict[str, Any]) -> Race:\n        runners = [\n            Runner(\n                number=rd.get(\"runnerNumber\"),\n                name=rd.get(\"horseName\", \"Unknown\"),\n                scratched=rd.get(\"isScratched\", False),\n            )\n            for rd in race.get(\"runners\", [])\n        ]\n\n        return Race(\n            id=f\"ras_{race.get('raceId')}\",\n            venue=meeting.get(\"venueName\", \"Unknown Venue\"),\n            race_number=race.get(\"raceNumber\"),\n            start_time=datetime.fromisoformat(race.get(\"startTime\")),\n            runners=runners,\n            source=self.source_name,\n        )\n",
    "python_service/adapters/sporting_life_adapter.py": "# python_service/adapters/sporting_life_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return \" \".join(text.strip().split()) if text else None\n\n\nclass SportingLifeAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"SportingLife\", base_url=\"https://www.sportinglife.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response_html = await self.make_request(http_client, \"GET\", \"/horse-racing/racecards\")\n        if not response_html:\n            return []\n        soup = BeautifulSoup(response_html, \"html.parser\")\n        links = {a[\"href\"] for a in soup.select(\"a.hr-race-card-meeting__race-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response_html = await self.make_request(http_client, \"GET\", url)\n            if not response_html:\n                return None\n            soup = BeautifulSoup(response_html, \"html.parser\")\n            track_name = _clean_text(soup.select_one(\"a.hr-race-header-course-name__link\").get_text())\n            race_time_str = _clean_text(soup.select_one(\"span.hr-race-header-time__time\").get_text())\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            active_link = soup.select_one(\"a.hr-race-header-navigation-link--active\")\n            race_number = soup.select(\"a.hr-race-header-navigation-link\").index(active_link) + 1 if active_link else 1\n            runners = [self._parse_runner(row) for row in soup.select(\"div.hr-racing-runner-card\")]\n            return Race(\n                id=f\"sl_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                venue=track_name,\n                race_number=race_number,\n                start_time=start_time,\n                runners=[r for r in runners if r],\n                source=self.source_name,\n            )\n        except Exception as e:\n            log.error(\"Error parsing race from SportingLife\", url=url, exc_info=e)\n            return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"a.hr-racing-runner-horse-name\").get_text())\n            num_str = _clean_text(row.select_one(\"span.hr-racing-runner-saddle-cloth-no\").get_text())\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"span.hr-racing-runner-odds\").get_text())\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())}\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except Exception as e:\n            log.warning(\"Failed to parse runner from SportingLife\", exc_info=e)\n            return None\n",
    "python_service/adapters/the_racing_api_adapter.py": "# python_service/adapters/theracingapi_adapter.py\n\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\n\nimport httpx\nimport structlog\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\nclass TheRacingApiAdapter(BaseAdapter):\n    \"\"\"Adapter for the high-value JSON-based The Racing API.\"\"\"\n\n    def __init__(self, config):\n        super().__init__(source_name=\"TheRacingAPI\", base_url=\"https://api.theracingapi.com/v1/\")\n        self.api_key = config.THE_RACING_API_KEY\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        if not self.api_key:\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"ConfigurationError: THE_RACING_API_KEY not set\"\n            )\n\n        try:\n            endpoint = f\"racecards?date={date}&course=all&region=gb,ire\"\n            headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n            response = await self.make_request(http_client, \"GET\", endpoint, headers=headers)\n\n            if not response:\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No response from API.\"\n                )\n\n            response_json = response.json()\n            if not response_json or not response_json.get(\"racecards\"):\n                return self._format_response(\n                    [], start_time, is_success=True, error_message=\"No racecards found in API response.\"\n                )\n\n            all_races = self._parse_races(response_json[\"racecards\"])\n            return self._format_response(all_races, start_time, is_success=True)\n        except httpx.HTTPError as e:\n            log.error(f\"{self.source_name}: HTTP request failed after retries\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=\"API request failed after multiple retries.\"\n            )\n        except Exception as e:\n            log.error(f\"{self.source_name}: An unexpected error occurred\", error=str(e), exc_info=True)\n            return self._format_response(\n                [], start_time, is_success=False, error_message=f\"An unexpected error occurred: {e}\"\n            )\n\n    def _parse_races(self, racecards: List[Dict[str, Any]]) -> List[Race]:\n        races = []\n        for race_data in racecards:\n            try:\n                start_time = datetime.fromisoformat(race_data[\"off_time\"].replace(\"Z\", \"+00:00\"))\n\n                race = Race(\n                    id=f\"tra_{race_data['race_id']}\",\n                    venue=race_data[\"course\"],\n                    race_number=race_data[\"race_no\"],\n                    start_time=start_time,\n                    runners=self._parse_runners(race_data.get(\"runners\", [])),\n                    source=self.source_name,\n                    race_name=race_data.get(\"race_name\"),\n                    distance=race_data.get(\"distance_f\"),\n                )\n                races.append(race)\n            except Exception as e:\n                log.error(f\"{self.source_name}: Error parsing race\", race_id=race_data.get(\"race_id\"), error=str(e))\n        return races\n\n    def _parse_runners(self, runners_data: List[Dict[str, Any]]) -> List[Runner]:\n        runners = []\n        for i, runner_data in enumerate(runners_data):\n            try:\n                odds_data = {}\n                if runner_data.get(\"odds\"):\n                    win_odds = Decimal(str(runner_data[\"odds\"][0][\"odds_decimal\"]))\n                    odds_data[self.source_name] = OddsData(\n                        win=win_odds, source=self.source_name, last_updated=datetime.now()\n                    )\n\n                runners.append(\n                    Runner(\n                        number=runner_data.get(\"number\", i + 1),\n                        name=runner_data[\"horse\"],\n                        odds=odds_data,\n                        jockey=runner_data.get(\"jockey\"),\n                        trainer=runner_data.get(\"trainer\"),\n                    )\n                )\n            except Exception as e:\n                log.error(\n                    f\"{self.source_name}: Error parsing runner\", runner_name=runner_data.get(\"horse\"), error=str(e)\n                )\n        return runners\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool = True, error_message: str = None\n    ) -> Dict[str, Any]:\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/timeform_adapter.py": "# python_service/adapters/timeform_adapter.py\n\nimport asyncio\nfrom datetime import datetime\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n\nimport httpx\nimport structlog\nfrom bs4 import BeautifulSoup\nfrom bs4 import Tag\n\nfrom ..models import OddsData\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.odds import parse_odds_to_decimal\nfrom .base import BaseAdapter\n\nlog = structlog.get_logger(__name__)\n\n\ndef _clean_text(text: Optional[str]) -> Optional[str]:\n    return \" \".join(text.strip().split()) if text else None\n\n\nclass TimeformAdapter(BaseAdapter):\n    def __init__(self, config):\n        super().__init__(source_name=\"Timeform\", base_url=\"https://www.timeform.com\")\n\n    async def fetch_races(self, date: str, http_client: httpx.AsyncClient) -> Dict[str, Any]:\n        start_time = datetime.now()\n        try:\n            race_links = await self._get_race_links(http_client)\n            tasks = [self._fetch_and_parse_race(link, http_client) for link in race_links]\n            races = [race for race in await asyncio.gather(*tasks) if race]\n            return self._format_response(races, start_time, is_success=True)\n        except Exception as e:\n            return self._format_response([], start_time, is_success=False, error_message=str(e))\n\n    async def _get_race_links(self, http_client: httpx.AsyncClient) -> List[str]:\n        response = await self.make_request(http_client, \"GET\", \"/horse-racing/racecards\")\n        if not response:\n            return []\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        links = {a[\"href\"] for a in soup.select(\"a.rp-racecard-off-link[href]\")}\n        return [f\"{self.base_url}{link}\" for link in links]\n\n    async def _fetch_and_parse_race(self, url: str, http_client: httpx.AsyncClient) -> Optional[Race]:\n        try:\n            response = await self.make_request(http_client, \"GET\", url)\n            if not response:\n                return None\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            track_name = _clean_text(soup.select_one(\"h1.rp-raceTimeCourseName_name\").get_text())\n            race_time_str = _clean_text(soup.select_one(\"span.rp-raceTimeCourseName_time\").get_text())\n            start_time = datetime.strptime(f\"{datetime.now().date()} {race_time_str}\", \"%Y-%m-%d %H:%M\")\n            all_times = [_clean_text(a.get_text()) for a in soup.select(\"a.rp-racecard-off-link\")]\n            race_number = all_times.index(race_time_str) + 1 if race_time_str in all_times else 1\n            runners = [self._parse_runner(row) for row in soup.select(\"div.rp-horseTable_mainRow\")]\n            return Race(\n                id=f\"tf_{track_name.replace(' ', '')}_{start_time.strftime('%Y%m%d')}_R{race_number}\",\n                venue=track_name,\n                race_number=race_number,\n                start_time=start_time,\n                runners=[r for r in runners if r],\n                source=self.source_name,\n            )\n        except Exception as e:\n            log.error(\"Error parsing race from Timeform\", url=url, exc_info=e)\n            return None\n\n    def _parse_runner(self, row: Tag) -> Optional[Runner]:\n        try:\n            name = _clean_text(row.select_one(\"a.rp-horseTable_horse-name\").get_text())\n            num_str = _clean_text(row.select_one(\"span.rp-horseTable_horse-number\").get_text()).strip(\"()\")\n            number = int(\"\".join(filter(str.isdigit, num_str)))\n            odds_str = _clean_text(row.select_one(\"button.rp-bet-placer-btn__odds\").get_text())\n            win_odds = parse_odds_to_decimal(odds_str)\n            odds_data = (\n                {self.source_name: OddsData(win=win_odds, source=self.source_name, last_updated=datetime.now())}\n                if win_odds and win_odds < 999\n                else {}\n            )\n            return Runner(number=number, name=name, odds=odds_data)\n        except Exception as e:\n            log.warning(\"Failed to parse runner from Timeform\", exc_info=e)\n            return None\n\n    def _format_response(\n        self, races: List[Race], start_time: datetime, is_success: bool, error_message: str = None\n    ) -> Dict[str, Any]:\n        return {\n            \"races\": races,\n            \"source_info\": {\n                \"name\": self.source_name,\n                \"status\": \"SUCCESS\" if is_success else \"FAILED\",\n                \"races_fetched\": len(races),\n                \"error_message\": error_message,\n                \"fetch_duration\": (datetime.now() - start_time).total_seconds(),\n            },\n        }\n",
    "python_service/adapters/tvg_adapter.py": "# python_service/adapters/tvg_adapter.py\nfrom datetime import datetime\nfrom typing import Any, List, Optional\n\nfrom ..models import Race, Runner\nfrom ..utils.text import clean_text\nfrom .base_v3 import BaseAdapterV3\n\nclass TVGAdapter(BaseAdapterV3):\n    \"\"\"Adapter for fetching US racing data from the TVG API, using BaseAdapterV3.\"\"\"\n\n    SOURCE_NAME = \"TVG\"\n    BASE_URL = \"https://api.tvg.com/v2/races/\"\n\n    def __init__(self, config=None):\n        super().__init__(source_name=self.SOURCE_NAME, base_url=self.BASE_URL)\n        self.config = config or {}\n        self.tvg_api_key = self.config.TVG_API_KEY\n        if not self.tvg_api_key:\n            self.logger.warning(\"TVG_API_KEY is not set. Adapter will be non-functional.\")\n\n    async def _fetch_data(self, date: str) -> Any:\n        \"\"\"Fetches all race details for a given date by first getting tracks.\"\"\"\n        if not self.tvg_api_key:\n            return None\n\n        headers = {\"X-Api-Key\": self.tvg_api_key}\n        tracks_response = await self.http_client.get(f\"{self.BASE_URL}summary?date={date}&country=USA\", headers=headers)\n        tracks_response.raise_for_status()\n        tracks_data = tracks_response.json()\n\n        all_race_details = []\n        for track in tracks_data.get('tracks', []):\n            track_id = track.get('id')\n            for race in track.get('races', []):\n                race_id = race.get('id')\n                if track_id and race_id:\n                    details_response = await self.http_client.get(f\"{self.BASE_URL}{track_id}/{race_id}\", headers=headers)\n                    if details_response.status_code == 200:\n                        all_race_details.append(details_response.json())\n        return all_race_details\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        \"\"\"Parses the list of detailed race JSON objects into Race models.\"\"\"\n        races = []\n        for race_detail in raw_data:\n            try:\n                track = race_detail.get('track', {})\n                race_info = race_detail.get('race', {})\n\n                runners = []\n                for runner_data in race_detail.get('runners', []):\n                    if runner_data.get('scratched'):\n                        continue\n\n                    odds = runner_data.get('odds', {})\n                    current_odds = odds.get('currentPrice', {})\n                    odds_str = current_odds.get('fractional') or odds.get('morningLinePrice', {}).get('fractional')\n\n                    runners.append(Runner(\n                        number=int(runner_data.get('programNumber', '0').replace('A', '')),\n                        name=clean_text(runner_data.get('name')),\n                        odds=odds_str,\n                        scratched=False\n                    ))\n\n                if runners:\n                    race = Race(\n                        id=f\"tvg_{track.get('code', 'UNK')}_{race_info.get('date', 'NODATE')}_{race_info.get('number', 0)}\",\n                        venue=track.get('name'),\n                        race_number=race_info.get('number'),\n                        start_time=datetime.fromisoformat(race_info.get('postTime').replace('Z', '+00:00')),\n                        runners=runners,\n                        source=self.SOURCE_NAME\n                    )\n                    races.append(race)\n            except (ValueError, AttributeError):\n                self.logger.warning(\"Failed to parse a TVG race detail.\", exc_info=True)\n                continue\n        return races\n\n    async def fetch_races(self, date: str, http_client):\n        pass\n",
    "python_service/adapters/utils.py": "# This file is intentionally left blank after the refactoring in \"Operation: The A+ Trifecta\".\n# The odds parsing logic has been centralized in python_service/utils/odds.py.\n# The text normalization logic has been centralized in python_service/utils/text.py.\n"
}