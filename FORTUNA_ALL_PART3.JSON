{
    ".env.example": "# .env.example\n# Copy this file to .env and fill in your actual credentials.\n\n# --- Application Security (Required) ---\nAPI_KEY=\"YOUR_SECRET_API_KEY_HERE\"\n\n# --- Betfair API Credentials (Required for LiveOddsMonitor) ---\nBETFAIR_APP_KEY=\"YOUR_APP_KEY_HERE\"\nBETFAIR_USERNAME=\"YOUR_USERNAME_HERE\"\nBETFAIR_PASSWORD=\"YOUR_PASSWORD_HERE\"\n\n# --- Optional Adapter Keys ---\nTVG_API_KEY=\"\"\nRACING_AND_SPORTS_TOKEN=\"\"\nPOINTSBET_API_KEY=\"\"\n\n# --- CORS Configuration (Optional) ---\n# A comma-separated list of allowed origins for the API.\n# Example: ALLOWED_ORIGINS=\"http://localhost:3000,https://your-production-domain.com\"\nALLOWED_ORIGINS=\"http://localhost:3000,http://localhost:3001\"\n\n# --- Greyhound Adapter (Optional) ---\n# To enable the Greyhound adapter, provide the full base URL for the API.\n# If this is left blank, the adapter will be disabled.\nGREYHOUND_API_URL=\"\"\n\n# --- The Racing API (Optional but Recommended) ---\n# Get a key from https://www.theracingapi.com/\nTHE_RACING_API_KEY=\"\"\n\n# --- Optional Caching Backend ---\n# If you have a Redis server, provide the URL here to enable a persistent cache.\n# If left blank, a temporary in-memory cache will be used.\nREDIS_URL=\"\"\n",
    ".gitignore": "# Byte-compiled / optimized files\n__pycache__/\n*.pyc\n\n# Distribution / packaging\nbuild/\ndist/\n*.egg-info/\n\n# Unit test / coverage reports\n.pytest_cache/\n.coverage\n\n# Environments\n.venv/\nvenv/\nenv/\n\n# IDE settings\n.vscode/\n.idea/\n\n# Database files\n*.db\n*.sqlite\n*.sqlite3\n\n# Node.js\nnode_modules/\n/ui/node_modules/\n/ui/build/\n\n# Environment files\n.env\n\n# Log files\n*.log\n*.log*\n",
    "ARCHITECTURAL_MANDATE.md": "# The Fortuna Faucet Architectural Mandate\n\n## The Prime Directive: The Two-Pillar System\n\nThe project's architecture is a lean, hyper-powerful, two-pillar system chosen for its clarity, maintainability, and performance.\n\n## Pillar 1: The Asynchronous Python Backend\n\nThe backend is a modern, asynchronous service built on **FastAPI**. Its architecture includes:\n\n1.  **The `OddsEngine`:** A central, async orchestrator for data collection.\n2.  **The Resilient `BaseAdapter`:** An abstract base class providing professional-grade features.\n3.  **The Adapter Fleet:** A modular system of 'plugin' adapters for data sources.\n4.  **Pydantic Data Contracts:** Strict, validated Pydantic models for data integrity.\n5.  **The `TrifectaAnalyzer` (Intelligence Layer):** A dedicated module for scoring and qualifying opportunities.\n\n## Pillar 2: The TypeScript Frontend\n\nThe frontend is a modern, feature-rich web application built on **Next.js** and **TypeScript**.",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `scrape-sort_races-toteboards`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n",
    "README.md": "# Fortuna Faucet\n\nThis repository contains the Fortuna Faucet project, a global, multi-source horse racing analysis tool. The project is a two-pillar system: a powerful, asynchronous Python backend that performs all data gathering, and a feature-rich TypeScript frontend.\n\n---\n\n## \ud83d\ude80 Quick Start\n\n### 1. Configure Your Environment\n\nRun the setup script to ensure Python and Node.js are correctly configured and all dependencies are installed.\n\n```batch\n# From the project root:\nsetup_windows.bat\n```\n\n### 2. Launch the Application\n\nRun the master launch script. This will start both the Python backend and the TypeScript frontend servers in parallel.\n\n```batch\n# From the project root:\nrun_fortuna.bat\n```\n\nThe backend API will be available at `http://localhost:8000`.\nThe frontend will be available at `http://localhost:3000`.\n\n### 4. Using the API\n\nTo use the API directly (e.g., with `curl` or other tools), you must provide the `API_KEY` set in your `.env` file via the `X-API-Key` header. This is required for all endpoints except `/health`.\n\n```bash\n# Example: Test the qualified races endpoint\ncurl -H \"X-API-Key: YOUR_SECRET_API_KEY_HERE\" http://localhost:8000/api/races/qualified/trifecta\n```\n\n---\n\n## \ud83d\ude80 For Windows Users\n\nThis project now includes a complete, one-click installation and management suite for an enhanced Windows experience.\n\nFor the best experience and full setup instructions, please see the dedicated guide: **[README_WINDOWS.md](README_WINDOWS.md)**\n",
    "README_WINDOWS.md": "# \ud83c\udfaf FORTUNA FAUCET - Windows Installation Guide\n\n## Quick Start (3 Minutes)\n\n### Step 1: Download and Extract\n1. Download the complete Fortuna Faucet package\n2. Extract to `C:\\\\FortunaFaucet` (recommended)\n\n### Step 2: Run the Installer\n1. Right-click `INSTALL_FORTUNA.bat`\n2. Select \"Run as Administrator\"\n3. Wait for automatic installation (3-5 minutes)\n\n### Step 3: Configure Your API Keys\n1. Open `.env` file in Notepad\n2. Add your API credentials:\n   ```\n   API_KEY=your_secret_key_here\n   ```\n3. Save and close\n\n### Step 4: Launch Fortuna\n1. Double-click **\"Launch Fortuna\"** shortcut on your desktop\n2. Wait 10 seconds for services to start\n3. Dashboard opens automatically in your browser\n\n## Desktop Shortcuts\n\nAfter installation, you'll have three shortcuts:\n\n- **Launch Fortuna** \ud83d\ude80 - Starts all services\n- **Fortuna Monitor** \ud83d\udcca - Opens status monitor\n- **Stop Fortuna** \ud83d\uded1 - Cleanly stops all services\n\n## Troubleshooting\n\n### \"Backend Offline\" Error\n1. Run `STOP_FORTUNA.bat`\n2. Wait 10 seconds\n3. Run `LAUNCH_FORTUNA.bat` again\n\n### Can't Find .env File\nThe .env file should be in the same folder as LAUNCH_FORTUNA.bat.\nIf missing, copy .env.example to .env\n\n\n## Service Management (Advanced)\n\nThe Fortuna Faucet backend runs as a persistent Windows Service, meaning it starts with your computer and runs silently in the background.\n\n- **To Install/Start the Service:** If you ever need to manually install it, right-click `install_service.bat` and choose \"Run as Administrator\".\n- **To Uninstall the Service:** To completely remove the background service, right-click `uninstall_service.bat` and choose \"Run as Administrator\".\n\nThis allows the Electron application (the user interface) to be opened and closed without interrupting the core data collection engine.\n",
    "ROADMAP_APPENDICES.md": "# Checkmate: Strategic Appendices\n\n**Purpose:** This document is the permanent home for the high-value strategic intelligence salvaged from the deprecated `ROADMAP.md`. It contains our long-term goals and a library of resources to accelerate development.\n\n---\n\n## Appendix A: V3 Adapter Backlog (The \"Treasure Chest\")\n\nThis is the definitive, prioritized list of data sources to be implemented.\n\n### Category 1: High-Value Data Feeds (API-First)\n*   BetfairDataScientistThoroughbred\n*   BetfairDataScientistGreyhound\n*   racingandsports\n*   sportinglife (requires investigation)\n*   racingpost (requires auth)\n\n### Category 2: Premium Global Sources (Scraping)\n*   timeform\n*   attheraces\n*   racingtv\n*   oddschecker\n*   betfair\n*   horseracingnation\n*   brisnet\n\n### Category 3: North American Authorities & ADWs\n*   equibase\n*   drf\n*   fanduel\n*   twinspires\n*   1stbet\n*   nyrabets\n*   xpressbet\n\n### Category 4: European Authorities & Markets\n*   francegalop\n*   deutschergalopp\n*   svenskgalopp\n*   pmu\n\n### Category 5: Asia-Pacific & Rest of World\n*   tab\n*   punters\n*   racingaustralia\n*   hkjc\n*   jra\n*   goldcircle\n*   emiratesracing\n\n### Category 6: Specialized Disciplines (Harness & Greyhound)\n*   usta\n*   standardbredcanada\n*   harnessracingaustralia\n*   gbgb\n*   grireland\n*   thedogs\n\n---\n\n## Appendix B: Open-Source Intelligence Leads\n\nA curated list of projects and resources to accelerate development.\n\n1.  **joenano/rpscrape:** https://github.com/joenano/rpscrape\n2.  **Daniel57910/horse-scraper:** https://github.com/Daniel57910/horse-scraper\n3.  **Web Scraping for HKJC:** https://gist.github.com/tomfoolc/ef039b229c8e97bd40c5493174bca839\n3.  **Web Scraping for HKJC:** https://gist.github.com/tomfoolc/ef039b229c8e97bd40c5493174bca839\n4.  **LibHunt horse-racing projects:** https://www.libhunt.com/topic/horse-racing\n5.  **Web data scraping blog:** https://www.3idatascing.com/how-does-web-data-scraping-help-in-horse-racing-and-greyhound/\n6.  **Fawazk/Greyhoundscraper:** https://github.com/Fawazk/Greyhoundscraper\n7.  **Betfair Hub Models Scraping Tutorial:** https://betfair-datascientists.github.io/tutorials/How_to_Automate_3/\n8.  **scrapy-horse-racing:** https://github.com/chrism-attmann/scrapy-horse-racing\n9.  **horse-racing-data:** https://github.com/jeffkub/horse-racing-data\n\n\n## C. Un-Mined Gems (Future Campaign Candidates)\n\n*Discovered during a full operational review. These represent high-value, validated concepts from the project's history that are candidates for future development campaigns.*\n\n### C1. The Intelligence Layer (\"The Analyst\")\n\n- **Concept:** A dedicated analysis and scoring engine (`analyzer.py`) that sits on top of the `OddsEngine`. It would provide a high-value `/api/races/qualified` endpoint, transforming the API from a data funnel into a source of actionable intelligence.\n- **Origin:** Inspired by the `TrifectaAnalyzer` logic in the legacy `checkmate_engine.py` prototype. Formally proposed as \"Operation: Activate the Analyst\".\n- **Value:** Fulfills the project's original vision of finding opportunities, not just collecting data. Creates a clean architectural separation between data collection and business logic.\n\n### C2. The Legacy Test Suite (\"The Oracle's Library\")\n\n- **Concept:** Repurpose the vast collection of existing tests and mock data located in `attic/legacy_tests_pre_triage`.\n- **Origin:** Identified during the full repository file catalog audit.\n- **Value:** Provides a massive shortcut to production hardening. Allows the project to increase test coverage and resilience by validating the CORE services against hundreds of historical edge cases.\n\n### C3. The AI Architectural Reviews (\"The Council's Wisdom\")\n\n- **Concept:** Synthesize the expert analysis and architectural recommendations from the multiple AI model reviews stored in the Digital Attic (`*.md.txt` files).\n- **Origin:** Explicitly mentioned in the Gemini928 handoff memo as \"Architectural Parables\".\n- **Value:** A source of high-level architectural consulting. These documents may contain actionable advice on performance, security, or design patterns that could significantly improve the current architecture.\n\n### C4. The Interactive Dashboard Prototype (\"The Command Deck\")\n\n- **Concept:** Create a modern, internal, real-time command deck for visualizing engine data and testing new `Analyzer` models.\n- **Origin:** Inspired by the `portable_demo_v2.py` Streamlit application from the attic.\n- **Value:** An invaluable tool for development, debugging, and real-time operational insight, far more intuitive than raw logs or API calls.",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2) ---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "chart_scraper.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Chart Scraper (v3 - Perfected)\n# ==============================================================================\n# This script downloads and parses historical race result charts from Equibase PDF files\n# using a direct-download URL for combined daily charts.\n# ==============================================================================\n\nimport requests\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom bs4 import BeautifulSoup\nfrom tabula import read_pdf\nimport os\nimport time\nimport pikepdf\n\nclass ChartScraper:\n    \"\"\"Orchestrates the downloading, decrypting, and parsing of combined Equibase PDF charts.\"\"\"\n\n    def __init__(self):\n        self.download_dir = \"results_archive\"\n        self.pdf_dir = os.path.join(self.download_dir, 'pdf')\n        self.unlocked_pdf_dir = os.path.join(self.download_dir, 'pdf_unlocked')\n        self.csv_dir = os.path.join(self.download_dir, 'csv')\n        self.track_summary_url = \"https://www.equibase.com/static/chart/summary/\"\n        self.pdf_url_pattern = \"https://www.equibase.com/static/chart/pdf/{TID}{MMDDYY}{CTRY}.pdf\"\n\n    def _get_yesterday_date(self) -> tuple[str, str, str]:\n        yesterday = datetime.now() - timedelta(days=1)\n        summary_date = yesterday.strftime(\"%Y%m%d\")\n        pdf_chart_date = yesterday.strftime(\"%m%d%y\") # New format for combined chart URL\n        display_date = yesterday.strftime(\"%m/%d/%Y\")\n        return summary_date, pdf_chart_date, display_date\n\n    def _get_yesterday_tracks(self, url_date_format: str) -> list[str]:\n        full_url = f\"{self.track_summary_url}{url_date_format}.html\"\n        print(f\"-> Searching for tracks at: {full_url}\")\n        try:\n            response = requests.get(full_url, timeout=10)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            print(f\"Error fetching track summary page: {e}\")\n            return []\n\n        soup = BeautifulSoup(response.content, 'lxml')\n        track_codes = set()\n        for a_tag in soup.find_all('a', href=True):\n            if 'TID=' in a_tag['href']:\n                try:\n                    track_code = a_tag['href'].split('TID=')[1].split('&')[0]\n                    track_codes.add(track_code)\n                except IndexError:\n                    continue\n\n        unique_tracks = sorted(list(track_codes))\n        print(f\"-> Found {len(unique_tracks)} unique tracks: {unique_tracks}\")\n        return unique_tracks\n\n    def _download_and_parse_chart(self, track_code: str, chart_date: str):\n        pdf_url = self.pdf_url_pattern.format(TID=track_code, MMDDYY=chart_date, CTRY='USA')\n        filename_base = f\"{track_code}_{chart_date}_FULL\"\n        pdf_path = os.path.join(self.pdf_dir, f\"{filename_base}.pdf\")\n        unlocked_pdf_path = os.path.join(self.unlocked_pdf_dir, f\"{filename_base}_unlocked.pdf\")\n        csv_path = os.path.join(self.csv_dir, f\"{filename_base}_scraped.csv\")\n\n        print(f\"   - Attempting full chart for {track_code}...\")\n        try:\n            pdf_response = requests.get(pdf_url, stream=True, timeout=20)\n            content_type = pdf_response.headers.get('Content-Type', '')\n            content_length = int(pdf_response.headers.get('Content-Length', 0))\n\n            if 'application/pdf' not in content_type or content_length < 20000: # Increase size threshold for full charts\n                print(\"     -> Not a valid combined PDF (chart may not exist).\")\n                return\n\n            with open(pdf_path, 'wb') as f:\n                f.write(pdf_response.content)\n            print(f\"     -> Downloaded locked PDF to {pdf_path}\")\n\n        except requests.exceptions.RequestException as e:\n            print(f\"     -> Error downloading PDF: {e}\")\n            return\n\n        try:\n            with pikepdf.open(pdf_path, allow_overwriting_input=True) as pdf:\n                pdf.save(unlocked_pdf_path)\n            print(f\"     -> Saved unlocked PDF to {unlocked_pdf_path}\")\n        except Exception as e:\n            print(f\"     -> Failed to unlock PDF with pikepdf: {e}\")\n            return\n\n        try:\n            tables = read_pdf(unlocked_pdf_path, pages='all', multiple_tables=True, lattice=True, silent=True)\n            if not tables:\n                print(\"     -> Tabula found no tables to extract from unlocked PDF.\")\n                return\n\n            combined_df = pd.concat(tables, ignore_index=True)\n            combined_df.to_csv(csv_path, index=False)\n            print(f\"     -> SUCCESSFULLY extracted {len(tables)} tables to {csv_path}\")\n        except Exception as e:\n            print(f\"     -> Error during Tabula PDF scraping: {e}\")\n\n    def run(self):\n        os.makedirs(self.pdf_dir, exist_ok=True)\n        os.makedirs(self.unlocked_pdf_dir, exist_ok=True)\n        os.makedirs(self.csv_dir, exist_ok=True)\n\n        summary_date, chart_date, display_date = self._get_yesterday_date()\n        print(f\"\\\\n--- Starting Perfected Equibase Chart Scraper for: {display_date} ---\")\n\n        tracks = self._get_yesterday_tracks(summary_date)\n        if not tracks:\n            print(\"\\\\n*** No tracks found for yesterday. Halting. ***\")\n            return\n\n        print(\"\\\\n--- Downloading, Unlocking, and Parsing Full Daily Charts ---\")\n        for track in tracks:\n            print(f\"\\\\n[TRACK: {track}]\")\n            self._download_and_parse_chart(track, chart_date)\n            time.sleep(1)\n\n        print(f\"\\\\n--- Scraper Finished! Check the '{self.csv_dir}' folder. ---\")\n\nif __name__ == \"__main__\":\n    scraper = ChartScraper()\n    scraper.run()",
    "command_deck.py": "import streamlit as st\nimport pandas as pd\nimport requests\nimport os\nfrom dotenv import load_dotenv\n\n# --- Configuration ---\nst.set_page_config(layout=\"wide\", page_title=\"Fortuna Faucet Command Deck\")\nload_dotenv() # Load .env file\n\nAPI_BASE_URL = \"http://127.0.0.1:8000\"\nAPI_KEY = os.getenv(\"DEV_API_KEY\", \"test_api_key\")\nHEADERS = {\"X-API-Key\": API_KEY}\n\n# --- Helper Functions ---\n@st.cache_data(ttl=30)\ndef get_api_data(endpoint: str):\n    \"\"\"Fetches data from a given API endpoint.\"\"\"\n    try:\n        url = f\"{API_BASE_URL}{endpoint}\"\n        st.write(f\"*Fetching data from: `{url}`*\")\n        response = requests.get(url, headers=HEADERS)\n        response.raise_for_status()\n        return response.json(), None\n    except requests.exceptions.RequestException as e:\n        return None, str(e)\n\n# --- UI Layout ---\nst.title(\"\ud83d\ude80 Fortuna Faucet Command Deck\")\nst.markdown(\"Real-time operational dashboard for the Fortuna Faucet backend.\")\n\n# --- Sidebar Controls ---\nst.sidebar.header(\"Controls\")\nanalyzer_selection = st.sidebar.selectbox(\n    'Select Analyzer',\n    ['trifecta'] # In the future, this could be populated from an API endpoint\n)\n\nif st.sidebar.button(\"Clear Cache & Refresh Data\"):\n    st.cache_data.clear()\n\n# --- Data Display ---\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.header(f\"\ud83d\udcc8 Qualified Races (`{analyzer_selection}`)\")\n    qualified_data, error = get_api_data(f\"/api/races/qualified/{analyzer_selection}\")\n\n    if error:\n        st.error(f\"**Failed to fetch qualified races:**\\\\n\\\\n{error}\")\n    elif qualified_data:\n        if qualified_data:\n            # Corrected to use 'id' instead of 'race_id' to match the Pydantic model\n            df = pd.json_normalize(qualified_data, record_path=['runners'], meta=['id', 'venue', 'race_number', 'start_time'])\n            st.dataframe(df)\n        else:\n            st.info(f\"No races were qualified by the '{analyzer_selection}' analyzer.\")\n    else:\n        st.info(\"Awaiting data...\")\n\nwith col2:\n    st.header(\"\ud83d\udcca Adapter Status\")\n    status_data, error = get_api_data(\"/api/adapters/status\")\n\n    if error:\n        st.error(f\"**Failed to fetch adapter status:**\\\\n\\\\n{error}\")\n    elif status_data:\n        st.dataframe(pd.DataFrame(status_data))\n    else:\n        st.info(\"Awaiting data...\")",
    "convert_to_json.py": "# convert_to_json.py\n# This script now contains the full, enlightened logic to handle all manifest formats and path styles.\n\nimport json\nimport os\nimport re\nimport sys\nfrom multiprocessing import Process, Queue\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_DIR = 'ReviewableJSON'\nFILE_PROCESSING_TIMEOUT = 10\n\n# --- ENLIGHTENED PARSING LOGIC (V2) ---\ndef extract_and_normalize_path(line: str) -> str | None:\n    \"\"\"\n    Extracts a file path from a line, handling multiple formats, and normalizes it.\n    Handles:\n    - Markdown links: `* [display](path)`\n    - Plain paths in backticks: ``- `path.py` - description``\n    - Plain paths with list markers: `- path/to/file.py`\n    \"\"\"\n    line = line.strip()\n    if not line or line.startswith('#'):\n        return None\n\n    # 1. Check for Markdown link format\n    md_match = re.search(r'\\[.*\\]\\((https?://[^\\)]+)\\)', line)\n    if md_match:\n        path = md_match.group(1)\n    else:\n        # 2. Check for paths in backticks\n        bt_match = re.search(r'`([^`]+)`', line)\n        if bt_match:\n            path = bt_match.group(1)\n        else:\n            # 3. Assume plain path, stripping list markers\n            path = re.sub(r'^[*-]\\s*', '', line).split(' ')[0]\n\n    # --- Path Standardization ---\n    if not path or not ('.' in path or '/' in path):\n        return None # Not a valid path\n\n    # If it's a full raw GitHub URL, extract the local path\n    if path.startswith('https://raw.githubusercontent.com/'):\n        path = '/'.join(path.split('/main/')[1:])\n\n    # Final check for valid file extensions or structure\n    if not re.search(r'(\\.[a-zA-Z0-9]+$)|(^[\\w/]+$)', path):\n        return None\n\n    return path.strip()\n\n# --- SANDBOXED FILE READ (Unchanged) ---\ndef _sandboxed_file_read(file_path, q):\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        q.put({\"file_path\": file_path, \"content\": content})\n    except Exception as e:\n        q.put({\"error\": str(e)})\n\ndef convert_file_to_json_sandboxed(file_path):\n    q = Queue()\n    p = Process(target=_sandboxed_file_read, args=(file_path, q))\n    p.start()\n    p.join(timeout=FILE_PROCESSING_TIMEOUT)\n    if p.is_alive():\n        p.terminate()\n        p.join()\n        return {\"error\": f\"Timeout: File processing took longer than {FILE_PROCESSING_TIMEOUT} seconds.\"}\n    if not q.empty():\n        return q.get()\n    return {\"error\": \"Unknown error in sandboxed read process.\"}\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'='*60}\\nStarting IRONCLAD JSON backup process... (Enlightened Scribe Edition)\\n{'='*60}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        if not os.path.exists(manifest):\n            print(f\"    [WARNING] Manifest not found: {manifest}\")\n            continue\n\n        with open(manifest, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n\n        paths_found = 0\n        for line in lines:\n            path = extract_and_normalize_path(line)\n            if path:\n                all_local_paths.append(path)\n                paths_found += 1\n        print(f\"    --> Found {paths_found} valid file paths.\")\n\n    if not all_local_paths:\n        print(\"\\n[FATAL] No valid file paths found in any manifest. Aborting.\")\n        sys.exit(1)\n\n    unique_local_paths = sorted(list(set(all_local_paths)))\n    print(f\"\\nFound a total of {len(unique_local_paths)} unique files to process.\")\n    processed_count, failed_count = 0, 0\n\n    for local_path in unique_local_paths:\n        print(f\"\\nProcessing: {local_path}\")\n        json_data = convert_file_to_json_sandboxed(local_path)\n        if json_data and \"error\" not in json_data:\n            output_path = os.path.join(OUTPUT_DIR, local_path + '.json')\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(json_data, f, indent=4)\n            print(f\"    [SUCCESS] Saved backup to {output_path}\")\n            processed_count += 1\n        else:\n            error_msg = json_data.get(\"error\", \"Unknown error\") if json_data else \"File not found\"\n            print(f\"    [ERROR] Failed to process {local_path}: {error_msg}\")\n            failed_count += 1\n\n    print(f\"\\n{'='*60}\\nBackup process complete.\\nSuccessfully processed: {processed_count}/{len(unique_local_paths)}\\nFailed/Skipped: {failed_count}\\n{'='*60}\")\n\n    if failed_count > 0:\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()",
    "create_fortuna_json.py": "# create_fortuna_json.py\n# This script now dynamically reads the manifests and creates three separate, categorized JSON packages.\n\nimport json\nimport os\nimport re\nimport sys\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST.md', 'MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_FILE_PART1 = 'FORTUNA_ALL_PART1.JSON' # Core Backend\nOUTPUT_FILE_PART2 = 'FORTUNA_ALL_PART2.JSON' # Adapter Fleet\nOUTPUT_FILE_PART3 = 'FORTUNA_ALL_PART3.JSON' # Frontend, Docs, Tests & Tooling\n\n# --- ENLIGHTENED PARSING LOGIC ---\ndef extract_and_normalize_path(line: str) -> str | None:\n    \"\"\"\n    Extracts a file path from a line, handling multiple formats, and normalizes it.\n    Handles:\n    - Markdown links: `* [display](path)`\n    - Plain paths in backticks: ``- `path.py` - description``\n    - Plain paths with list markers: `- path/to/file.py`\n    \"\"\"\n    line = line.strip()\n    if not line or line.startswith('#'):\n        return None\n\n    # 1. Check for Markdown link format\n    md_match = re.search(r'\\[.*\\]\\((https?://[^\\)]+)\\)', line)\n    if not md_match:\n        md_match = re.search(r'\\[.*\\]\\(([^)]+)\\)', line)\n\n    if md_match:\n        path = md_match.group(1)\n    else:\n        # 2. Check for paths in backticks\n        bt_match = re.search(r'`([^`]+)`', line)\n        if bt_match:\n            path = bt_match.group(1)\n        else:\n            # 3. Assume plain path, stripping list markers\n            path = re.sub(r'^[*-]\\s*', '', line).split(' ')[0]\n\n    # --- Path Standardization ---\n    if not path or not ('.' in path or '/' in path):\n        if not path.endswith('.md'):\n             return None # Not a valid path\n\n    # If it's a full raw GitHub URL, extract the local path\n    if path.startswith('https://raw.githubusercontent.com/'):\n        path = '/'.join(path.split('/main/')[1:])\n\n    # Final check to avoid capturing descriptions\n    if ' ' in path and not path.startswith('`'):\n        return None\n\n    return path.strip()\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'='*60}\\nStarting FORTUNA Triumvirate Dossier creation...\\n{'='*60}\")\n\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        if not os.path.exists(manifest):\n            print(f\"    [WARNING] Manifest not found: {manifest}\")\n            continue\n\n        with open(manifest, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n\n        paths_found = 0\n        for line in lines:\n            path = extract_and_normalize_path(line)\n            if path:\n                all_local_paths.append(path)\n                paths_found += 1\n        print(f\"    --> Found {paths_found} valid file paths.\")\n\n    if not all_local_paths:\n        print(\"\\n[FATAL] No valid file paths found in any manifest. Aborting.\")\n        sys.exit(1)\n\n    part1_data = {} # Core Backend\n    part2_data = {} # Adapter Fleet\n    part3_data = {} # Frontend, Docs, Tests, Tooling\n    failed_count = 0\n    unique_local_paths = sorted(list(set(all_local_paths)))\n\n    print(f\"\\nFound a total of {len(unique_local_paths)} unique files to categorize and process.\")\n\n    for local_path in unique_local_paths:\n        try:\n            print(f\"--> Processing: {local_path}\")\n\n            if not os.path.exists(local_path):\n                print(f\"    [ERROR] File not found on disk: {local_path}\")\n                failed_count += 1\n                continue\n\n            with open(local_path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n\n            # --- Categorization Logic (Triumvirate) ---\n            if local_path.startswith('python_service/adapters/'):\n                part2_data[local_path] = content\n            elif local_path.startswith('python_service/'):\n                part1_data[local_path] = content\n            else:\n                part3_data[local_path] = content\n\n        except Exception as e:\n            print(f\"    [ERROR] Failed to read {local_path}: {e}\")\n            failed_count += 1\n\n    # --- Write Part 1 ---\n    print(f\"\\nWriting {len(part1_data)} files to {OUTPUT_FILE_PART1}...\")\n    with open(OUTPUT_FILE_PART1, 'w', encoding='utf-8') as f:\n        json.dump(part1_data, f, indent=4)\n    print(f\"    [SUCCESS] {OUTPUT_FILE_PART1} created.\")\n\n    # --- Write Part 2 ---\n    print(f\"Writing {len(part2_data)} files to {OUTPUT_FILE_PART2}...\")\n    with open(OUTPUT_FILE_PART2, 'w', encoding='utf-8') as f:\n        json.dump(part2_data, f, indent=4)\n    print(f\"    [SUCCESS] {OUTPUT_FILE_PART2} created.\")\n\n    # --- Write Part 3 ---\n    print(f\"Writing {len(part3_data)} files to {OUTPUT_FILE_PART3}...\")\n    with open(OUTPUT_FILE_PART3, 'w', encoding='utf-8') as f:\n        json.dump(part3_data, f, indent=4)\n    print(f\"    [SUCCESS] {OUTPUT_FILE_PART3} created.\")\n\n    total_processed = len(part1_data) + len(part2_data) + len(part3_data)\n    print(f\"\\n{'='*60}\\nPackaging process complete.\\nSuccessfully processed: {total_processed}/{len(unique_local_paths)}\\nFailed/Skipped: {failed_count}\\n{'='*60}\")\n\n    if failed_count > 0:\n        print(\"\\n[WARNING] Some files failed to process. The output may be incomplete.\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()",
    "electron/main.js": "// electron/main.js\nconst { app, BrowserWindow, Tray, Menu, nativeImage } = require('electron');\nconst { spawn } = require('child_process');\nconst path = require('path');\n\nclass FortunaDesktopApp {\n  constructor() {\n    this.backendProcess = null;\n    this.frontendProcess = null;\n    this.mainWindow = null;\n    this.tray = null;\n  }\n\n  async startBackend() {\n    return new Promise((resolve, reject) => {\n      // Corrected pathing for a packaged app\n      const isDev = process.env.NODE_ENV !== 'production';\n      const rootPath = isDev ? path.join(__dirname, '..') : process.resourcesPath;\n      const pythonPath = path.join(rootPath, '.venv', 'Scripts', 'python.exe');\n      const apiPath = path.join(rootPath, 'python_service', 'api.py');\n      \n      this.backendProcess = spawn(pythonPath, ['-m', 'uvicorn', 'api:app', '--host', '127.0.0.1', '--port', '8000'], {\n        cwd: path.join(rootPath, 'python_service')\n      });\n\n      this.backendProcess.stdout.on('data', (data) => {\n        console.log(`Backend STDOUT: ${data}`);\n        if (data.toString().includes('Uvicorn running')) {\n          console.log('Backend started successfully.');\n          resolve();\n        }\n      });\n\n      this.backendProcess.stderr.on('data', (data) => {\n        console.error(`Backend STDERR: ${data}`);\n      });\n\n      this.backendProcess.on('error', reject);\n    });\n  }\n\n  async startFrontend() {\n    const isDev = process.env.NODE_ENV !== 'production';\n    if (isDev) {\n        // In development, we assume the Next.js dev server is already running.\n        return Promise.resolve();\n    } else {\n        // In production, we would serve the built Next.js app.\n        // This part needs a production-ready server like Express or Next.js's standalone output.\n        // For now, we will assume the build is served and we just load the URL.\n        return Promise.resolve();\n    }\n  }\n\n  createMainWindow() {\n    this.mainWindow = new BrowserWindow({\n      width: 1600,\n      height: 1000,\n      title: 'Fortuna Faucet - Racing Analysis',\n      icon: path.join(__dirname, 'assets', 'icon.ico'),\n      webPreferences: {\n        nodeIntegration: false,\n        contextIsolation: true,\n        preload: path.join(__dirname, 'preload.js')\n      },\n      autoHideMenuBar: true,\n      backgroundColor: '#1a1a2e'\n    });\n\n    // In development, load from the Next.js dev server.\n    this.mainWindow.loadURL('http://localhost:3000');\n  }\n\n  createSystemTray() {\n    const iconPath = path.join(__dirname, 'assets', 'tray-icon.png');\n    const icon = nativeImage.createFromPath(iconPath);\n    this.tray = new Tray(icon.resize({ width: 16, height: 16 }));\n    \n    const contextMenu = Menu.buildFromTemplate([\n      { label: 'Open Dashboard', click: () => this.mainWindow.show() },\n      { type: 'separator' },\n      { label: 'Exit', click: () => app.quit() }\n    ]);\n\n    this.tray.setToolTip('Fortuna Faucet - Monitoring Races');\n    this.tray.setContextMenu(contextMenu);\n  }\n\n  async initialize() {\n    console.log('Starting Fortuna Faucet backend...');\n    await this.startBackend();\n    \n    console.log('Frontend server is assumed to be running in dev mode...');\n    await this.startFrontend();\n    \n    // Wait for frontend to be ready\n    await new Promise(resolve => setTimeout(resolve, 5000));\n    \n    this.createMainWindow();\n    this.createSystemTray();\n  }\n\n  cleanup() {\n    console.log('Cleaning up processes...');\n    if (this.backendProcess) this.backendProcess.kill();\n    if (this.frontendProcess) this.frontendProcess.kill();\n  }\n}\n\nlet fortunaApp;\n\napp.whenReady().then(() => {\n  fortunaApp = new FortunaDesktopApp();\n  fortunaApp.initialize();\n});\n\napp.on('window-all-closed', () => {\n  // On macOS it's common to re-create a window in the app when the\n  // dock icon is clicked and there are no other windows open.\n  if (process.platform !== 'darwin') {\n    // Do not quit here, let it run in the tray\n  }\n});\n\napp.on('before-quit', () => {\n  if(fortunaApp) {\n    fortunaApp.cleanup();\n  }\n});\n",
    "electron/package.json": "{\n  \"name\": \"fortuna-faucet-desktop\",\n  \"version\": \"1.0.0\",\n  \"description\": \"The desktop shell for the Fortuna Faucet application.\",\n  \"main\": \"main.js\",\n  \"scripts\": {\n    \"start\": \"electron .\",\n    \"build\": \"electron-builder\",\n    \"build:win\": \"electron-builder --win\"\n  },\n  \"build\": {\n    \"appId\": \"com.fortunafaucet.desktop\",\n    \"productName\": \"Fortuna Faucet\",\n    \"directories\": {\n      \"buildResources\": \"assets\"\n    },\n    \"win\": {\n      \"target\": [\"nsis\", \"portable\"],\n      \"icon\": \"assets/icon.ico\"\n    },\n    \"nsis\": {\n      \"oneClick\": false,\n      \"allowToChangeInstallationDirectory\": true,\n      \"createDesktopShortcut\": true,\n      \"createStartMenuShortcut\": true\n    }\n  },\n  \"devDependencies\": {\n    \"electron\": \"^28.0.0\",\n    \"electron-builder\": \"^24.9.1\"\n  }\n}\n",
    "electron/preload.js": "// electron/preload.js\n// This script runs in a privileged environment with access to Node.js APIs.\n// It's used to securely expose specific functionality to the renderer process (the web UI).\n\nconst { contextBridge, ipcRenderer } = require('electron');\n\n// Expose a safe, limited API to the frontend.\ncontextBridge.exposeInMainWorld('electronAPI', {\n  // Example: expose a function to send a message to the main process\n  // send: (channel, data) => ipcRenderer.send(channel, data),\n  \n  // Example: expose a function to receive a message from the main process\n  // on: (channel, func) => {\n  //   ipcRenderer.on(channel, (event, ...args) => func(...args));\n  // }\n});\n\nconsole.log('Preload script loaded.');\n",
    "fortuna_monitor.py": "#!/usr/bin/env python3\n\"\"\"\nFORTUNA FAUCET - Advanced Windows Monitor with Performance Graphs\n\"\"\"\n\nimport asyncio\nimport httpx\nimport tkinter as tk\nfrom tkinter import ttk, scrolledtext, messagebox\nfrom datetime import datetime\nfrom typing import List, Any\nimport os\nfrom collections import deque\nimport threading\nimport webbrowser\n\n# Try to import matplotlib for graphs\ntry:\n    import matplotlib\n    matplotlib.use('TkAgg')\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n    from matplotlib.figure import Figure\n    GRAPHS_AVAILABLE = True\nexcept ImportError:\n    GRAPHS_AVAILABLE = False\n\ndef load_api_key():\n    if os.path.exists('.env'):\n        with open('.env', 'r') as f:\n            for line in f:\n                if line.startswith('API_KEY='):\n                    return line.split('=', 1)[1].strip().strip('\\\"')\n    return None\n\nAPI_BASE_URL = \"http://localhost:8000\"\nAPI_KEY = load_api_key()\n\nclass PerformanceTracker:\n    def __init__(self, max_history=50):\n        self.timestamps = deque(maxlen=max_history)\n        self.race_counts = deque(maxlen=max_history)\n        self.fetch_durations = deque(maxlen=max_history)\n        self.success_rates = deque(maxlen=max_history)\n\n    def add_datapoint(self, races, duration, success_rate):\n        self.timestamps.append(datetime.now())\n        self.race_counts.append(races)\n        self.fetch_durations.append(duration)\n        self.success_rates.append(success_rate)\n\nclass FortunaAdvancedMonitor(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - Advanced System Monitor\")\n        try:\n            from ctypes import windll\n            windll.shcore.SetProcessDpiAwareness(1)\n        except:\n            pass\n        self.geometry(\"1200x800\")\n        self.configure(bg='#1a1a2e')\n\n        self.performance = PerformanceTracker()\n        self.is_running = True\n        self.refresh_interval = 30000\n        self.auto_refresh_var = tk.BooleanVar(value=True)\n\n        self._setup_styles()\n        self._create_widgets()\n        self.after(100, self.initial_load)\n\n    def initial_load(self):\n        if not API_KEY:\n            messagebox.showerror(\"Config Error\", \"API_KEY not found in .env file!\")\n            self.destroy()\n            return\n        self.schedule_refresh()\n\n    def _setup_styles(self):\n        style = ttk.Style()\n        style.theme_use('clam')\n        style.configure('Header.TLabel', background='#16213e', foreground='#e94560', font=('Segoe UI', 18, 'bold'), padding=15)\n        style.configure('Stat.TFrame', background='#0f3460', relief='flat')\n        style.configure('StatValue.TLabel', background='#0f3460', foreground='#00ff88', font=('Segoe UI', 24, 'bold'))\n        style.configure('StatLabel.TLabel', background='#0f3460', foreground='#ffffff', font=('Segoe UI', 10))\n\n    def _create_widgets(self):\n        header_frame = tk.Frame(self, bg='#16213e', height=100)\n        header_frame.pack(fill=tk.X)\n        header_frame.pack_propagate(False)\n        ttk.Label(header_frame, text=\"\ud83c\udfaf FORTUNA FAUCET\", style='Header.TLabel').pack(pady=10)\n\n        stats_frame = tk.Frame(self, bg='#1a1a2e')\n        stats_frame.pack(fill=tk.X, padx=15, pady=10)\n        self._create_stat_card(stats_frame, \"Active Adapters\", \"0\", 0)\n        self._create_stat_card(stats_frame, \"Total Races\", \"0\", 1)\n        self._create_stat_card(stats_frame, \"Success Rate\", \"0%\", 2)\n        self._create_stat_card(stats_frame, \"Avg Duration\", \"0s\", 3)\n\n        self.notebook = ttk.Notebook(self)\n        self.notebook.pack(fill=tk.BOTH, expand=True, padx=15, pady=10)\n        self.notebook.add(self._create_adapter_tab(), text=\"\ud83d\udd27 Adapters\")\n        if GRAPHS_AVAILABLE:\n            self.notebook.add(self._create_graph_tab(), text=\"\ud83d\udcca Performance\")\n\n        self._create_control_panel()\n        self._create_status_bar()\n\n    def _create_stat_card(self, parent, label, value, column):\n        card = ttk.Frame(parent, style='Stat.TFrame', width=250, height=100)\n        card.grid(row=0, column=column, padx=5, sticky='ew')\n        card.grid_propagate(False)\n        parent.grid_columnconfigure(column, weight=1)\n        value_label = ttk.Label(card, text=value, style='StatValue.TLabel')\n        value_label.pack(pady=(15, 0))\n        ttk.Label(card, text=label, style='StatLabel.TLabel').pack()\n        setattr(self, f'stat_{label.lower().replace(\" \", \"_\")}', value_label)\n\n    def _create_adapter_tab(self):\n        frame = tk.Frame(self.notebook, bg='#0f3460')\n        columns = ('Adapter', 'Status', 'Races', 'Duration', 'Error')\n        self.adapter_tree = ttk.Treeview(frame, columns=columns, show='headings')\n        for col in columns:\n            self.adapter_tree.heading(col, text=col)\n        self.adapter_tree.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n        return frame\n\n    def _create_graph_tab(self):\n        frame = tk.Frame(self.notebook, bg='#0f3460')\n        if GRAPHS_AVAILABLE:\n            self.fig = Figure(figsize=(10, 6), facecolor='#0f3460')\n            self.canvas = FigureCanvasTkAgg(self.fig, master=frame)\n            self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n            self.ax1 = self.fig.add_subplot(2, 2, 1, facecolor='#16213e')\n            self.ax2 = self.fig.add_subplot(2, 2, 2, facecolor='#16213e')\n            self.ax3 = self.fig.add_subplot(2, 2, 3, facecolor='#16213e')\n            self.ax4 = self.fig.add_subplot(2, 2, 4, facecolor='#16213e')\n            self.fig.tight_layout(pad=3.0)\n        else:\n            ttk.Label(frame, text=\"Install matplotlib to enable graphs: pip install matplotlib\").pack(expand=True)\n        return frame\n\n    def _create_control_panel(self):\n        control_frame = tk.Frame(self, bg='#1a1a2e')\n        control_frame.pack(fill=tk.X, padx=15, pady=10)\n        tk.Button(control_frame, text=\"\ud83d\udd04 Refresh Now\", command=self.manual_refresh, bg='#e94560', fg='#ffffff', font=('Segoe UI', 10, 'bold'), relief=tk.FLAT, padx=25, pady=10).pack(side=tk.LEFT)\n        tk.Button(control_frame, text=\"\ud83c\udf10 Dashboard\", command=lambda: webbrowser.open('http://localhost:3000'), bg='#0f3460', fg='#ffffff', font=('Segoe UI', 10, 'bold'), relief=tk.FLAT, padx=25, pady=10).pack(side=tk.LEFT, padx=5)\n        tk.Checkbutton(control_frame, text=\"Auto-refresh\", variable=self.auto_refresh_var, bg='#1a1a2e', fg='#ffffff', selectcolor='#0f3460').pack(side=tk.RIGHT)\n\n    def _create_status_bar(self):\n        status_frame = tk.Frame(self, bg='#0f3460', height=30)\n        status_frame.pack(fill=tk.X, side=tk.BOTTOM)\n        status_frame.pack_propagate(False)\n        self.last_update_label = tk.Label(status_frame, text=\"Last Update: --:--:--\", bg='#0f3460', fg='#ffffff')\n        self.last_update_label.pack(side=tk.LEFT, padx=15)\n        self.status_indicator = tk.Label(status_frame, text=\"\u25cf Initializing...\", bg='#0f3460', fg='#ffcc00')\n        self.status_indicator.pack(side=tk.RIGHT, padx=15)\n\n    def manual_refresh(self):\n        self.status_indicator.config(text=\"\u25cf Fetching...\", fg='#ffcc00')\n        self.update()\n        threading.Thread(target=lambda: asyncio.run(self.refresh_data())).start()\n\n    async def refresh_data(self):\n        try:\n            headers = {\"X-API-Key\": API_KEY}\n            async with httpx.AsyncClient(timeout=10.0) as client:\n                response = await client.get(f\"{API_BASE_URL}/api/adapters/status\", headers=headers)\n                response.raise_for_status()\n                adapters = response.json()\n            self.update_ui(adapters)\n        except httpx.ConnectError:\n            self.update_ui(is_error=True, error_message=\"Backend Offline\")\n        except Exception as e:\n            self.update_ui(is_error=True, error_message=str(e))\n\n    def update_ui(self, adapters: List[Any] = [], is_error: bool = False, error_message: str = \"\"):\n        if is_error:\n            self.status_indicator.config(text=f\"\u25cf {error_message}\", fg='#ff4444')\n            for item in self.adapter_tree.get_children(): self.adapter_tree.delete(item)\n            self.adapter_tree.insert('', tk.END, values=('SYSTEM ERROR', 'FAILED', 0, 0, error_message[:60]))\n            return\n\n        total_races = sum(a.get('races_fetched', 0) for a in adapters)\n        avg_duration = sum(a.get('fetch_duration', 0) for a in adapters) / len(adapters) if adapters else 0\n        success_rate = sum(1 for a in adapters if a.get('status') == 'SUCCESS') / len(adapters) * 100 if adapters else 0\n        self.performance.add_datapoint(total_races, avg_duration, success_rate)\n\n        self.stat_active_adapters.config(text=str(len(adapters)))\n        self.stat_total_races.config(text=str(total_races))\n        self.stat_success_rate.config(text=f\"{success_rate:.1f}%\")\n        self.stat_avg_duration.config(text=f\"{avg_duration:.2f}s\")\n\n        for item in self.adapter_tree.get_children(): self.adapter_tree.delete(item)\n        for adapter in adapters:\n            status = adapter.get('status', 'UNKNOWN')\n            self.adapter_tree.insert('', tk.END, values=(adapter.get('name', 'Unknown'), status, adapter.get('races_fetched', 0), f\"{adapter.get('fetch_duration', 0):.2f}\", adapter.get('error_message', '\u2014')[:60]))\n\n        if GRAPHS_AVAILABLE: self.update_graphs()\n        self.last_update_label.config(text=f\"Last Update: {datetime.now().strftime('%H:%M:%S')}\")\n        self.status_indicator.config(text=\"\u25cf All Systems Operational\", fg='#00ff88')\n\n    def update_graphs(self):\n        history = self.performance.get_history()\n        if not history['times']: return\n        for ax in [self.ax1, self.ax2, self.ax3, self.ax4]: ax.clear()\n        self.ax1.plot(history['times'], history['races'], color='#00ff88')\n        self.ax1.set_title('Races Fetched', color='white')\n        self.ax2.plot(history['times'], history['durations'], color='#e94560')\n        self.ax2.set_title('Avg. Fetch Duration (s)', color='white')\n        self.ax3.plot(history['times'], history['success'], color='#ffcc00')\n        self.ax3.set_title('Success Rate (%)', color='white')\n        self.ax3.set_ylim(0, 105)\n        self.canvas.draw()\n\n    def schedule_refresh(self):\n        if self.is_running and self.auto_refresh_var.get():\n            self.manual_refresh()\n        if self.is_running:\n            self.after(self.refresh_interval, self.schedule_refresh)\n\n    def on_closing(self):\n        self.is_running = False\n        self.destroy()\n\nif __name__ == \"__main__\":\n    if not API_KEY:\n        messagebox.showerror(\"Config Error\", \"API_KEY not found in .env file!\")\n    else:\n        app = FortunaAdvancedMonitor()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()\n",
    "fortuna_watchman.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Watchman (v2 - Score-Aware)\n# ==============================================================================\n# This is the master orchestrator for the Fortuna Faucet project.\n# It executes the full, end-to-end handicapping strategy autonomously.\n# ==============================================================================\n\nimport asyncio\nimport httpx\nimport structlog\nfrom datetime import datetime, timedelta, timezone\nfrom typing import List\n\nfrom python_service.config import get_settings\nfrom python_service.engine import FortunaEngine\nfrom python_service.analyzer import AnalyzerEngine\nfrom python_service.models import Race\nfrom live_monitor import LiveOddsMonitor\n\nlog = structlog.get_logger(__name__)\n\nclass Watchman:\n    \"\"\"Orchestrates the daily operation of the Fortuna Faucet.\"\"\"\n\n    def __init__(self):\n        self.settings = get_settings()\n        self.odds_engine = FortunaEngine(config=self.settings)\n        self.analyzer_engine = AnalyzerEngine()\n\n    async def get_initial_targets(self) -> List[Race]:\n        \"\"\"Uses the OddsEngine and AnalyzerEngine to get the day's ranked targets.\"\"\"\n        log.info(\"Watchman: Acquiring and ranking initial targets for the day...\")\n        today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')\n        try:\n            background_tasks = set() # Create a dummy set for background tasks\n            aggregated_data = await self.odds_engine.get_races(today_str, background_tasks)\n            all_races = aggregated_data.get('races', [])\n            if not all_races:\n                log.warning(\"Watchman: No races returned from OddsEngine.\")\n                return []\n\n            analyzer = self.analyzer_engine.get_analyzer('trifecta')\n            qualified_races = analyzer.qualify_races(all_races) # This now returns a sorted list with scores\n            log.info(\"Watchman: Initial target acquisition and ranking complete\", target_count=len(qualified_races))\n\n            # Log the top targets for better observability\n            for race in qualified_races[:5]:\n                log.info(\"Top Target Found\",\n                    score=race.qualification_score,\n                    venue=race.venue,\n                    race_number=race.race_number,\n                    post_time=race.start_time.isoformat()\n                )\n            return qualified_races\n        except Exception as e:\n            log.error(\"Watchman: Failed to get initial targets\", error=str(e), exc_info=True)\n            return []\n\n    async def run_tactical_monitoring(self, targets: List[Race]):\n        \"\"\"Uses the LiveOddsMonitor on each target as it approaches post time.\"\"\"\n        log.info(\"Watchman: Entering tactical monitoring loop.\")\n        active_targets = list(targets)\n\n        from python_service.adapters.betfair_adapter import BetfairAdapter\n        async with LiveOddsMonitor(betfair_adapter=BetfairAdapter(config=self.settings)) as live_monitor:\n            async with httpx.AsyncClient() as client:\n                while active_targets:\n                    now = datetime.now(timezone.utc)\n\n                    # Find races that are within the 5-minute monitoring window\n                    races_to_monitor = [r for r in active_targets if r.start_time.replace(tzinfo=timezone.utc) > now and r.start_time.replace(tzinfo=timezone.utc) < now + timedelta(minutes=5)]\n\n                    if races_to_monitor:\n                        for race in races_to_monitor:\n                            log.info(\"Watchman: Deploying Live Monitor for approaching target\",\n                                race_id=race.id,\n                                venue=race.venue,\n                                score=race.qualification_score\n                            )\n                            updated_race = await live_monitor.monitor_race(race, client)\n                            log.info(\"Watchman: Live monitoring complete for race\", race_id=updated_race.id)\n                            # Remove from target list to prevent re-monitoring\n                            active_targets = [t for t in active_targets if t.id != race.id]\n\n                    if not active_targets:\n                        break # Exit loop if all targets are processed\n\n                    await asyncio.sleep(30) # Check for upcoming races every 30 seconds\n\n        log.info(\"Watchman: All targets for the day have been monitored. Mission complete.\")\n\n    async def execute_daily_protocol(self):\n        \"\"\"The main, end-to-end orchestration method.\"\"\"\n        log.info(\"--- Fortuna Watchman Daily Protocol: ACTIVE ---\")\n        initial_targets = await self.get_initial_targets()\n        if initial_targets:\n            await self.run_tactical_monitoring(initial_targets)\n        else:\n            log.info(\"Watchman: No initial targets found. Shutting down for the day.\")\n\n        await self.odds_engine.close()\n        log.info(\"--- Fortuna Watchman Daily Protocol: COMPLETE ---\")\n\nasync def main():\n    from python_service.logging_config import configure_logging\n    configure_logging()\n    watchman = Watchman()\n    await watchman.execute_daily_protocol()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
    "install_service.bat": "@echo off\nREM Installs and starts the Fortuna Faucet backend as a Windows Service.\n\necho Installing Fortuna Faucet as a Windows Service...\n\nREM Ensure pywin32 is installed in the venv\necho [1/2] Verifying pywin32 dependency...\ncall .\\.venv\\Scripts\\activate.bat\npip install pywin32 --quiet\n\nREM Install and start the service\necho [2/2] Installing and starting the service...\npython windows_service.py install\npython windows_service.py start\n\necho.\necho \u2705 Service installed and started successfully!\necho The backend will now run automatically in the background.\necho You can manage it from the Windows Services application (services.msc).\necho.\npause\n",
    "launcher.ps1": "# launcher.ps1\n# Enhanced PowerShell launcher for Fortuna Faucet\n\n# --- Configuration ---\n$backendPort = 8000\n$frontendPort = 3000\n$backendDir = \"python_service\"\n$frontendDir = \"web_platform\\\\frontend\"\n\n# --- Helper Functions for Color Output ---\nfunction Write-Header {\n    param([string]$text)\n    Write-Host (\"=\" * 60) -ForegroundColor Cyan\n    Write-Host $text -ForegroundColor Cyan\n    Write-Host (\"=\" * 60) -ForegroundColor Cyan\n}\n\nfunction Write-Step {\n    param([string]$text)\n    Write-Host \"\\\\n>> $($text)\" -ForegroundColor Yellow\n}\n\nfunction Write-Info {\n    param([string]$text)\n    Write-Host \"   -> $($text)\" -ForegroundColor White\n}\n\nfunction Write-Success {\n    param([string]$text)\n    Write-Host \"\\\\n$($text)\" -ForegroundColor Green -BackgroundColor Black\n}\n\nfunction Write-Error {\n    param([string]$text)\n    Write-Host \"[ERROR] $($text)\" -ForegroundColor Red\n}\n\n# --- Main Logic ---\nClear-Host\nWrite-Header \"Fortuna Faucet Enhanced Launcher (PowerShell Edition)\"\n\n# 1. Check Backend Port\nWrite-Step \"Step 1: Checking backend port ($backendPort)...\"\n$backendConnection = Get-NetTCPConnection -LocalPort $backendPort -ErrorAction SilentlyContinue\nif ($backendConnection) {\n    Write-Error \"Port $backendPort is already in use. Please close the existing process.\"\n    exit 1\n} else {\n    Write-Info \"Port $backendPort is available.\"\n}\n\n# 2. Check Frontend Port\nWrite-Step \"Step 2: Checking frontend port ($frontendPort)...\"\n$frontendConnection = Get-NetTCPConnection -LocalPort $frontendPort -ErrorAction SilentlyContinue\nif ($frontendConnection) {\n    Write-Error \"Port $frontendPort is already in use. Please close the existing process.\"\n    exit 1\n} else {\n    Write-Info \"Port $frontendPort is available.\"\n}\n\n# 3. Launch Services\nWrite-Step \"Step 3: Launching services...\"\nWrite-Info \"Starting Backend in a new window...\"\nStart-Process wt -ArgumentList \"new-tab\", \"-d\", \".\", \"cmd\", \"/c\", \"title Fortuna Backend && .\\\\.venv\\\\Scripts\\\\activate.bat && cd $backendDir && uvicorn api:app --reload\"\n\nWrite-Info \"Starting Frontend in a new window...\"\nStart-Process wt -ArgumentList \"new-tab\", \"-d\", \"$frontendDir\", \"cmd\", \"/c\", \"title Fortuna Frontend && npm run dev\"\n\nWrite-Info \"Waiting 10 seconds for services to initialize...\"\nStart-Sleep -Seconds 10\n\n# 4. Launch Browser\nWrite-Step \"Step 4: Opening dashboard...\"\nStart-Process \"http://localhost:$frontendPort\"\nWrite-Info \"Browser launched at http://localhost:$frontendPort\"\n\nWrite-Success \"All services launched successfully!\"\n",
    "live_monitor.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Live Odds Monitor (The Third Pillar)\n# ==============================================================================\n\nimport httpx\nimport structlog\nfrom datetime import datetime\n\nfrom python_service.models import Race, OddsData\nfrom python_service.adapters.betfair_adapter import BetfairAdapter\n\nlog = structlog.get_logger(__name__)\n\nfrom typing import Dict\n\nclass LiveOddsMonitor:\n    \"\"\"Monitors live odds for given race markets and triggers bets.\"\"\"\n\n    def __init__(self, betfair_adapter: BetfairAdapter):\n        self.betfair_adapter = betfair_adapter\n        self.monitored_markets: Dict[str, Race] = {}\n\n    async def __aenter__(self):\n        \"\"\"Allows the monitor to be used as an async context manager.\"\"\"\n        log.info(\"LiveOddsMonitor entered context.\")\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Ensures resources are cleaned up when the context is exited.\"\"\"\n        log.info(\"LiveOddsMonitor exiting context, closing adapter resources...\")\n        await self.betfair_adapter.close()\n        log.info(\"Adapter resources closed.\")\n\n    async def monitor_race(self, race: Race, http_client: httpx.AsyncClient) -> Race:\n        \"\"\"\n        Monitors a single race, fetching live odds and updating the Race object.\n        \"\"\"\n        log.info(\"Monitoring race for live odds\", race_id=race.id, venue=race.venue)\n        if not race.id.startswith('bf_'):\n            log.warning(\"Cannot monitor non-Betfair race\", race_id=race.id, source=race.source)\n            return race # Return original race if not a Betfair market\n\n        market_id = race.id.split('bf_')[1]\n\n        try:\n            live_odds = await self.betfair_adapter.get_live_odds_for_market(market_id, http_client)\n            if not live_odds:\n                log.warning(\"No live odds returned from Betfair\", market_id=market_id)\n                return race\n\n            log.info(\"Successfully fetched live odds\", market_id=market_id, odds_count=len(live_odds))\n            # Update the runners in the Race object with the new live odds\n            for runner in race.runners:\n                if runner.selection_id in live_odds:\n                    runner.odds[self.adapter.source_name] = OddsData(\n                        win=live_odds[runner.selection_id],\n                        source=self.adapter.source_name,\n                        last_updated=datetime.now()\n                    )\n            return race\n        except Exception as e:\n            log.error(\"Failed to monitor race\", race_id=race.id, error=e, exc_info=True)\n            return race # Return original race on failure",
    "results_parser.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Chart Parser (The Carpenter)\n# ==============================================================================\n# This module is responsible for parsing the complex, semi-structured text\n# extracted from Equibase PDF race charts.\n# ==============================================================================\n\nimport re\n\nclass ChartParser:\n    \"\"\"A sophisticated parser for Equibase PDF chart text.\"\"\"\n\n    def count_runners(self, chart_text: str) -> int:\n        \"\"\"\n        Counts the number of runners in a race by parsing the 'Past Performance\n        Running Line Preview' section, which is a reliable indicator of field size.\n        \"\"\"\n        lines = chart_text.split('\\n')\n        in_running_line_section = False\n        runner_count = 0\n\n        for line in lines:\n            # Heuristic to detect the start of the relevant section\n            if 'Past Performance Running Line Preview' in line:\n                in_running_line_section = True\n                continue\n\n            if in_running_line_section:\n                # Stop if we hit a blank line or the next major section\n                if not line.strip() or 'Trainers:' in line:\n                    break\n\n                # A valid runner line starts with a program number\n                if re.match(r'^\\d+', line.strip()):\n                    runner_count += 1\n\n        return runner_count\n\n# --- Example Usage (for testing and demonstration) ---\nif __name__ == '__main__':\n    # This is a sample text block based on the 'Rosetta Stone' provided by the Project Lead\n    SAMPLE_TEXT = (\"\"\"Last Raced Pgm Horse Name (Jockey) Wgt M/E PP Start 1/4 1/2 3/4 Str Fin Odds Comments\n19Aug23 7ELP8 11 J J's Joker (Arrieta, Francisco) 120 L 11 1 41/2 51/2 51 21/2 11/2 7.08 4-3p,5w1/4,bid1/8,edgd\n3Sep23 7KD7 2 Peek (Saez, Luis) 120 L 2 3 11/2 11/2 11 11 1/2 22 11.53 ins,dug in 2p1/8,bestd\n15Sep23 1CD4 1 Game Warden (Gaffalione, Tyler) 120 L 1 2 52 41 41/2 31 3Neck 2.81* ins,aim btw1/4,lck bid\nTotal WPS Pool: $280,617\nPgm Horse Win Place Show\n11 J J's Joker 16.16 8.00 5.78\n2 Peek 10.80 6.22\n1 Game Warden 3.78\nPast Performance Running Line Preview\nPgm Horse Name Start 1/4 1/2 3/4 Str Fin\n11 J J's Joker 1 42 1/2 53 1/2 52 1/2 21 1/2 11/2\n2 Peek 3 11/2 11/2 11 11 1/2 21/2\n1 Game Warden 2 53 42 1/2 42 32 32 1/2\n4 Runningforjoy 9 75 1/2 64 63 1/2 53 42 3/4\n5 Archie the Giza 7 96 1/2 87 85 1/2 64 1/2 54 1/4\n8 Cafe Racer 4 21/2 21/2 31 43 65\n9 Barnstorming 5 31 31 1/2 21 76 1/2 711 1/4\n6 Cashmeup 8 65 75 1/2 74 87 1/2 811 1/2\n10 Texas Pride 12 1214 1/2 1213 1/2 1114 1113 3/4 913\n3 Active Duty 6 86 1/2 1110 1214 1/4 1013 1/2 1013 1/2\n12 Surface to Air 10 108 99 97 1/2 911 1114\n7 Dr Kringle 11 119 1/2 1010 108 1214 3/4 1217 3/4\nTrainers: 11 - Hartman, Chris; 2 - Arnold, II, George; 1 - Joseph, Jr, Saffie; 4 - Tomlinson, Michael; 5 - Medina, Robert; 8 - Stall, Jr, Albert; 9 - Cox, Brad;\n\"\"\")\n\n    print(\"--- Testing ChartParser with sample data ---\")\n    parser = ChartParser()\n    runner_count = parser.count_runners(SAMPLE_TEXT)\n\n    print(f\"Runner count found: {runner_count}\")\n    # Expected Output: 12\n    assert runner_count == 12\n    print(\"Test passed!\")",
    "run_fortuna.bat": "@echo off\nTITLE Fortuna Faucet Launcher\n\nREM This script now delegates to the enhanced PowerShell launcher.\nREM It ensures the correct execution policy is set for the current process.\n\nECHO Launching Fortuna Faucet via enhanced PowerShell launcher...\npowershell -ExecutionPolicy Bypass -File .\\\\launcher.ps1\n\nECHO.\nPAUSE\n",
    "setup_windows.bat": "@echo off\nREM ============================================================================\nREM  Project Gemini: WHOLE-SYSTEM Windows Setup Script\nREM ============================================================================\n\necho [INFO] Starting full-stack setup for Project Gemini...\n\nREM --- Section 1: Python Backend Setup ---\necho.\necho [BACKEND] Checking for Python installation...\npython --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Python is not found. Please install Python 3.8+ and add to PATH.\n    goto :eof\n)\necho [BACKEND] Python found.\n\necho [BACKEND] Creating Python virtual environment in '.\\\\.venv\\\\'...\nif not exist .\\\\.venv ( python -m venv .venv )\n\necho [BACKEND] Installing dependencies from 'python_service/requirements.txt'...\ncall .\\\\.venv\\\\Scripts\\\\activate.bat && pip install -r python_service/requirements.txt\nif %errorlevel% neq 0 (\n    echo [ERROR] Backend setup failed.\n    goto :eof\n)\necho [SUCCESS] Python backend setup complete.\n\nREM --- Section 2: TypeScript Frontend Setup ---\necho.\necho [FRONTEND] Checking for Node.js installation...\nnode --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Node.js is not found. Please install Node.js (LTS).\n    goto :eof\n)\necho [FRONTEND] Node.js found.\n\necho [FRONTEND] Installing dependencies from 'package.json'...\ncd web_platform/frontend\nnpm install\nif %errorlevel% neq 0 (\n    echo [ERROR] Frontend setup failed. Check npm errors.\n    cd ../..\n    goto :eof\n)\n\necho [FRONTEND] Checking for frontend environment file...\nif not exist .env.local (\n    echo [FRONTEND] '.env.local' not found. Creating from template...\n    copy .env.local.example .env.local\n    echo.\n    echo    ****************************************************************************\n    echo    *  [ACTION REQUIRED] Please edit 'web_platform/frontend/.env.local'      *\n    echo    *  and add your NEXT_PUBLIC_API_KEY for the frontend to work.            *\n    echo    ****************************************************************************\n    echo.\n) else (\n    echo [FRONTEND] '.env.local' already exists.\n)\n\ncd ../..\necho [SUCCESS] TypeScript frontend setup complete.\n\nREM --- Final Instructions ---\necho.\necho ============================================================================\nREM  FULL-STACK SETUP COMPLETE!\nREM  You can now launch the entire application with 'run_fortuna.bat'\nREM ============================================================================\n\n:eof",
    "setup_wizard.py": "# setup_wizard.py\n\"\"\"\nInteractive configuration wizard for Fortuna Faucet.\nGuides users through initial setup and API key configuration.\n\"\"\"\n\nimport os\nfrom pathlib import Path\nimport getpass\nimport secrets\nfrom datetime import datetime\n\nclass SetupWizard:\n    def __init__(self):\n        self.config = {}\n        self.env_file = Path('.env')\n\n    def run(self):\n        print(\"\\n\" + \"=\"*60)\n        print(\"   Welcome to Fortuna Faucet Setup Wizard\")\n        print(\"=\"*60 + \"\\n\")\n\n        if self.env_file.exists():\n            overwrite = input(f\"\u26a0\ufe0f  Configuration file '{self.env_file}' already exists. Overwrite? (y/N): \").lower()\n            if overwrite != 'y':\n                print(\"\\nSetup cancelled.\")\n                return\n\n        print(\"\\n\ud83d\udccb Step 1: Core Configuration\")\n        print(\"-\" * 60)\n        self._configure_core()\n\n        print(\"\\n\ud83d\udd11 Step 2: Betfair API (Required for Live Monitoring)\")\n        print(\"-\" * 60)\n        self._configure_betfair()\n\n        self._write_config()\n        self._display_summary()\n\n    def _configure_core(self):\n        \"\"\"Configure essential settings\"\"\"\n        print(\"\\nGenerating a secure, private API key for communication between your services...\")\n        api_key = secrets.token_urlsafe(32)\n        self.config['API_KEY'] = api_key\n        print(f\"\u2705 API Key generated successfully.\")\n\n    def _configure_betfair(self):\n        \"\"\"Configure Betfair Exchange API\"\"\"\n        print(\"\\nBetfair Exchange provides live odds and is essential for the\")\n        print(\"LiveOddsMonitor feature. Get your API key at:\")\n        print(\"\ud83d\udc49 https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni\")\n        \n        configure = input(\"\\nConfigure Betfair now? (Y/n): \").lower()\n        if configure != 'n':\n            self.config['BETFAIR_APP_KEY'] = input(\"App Key: \").strip()\n            self.config['BETFAIR_USERNAME'] = input(\"Username: \").strip()\n            self.config['BETFAIR_PASSWORD'] = getpass.getpass(\"Password: \").strip()\n            print(\"\u2705 Betfair configured\")\n        else:\n            self.config['BETFAIR_APP_KEY'] = \"\"\n            self.config['BETFAIR_USERNAME'] = \"\"\n            self.config['BETFAIR_PASSWORD'] = \"\"\n            print(\"\u23ed\ufe0f  Skipped - Live monitoring will be disabled\")\n\n    def _write_config(self):\n        \"\"\"Write configuration to .env file\"\"\"\n        with open(self.env_file, 'w') as f:\n            f.write(\"# Fortuna Faucet Configuration\\n\")\n            f.write(f\"# Generated by Setup Wizard on {datetime.now().isoformat()}\\n\\n\")\n            \n            f.write(\"# --- Core Settings ---\\n\")\n            f.write(f\"API_KEY=\\\"{self.config['API_KEY']}\\\"\\n\\n\")\n            \n            f.write(\"# --- Betfair Exchange ---\\n\")\n            f.write(f\"BETFAIR_APP_KEY=\\\"{self.config['BETFAIR_APP_KEY']}\\\"\\n\")\n            f.write(f\"BETFAIR_USERNAME=\\\"{self.config['BETFAIR_USERNAME']}\\\"\\n\")\n            f.write(f\"BETFAIR_PASSWORD=\\\"{self.config['BETFAIR_PASSWORD']}\\\"\\n\")\n\n    def _display_summary(self):\n        \"\"\"Display setup summary\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"   \u2705 Setup Complete!\")\n        print(\"=\"*60)\n        print(f\"\\n\ud83d\udcc1 Configuration saved to '{self.env_file}'\")\n        print(\"\\n\ud83d\ude80 Next Steps:\")\n        print(\"   1. Run INSTALL_FORTUNA.bat (as Administrator) if you haven't already.\")\n        print(\"   2. Double-click the 'Launch Fortuna' shortcut on your desktop.\")\n        print(\"\\n\ud83d\udca1 Tip:\")\n        print(\"   - You can run this wizard again at any time to reconfigure your settings.\")\n        print(\"\\n\" + \"=\"*60 + \"\\n\")\n\nif __name__ == '__main__':\n    wizard = SetupWizard()\n    wizard.run()\n",
    "uninstall_service.bat": "@echo off\nREM Stops and removes the Fortuna Faucet Windows Service.\n\necho Uninstalling Fortuna Faucet Windows Service...\n\nREM Activate venv to ensure python command works as expected\ncall .\\.venv\\Scripts\\activate.bat\n\nREM Stop and remove the service\necho [1/2] Stopping the service...\npython windows_service.py stop\n\necho [2/2] Removing the service from the registry...\npython windows_service.py remove\n\necho.\necho \u2705 Service stopped and uninstalled successfully!\necho.\npause\n",
    "web_platform/frontend/.env.local.example": "# Copy this file to .env.local and fill in your actual API key\nNEXT_PUBLIC_API_KEY=your_secret_api_key_here\nNEXT_PUBLIC_API_URL=http://localhost:8000",
    "web_platform/frontend/next.config.mjs": "/** @type {import('next').NextConfig} */\n\nconst withPWA = require('next-pwa')({\n  dest: 'public',\n  register: true,\n  skipWaiting: true,\n  disable: process.env.NODE_ENV === 'development'\n});\n\nconst nextConfig = {};\n\nmodule.exports = withPWA(nextConfig);\n",
    "web_platform/frontend/package.json": "{\n  \"name\": \"frontend\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"scripts\": { \"dev\": \"next dev\", \"build\": \"next build\", \"start\": \"next start\" },\n  \"dependencies\": {\n    \"next\": \"14.1.0\",\n    \"react\": \"^18\",\n    \"react-dom\": \"^18\",\n    \"socket.io-client\": \"^4.7.4\",\n    \"@tanstack/react-query\": \"^5.28.9\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20\",\n    \"@types/react\": \"^18\",\n    \"@types/react-dom\": \"^18\",\n    \"next-pwa\": \"^5.6.0\",\n    \"autoprefixer\": \"^10.0.1\",\n    \"postcss\": \"^8\",\n    \"tailwindcss\": \"^3.3.0\",\n    \"typescript\": \"^5\"\n  }\n}",
    "web_platform/frontend/postcss.config.js": "module.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n};",
    "web_platform/frontend/src/app/Providers.tsx": "// web_platform/frontend/src/app/Providers.tsx\n'use client';\n\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport React from 'react';\n\nexport default function Providers({ children }: { children: React.ReactNode }) {\n  const [queryClient] = React.useState(() => new QueryClient());\n\n  return (\n    <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>\n  );\n}",
    "web_platform/frontend/src/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\nimport Providers from './Providers';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Fortuna Faucet Command Deck',\n  description: 'Real-time racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={`${inter.className} bg-white text-gray-900 dark:bg-gray-900 dark:text-gray-100`}>\n        <Providers>{children}</Providers>\n      </body>\n    </html>\n  );\n}",
    "web_platform/frontend/src/components/LiveRaceDashboard.tsx": "// web_platform/frontend/src/components/LiveRaceDashboard.tsx\n'use client';\n\nimport React, { useState, useMemo } from 'react';\nimport { useQuery } from '@tanstack/react-query';\nimport { RaceCard } from './RaceCard';\n\n// --- Type Definitions ---\nimport type { Race } from '@/types/racing'; // Correct type import\n\ninterface QualifiedRacesResponse {\n  races: Race[];\n}\n\n// --- Helper Functions from UI Bible ---\nconst getNextRaceCountdown = (races: Race[]): string => {\n  const now = new Date().getTime();\n  const upcomingRaces = races\n    .map(race => new Date(race.start_time).getTime())\n    .filter(time => time > now);\n\n  if (upcomingRaces.length === 0) return '--:--';\n\n  const nextRaceTime = Math.min(...upcomingRaces);\n  const diff = nextRaceTime - now;\n  const minutes = Math.floor((diff / 1000) / 60);\n  const seconds = Math.floor((diff / 1000) % 60);\n\n  return `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;\n};\n\nconst fetchAdapterStatuses = async (): Promise<AdapterStatus[]> => {\n  const apiKey = process.env.NEXT_PUBLIC_API_KEY;\n  if (!apiKey) throw new Error('API key not configured.');\n  const response = await fetch(`/api/adapters/status`, { headers: { 'X-API-Key': apiKey } });\n  if (!response.ok) throw new Error(`Adapter status API request failed: ${response.statusText}`);\n  return response.json();\n};\n\n// --- Main Component ---\nexport const LiveRaceDashboard: React.FC = () => {\n  const [filterConfig, setFilterConfig] = useState({ minScore: 0, maxFieldSize: 999, sortBy: 'score' });\n\n  // --- TanStack Query Hooks ---\n  const { data: qualifiedData, error: racesError, isLoading: racesLoading } = useQuery<QualifiedRacesResponse>({\n    queryKey: ['qualifiedRaces'],\n    queryFn: fetchQualifiedRaces,\n    refetchInterval: 30000 // The Heartbeat\n  });\n\n  const { data: statuses, error: statusError } = useQuery<AdapterStatus[]>({\n    queryKey: ['adapterStatuses'],\n    queryFn: fetchAdapterStatuses,\n    refetchInterval: 60000\n  });\n\n  const handleFilterChange = (e: React.ChangeEvent<HTMLInputElement | HTMLSelectElement>) => {\n    const { name, value } = e.target;\n    setFilterConfig(prev => ({ ...prev, [name]: name === 'sortBy' ? value : Number(value) }));\n  };\n\n  const filteredAndSortedRaces = useMemo(() => {\n    let processedRaces = [...(qualifiedData?.races || [])];\n    processedRaces = processedRaces.filter(race => (race.qualification_score || 0) >= filterConfig.minScore && race.runners.filter(r => !r.scratched).length <= filterConfig.maxFieldSize);\n    processedRaces.sort((a, b) => {\n      switch (filterConfig.sortBy) {\n        case 'time': return new Date(a.start_time).getTime() - new Date(b.start_time).getTime();\n        case 'venue': return a.venue.localeCompare(b.venue);\n        default: return (b.qualification_score || 0) - (a.qualification_score || 0);\n      }\n    });\n    return processedRaces;\n  }, [qualifiedData, filterConfig]);\n\n  const error = racesError || statusError;\n\n  return (\n    <main className=\"min-h-screen bg-gray-900 text-white p-8\">\n      <h1 className=\"text-4xl font-bold text-center mb-8\">Fortuna Faucet Command Deck</h1>\n\n      {/* --- Visual Health Panel --- */}\n      <div className='mb-8 p-4 bg-gray-800/50 border border-gray-700 rounded-lg'>\n        <h2 className='text-lg font-semibold text-gray-300 mb-3'>Adapter Status</h2>\n        <div className='flex flex-wrap gap-2'>\n          {statuses?.map(s => (\n            <span key={s.adapter_name} className={`px-2 py-1 text-xs font-bold rounded-full ${s.status === 'SUCCESS' || s.status === 'OK' ? 'bg-green-500/20 text-green-300' : 'bg-red-500/20 text-red-300'}`}>\\n              {s.adapter_name}\\n            </span>\n          )) ?? <span className='text-gray-500 text-sm'>Loading statuses...</span>}\n        </div>\n      </div>\n\n      {/* --- Smart Filtering & Sorting System --- */}\n      <div className=\"filter-panel bg-gray-800/90 backdrop-blur-sm p-4 rounded-xl border border-gray-700 mb-6\">\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center gap-4\"><span className=\"font-semibold\">Smart Filters</span></div>\n          <div className=\"flex gap-6\">\n            <div className=\"flex items-center gap-3\"><label className=\"text-sm text-gray-400\">Min Score:</label><input type=\"range\" name=\"minScore\" min=\"0\" max=\"100\" value={filterConfig.minScore} onChange={handleFilterChange} className=\"w-32\" /><span className=\"text-sm font-semibold w-12\">{filterConfig.minScore}%</span></div>\n            <div className=\"flex items-center gap-3\"><label className=\"text-sm text-gray-400\">Max Field:</label><select name=\"maxFieldSize\" value={filterConfig.maxFieldSize} onChange={handleFilterChange} className=\"bg-gray-700 border border-gray-600 rounded px-3 py-1 text-white\"><option value=\"8\">8 runners</option><option value=\"10\">10 runners</option><option value=\"12\">12 runners</option><option value=\"999\">Any size</option></select></div>\n            <div className=\"flex items-center gap-3\"><label className=\"text-sm text-gray-400\">Sort by:</label><select name=\"sortBy\" value={filterConfig.sortBy} onChange={handleFilterChange} className=\"bg-gray-700 border border-gray-600 rounded px-3 py-1 text-white\"><option value=\"score\">Qualification Score</option><option value=\"time\">Post Time</option><option value=\"venue\">Track Name</option></select></div>\n          </div>\n        </div>\n      </div>\n\n      {racesLoading && <p className=\"text-center text-xl\">Searching for qualified races...</p>}\n      {error && <p className=\"text-center text-xl text-red-500\">Error: {error.message}</p>}\n\n      {!racesLoading && !error && (\n        <>\n          <div className='text-center mb-4 text-gray-400'>Displaying <span className='font-bold text-white'>{filteredAndSortedRaces.length}</span> of <span className='font-bold text-white'>{qualifiedData?.races.length || 0}</span> total qualified races.</div>\n          <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\">\n            {filteredAndSortedRaces.map(race => <RaceCard key={race.id} race={race} />)}\n          </div>\n        </>\n      )}\n    </main>\n  );\n};",
    "web_platform/frontend/src/components/RaceCard.tsx": "// web_platform/frontend/src/components/RaceCard.tsx\n'use client';\n\nimport React from 'react';\n\n// Type definitions matching the backend Race model\ninterface OddsData {\n  win: number | null;\n  source: string;\n  last_updated: string;\n}\n\ninterface Runner {\n  number: number;\n  name: string;\n  scratched: boolean;\n  selection_id?: number;\n  odds: Record<string, OddsData>;\n  jockey?: string;\n  trainer?: string;\n}\n\ninterface Race {\n  id: string;\n  venue: string;\n  race_number: number;\n  start_time: string;\n  runners: Runner[];\n  source: string;\n  qualification_score?: number;\n  distance?: string;\n  surface?: string;\n}\n\ninterface RaceCardProps {\n  race: Race;\n}\n\n// Helper function from the UI Bible\nfunction formatTimeUntilPost(startTime: string): string {\n  const now = new Date();\n  const post = new Date(startTime);\n  const diff = post.getTime() - now.getTime();\n\n  if (diff < 0) return 'Post Time Passed';\n\n  const hours = Math.floor(diff / (1000 * 60 * 60));\n  const minutes = Math.floor((diff % (1000 * 60 * 60)) / (1000 * 60));\n\n  return `${hours}h ${minutes}m`;\n}\n\nexport const RaceCard: React.FC<RaceCardProps> = ({ race }) => {\n  const activeRunners = race.runners.filter(r => !r.scratched);\n  activeRunners.sort((a, b) => a.number - b.number);\n\n  const getUniqueSourcesCount = (runners: Runner[]): number => {\n    const sources = new Set();\n    runners.forEach(runner => {\n      if (runner.odds) {\n        Object.keys(runner.odds).forEach(source => sources.add(source));\n      }\n    });\n    return sources.size;\n  };\n\n  const getBestOdds = (runner: Runner): { odds: number, source: string } | null => {\n    if (!runner.odds) return null;\n    const validOdds = Object.values(runner.odds).filter(o => o.win && o.win < 999);\n    if (validOdds.length === 0) return null;\n    const best = validOdds.reduce((min, o) => o.win! < min.win! ? o : min);\n    return { odds: best.win!, source: best.source };\n  };\n\n  return (\n    <div className={`race-card-enhanced border rounded-lg p-4 bg-gray-800 shadow-lg hover:border-purple-500 transition-all ${race.qualification_score && race.qualification_score >= 80 ? 'card-premium' : 'border-gray-700'}`}>\n      {/* Header with Smart Status Indicators */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div className=\"flex items-center gap-3\">\n          <div>\n            <h2 className=\"text-2xl font-bold text-white\">{race.venue}</h2>\n            <div className=\"flex gap-2 text-sm text-gray-400\">\n              <span>Race {race.race_number}</span>\n              <span>\u2022</span>\n              <span>{formatTimeUntilPost(race.start_time)}</span>\n            </div>\n          </div>\n        </div>\n\n        {race.qualification_score && (\n          <div className={`px-4 py-2 rounded-full text-center ${\n            race.qualification_score >= 80 ? 'bg-red-500/20 text-red-400 border border-red-500/30' :\n            race.qualification_score >= 60 ? 'bg-yellow-500/20 text-yellow-400 border border-yellow-500/30' :\n            'bg-green-500/20 text-green-400 border border-green-500/30'\n          }`}>\n            <div className=\"font-bold text-lg\">{race.qualification_score.toFixed(0)}%</div>\n            <div className=\"text-xs\">Score</div>\n          </div>\n        )}\n      </div>\n\n      {/* Race Conditions Grid */}\n      <div className=\"grid grid-cols-4 gap-2 mb-4 p-3 bg-gray-800/50 rounded-lg\">\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Distance</div>\n          <div className=\"text-sm font-semibold text-white\">{race.distance || 'N/A'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Surface</div>\n          <div className=\"text-sm font-semibold text-white\">{race.surface || 'Dirt'}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Field</div>\n          <div className=\"text-sm font-semibold text-white\">{activeRunners.length}</div>\n        </div>\n        <div className=\"text-center\">\n          <div className=\"text-xs text-gray-400\">Sources</div>\n          <div className=\"text-sm font-semibold text-white\">{getUniqueSourcesCount(race.runners)}</div>\n        </div>\n      </div>\n\n      {/* Interactive Runner Rows */}\n      <div className=\"runners-table space-y-2\">\n        {activeRunners.map((runner, idx) => {\n          const bestOddsInfo = getBestOdds(runner);\n          return (\n            <div key={runner.number} className=\"runner-row group hover:bg-purple-500/10 transition-all rounded-md p-3\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center gap-4 flex-1\">\n                  <div className={`w-10 h-10 rounded-full flex items-center justify-center font-bold transition-all group-hover:scale-110 text-gray-900 shadow-lg ${idx === 0 ? 'bg-gradient-to-br from-yellow-400 to-yellow-600 shadow-yellow-500/50' : idx === 1 ? 'bg-gradient-to-br from-gray-300 to-gray-500 shadow-gray-400/50' : idx === 2 ? 'bg-gradient-to-br from-orange-400 to-orange-600 shadow-orange-500/50' : 'bg-gray-700 text-gray-300'}`}>\n                    {runner.number}\n                  </div>\n                  <div className=\"flex flex-col\">\n                    <span className=\"font-bold text-white text-lg\">{runner.name}</span>\n                    <div className=\"flex gap-3 text-sm text-gray-400\">\n                      {runner.jockey && <span>J: {runner.jockey}</span>}\n                      {runner.trainer && <span>T: {runner.trainer}</span>}\n                    </div>\n                  </div>\n                </div>\n                {bestOddsInfo && (\n                  <div className=\"text-right\">\n                    <div className=\"text-2xl font-bold text-emerald-400\">{bestOddsInfo.odds.toFixed(2)}</div>\n                    <div className=\"text-xs text-gray-500\">via {bestOddsInfo.source}</div>\n                  </div>\n                )}\n              </div>\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n};",
    "web_platform/frontend/src/types/racing.ts": "// web_platform/frontend/src/types/racing.ts\n// This file is the central source of truth for frontend racing data types.\n\n// --- Runner & Odds Interfaces ---\nexport interface OddsData {\n  win: number | null;\n  source: string;\n  last_updated: string;\n}\n\nexport interface Runner {\n  number: number;\n  name: string;\n  scratched: boolean;\n  selection_id?: number;\n  odds: Record<string, OddsData>;\n  jockey?: string;\n  trainer?: string;\n}\n\n// --- Race Interface ---\n// This interface matches the shape of the data returned by the API for the dashboard.\nexport interface Race {\n  id: string;\n  venue: string;\n  race_number: number;\n  start_time: string;\n  runners: Runner[];\n  source: string;\n  qualification_score?: number;\n  distance?: string;\n  surface?: string;\n}\n\n// --- Analysis Factor Interfaces (retained from previous version) ---\nexport interface Factor {\n    points: number;\n    ok: boolean;\n    reason: string;\n}\n\nexport interface TrifectaFactors {\n    [key: string]: Factor;\n}",
    "web_platform/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  darkMode: 'media',\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config",
    "web_platform/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n",
    "windows_service.py": "# windows_service.py\nimport win32serviceutil\nimport win32service\nimport win32event\nimport servicemanager\nimport socket\nimport sys\nimport os\nimport subprocess\nfrom pathlib import Path\n\nclass FortunaBackendService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaFaucetBackend\"\n    _svc_display_name_ = \"Fortuna Faucet Racing Analysis Service\"\n    _svc_description_ = \"Background service for continuous racing data monitoring.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.stop_event = win32event.CreateEvent(None, 0, 0, None)\n        self.backend_process = None\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.stop_event)\n        if self.backend_process:\n            self.backend_process.terminate()\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE, servicemanager.PYS_SERVICE_STARTED, (self._svc_name_, ''))\n        self.main()\n\n    def main(self):\n        install_dir = Path(__file__).parent.resolve()\n        venv_python = install_dir / \".venv\" / \"Scripts\" / \"python.exe\"\n        api_module_dir = install_dir / \"python_service\"\n\n        env = os.environ.copy()\n        env_file = install_dir / \".env\"\n        if env_file.exists():\n            with open(env_file) as f:\n                for line in f:\n                    if '=' in line and not line.startswith('#'):\n                        key, value = line.strip().split('=', 1)\n                        env[key] = value.strip('\\\"')\n\n        self.backend_process = subprocess.Popen(\n            [str(venv_python), \"-m\", \"uvicorn\", \"api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n            cwd=str(api_module_dir),\n            env=env\n        )\n\n        win32event.WaitForSingleObject(self.stop_event, win32event.INFINITE)\n\nif __name__ == '__main__':\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaBackendService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaBackendService)\n"
}