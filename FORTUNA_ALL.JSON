{
    "python_service/__init__.py": "# This file makes the python_service directory a Python package.",
    "python_service/api.py": "# python_service/api.py\n\nimport structlog\nfrom datetime import date\nfrom typing import List, Optional\nfrom fastapi import FastAPI, HTTPException, Request, Depends\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\nfrom contextlib import asynccontextmanager\n\nfrom .config import get_settings\nfrom .orchestrator import fetch_all_races, get_adapter_statuses\nfrom .models import Race, RaceDay\nfrom .security import verify_api_key\nfrom .logging_config import configure_logging\nfrom .analyzer import AnalyzerEngine\n\nlog = structlog.get_logger()\nconfigure_logging()\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"\n    Manage the application's lifespan. On startup, it initializes the AnalyzerEngine\n    and attaches it to the app state.\n    \"\"\"\n    app.state.analyzer_engine = AnalyzerEngine()\n    log.info(\"Server startup: AnalyzerEngine initialized.\")\n    yield\n    log.info(\"Server shutdown.\")\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI(\n    title=\"Fortuna Faucet V4 - Unified Architecture\", \n    version=\"4.0\",\n    lifespan=lifespan\n)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\nsettings = get_settings()\napp.add_middleware(\n    CORSMiddleware, \n    allow_origins=settings.ALLOWED_ORIGINS, \n    allow_credentials=True, \n    allow_methods=[\"GET\"], \n    allow_headers=[\"*\"]\n)\n\n@app.get(\"/health\")\nasync def health_check(): \n    return {\"status\": \"ok\"}\n\n@app.get(\"/api/adapters/status\")\n@limiter.limit(\"60/minute\")\nasync def get_all_adapter_statuses(request: Request, _=Depends(verify_api_key)):\n    return get_adapter_statuses()\n\n@app.get(\"/api/races\", response_model=List[RaceDay])\n@limiter.limit(\"30/minute\")\nasync def get_races(request: Request, _=Depends(verify_api_key)):\n    try:\n        return await fetch_all_races()\n    except Exception: \n        log.error(\"Error in /api/races\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n@app.get(\"/api/races/qualified/{analyzer_name}\", response_model=List[Race])\n@limiter.limit(\"30/minute\")\nasync def get_qualified_races(\n    analyzer_name: str,\n    request: Request,\n    _=Depends(verify_api_key)\n):\n    \"\"\"\n    Gets all races for the day, filters them using the specified analyzer,\n    and returns the qualified races.\n    \"\"\"\n    try:\n        race_days = await fetch_all_races()\n        all_races: List[Race] = [race for day in race_days for race in day.races]\n        \n        analyzer_engine = request.app.state.analyzer_engine\n        analyzer = analyzer_engine.get_analyzer(analyzer_name)\n        qualified_races = analyzer.qualify_races(all_races)\n        return qualified_races\n    except ValueError as e:\n        log.warning(\"Requested analyzer not found\", analyzer_name=analyzer_name)\n        raise HTTPException(status_code=404, detail=str(e))\n    except Exception as e:\n        log.error(\"Error in /api/races/qualified\", error=str(e), exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal Server Error\")",
    "python_service/models.py": "# python_service/models.py\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict\nfrom datetime import datetime\nfrom decimal import Decimal\n\nclass OddsData(BaseModel):\n    win: Optional[Decimal] = None\n    source: str\n    last_updated: datetime\n\nclass Runner(BaseModel):\n    number: int\n    name: str\n    scratched: bool = False\n    odds: Dict[str, OddsData] = Field(default_factory=dict)\n    jockey: Optional[str] = None\n    trainer: Optional[str] = None\n    morning_line_odds: Optional[str] = None\n\nclass Race(BaseModel):\n    id: str\n    venue: str\n    race_number: int\n    start_time: datetime\n    runners: List[Runner]\n    source: str\n    race_name: Optional[str] = None\n    race_url: Optional[str] = None\n    distance: Optional[str] = None\n    qualification_score: Optional[float] = None\n\nclass RaceDay(BaseModel):\n    track_name: str\n    races: List[Race]",
    "python_service/analyzer.py": "from abc import ABC, abstractmethod\nfrom typing import List, Dict, Type, Optional\nimport structlog\nfrom decimal import Decimal\n\nfrom python_service.models import Race, Runner\n\nlog = structlog.get_logger(__name__)\n\ndef _get_best_win_odds(runner: Runner) -> Optional[Decimal]:\n    \"\"\"Gets the best win odds for a runner, filtering out invalid or placeholder values.\"\"\"\n    if not runner.odds:\n        return None\n\n    # Filter out invalid or placeholder odds (e.g., > 999)\n    valid_odds = [o.win for o in runner.odds.values() if o.win is not None and o.win < 999]\n\n    if not valid_odds:\n        return None\n\n    return min(valid_odds)\n\nclass BaseAnalyzer(ABC):\n    \"\"\"The abstract interface for all future analyzer plugins.\"\"\"\n    def __init__(self, **kwargs):\n        pass\n\n    @abstractmethod\n    def qualify_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"The core method every analyzer must implement.\"\"\"\n        pass\n\nclass TrifectaAnalyzer(BaseAnalyzer):\n    \"\"\"Analyzes races and assigns a qualification score based on the 'Trifecta of Factors'.\"\"\"\n    def __init__(self, max_field_size: int = 10, min_favorite_odds: float = 2.5, min_second_favorite_odds: float = 4.0):\n        self.max_field_size = max_field_size\n        self.min_favorite_odds = Decimal(str(min_favorite_odds))\n        self.min_second_favorite_odds = Decimal(str(min_second_favorite_odds))\n\n    def qualify_races(self, races: List[Race]) -> List[Race]:\n        \"\"\"Filters and scores races, returning a sorted list of qualified opportunities.\"\"\"\n        qualified_races = []\n        for race in races:\n            score = self._evaluate_race(race)\n            if score is not None:\n                race.qualification_score = score\n                qualified_races.append(race)\n\n        # Sort the qualified races by score, descending\n        qualified_races.sort(key=lambda r: r.qualification_score, reverse=True)\n        log.info(\"Qualification and scoring complete\", qualified_count=len(qualified_races))\n        return qualified_races\n\n    def _evaluate_race(self, race: Race) -> Optional[float]:\n        \"\"\"Evaluates a single race and returns a qualification score if it passes, else None.\"\"\"\n        # --- Constants for Scoring Logic ---\n        FAV_ODDS_NORMALIZATION = 10.0\n        SEC_FAV_ODDS_NORMALIZATION = 15.0\n        FAV_ODDS_WEIGHT = 0.6\n        SEC_FAV_ODDS_WEIGHT = 0.4\n        FIELD_SIZE_SCORE_WEIGHT = 0.3\n        ODDS_SCORE_WEIGHT = 0.7\n\n        active_runners = [r for r in race.runners if not r.scratched]\n\n        runners_with_odds = []\n        for runner in active_runners:\n            best_odds = _get_best_win_odds(runner)\n            if best_odds is not None:\n                runners_with_odds.append((runner, best_odds))\n\n        if len(runners_with_odds) < 2: return None\n\n        runners_with_odds.sort(key=lambda x: x[1])\n        favorite_odds = runners_with_odds[0][1]\n        second_favorite_odds = runners_with_odds[1][1]\n\n        # --- Apply the Trifecta of Factors as hard filters ---\n        if len(active_runners) > self.max_field_size: return None\n        if favorite_odds < self.min_favorite_odds: return None\n        if second_favorite_odds < self.min_second_favorite_odds: return None\n\n        # --- Calculate Qualification Score (as inspired by the TypeScript Genesis) ---\n        field_score = (self.max_field_size - len(active_runners)) / self.max_field_size\n\n        # Normalize odds scores - cap influence of extremely high odds\n        fav_odds_score = min(float(favorite_odds) / FAV_ODDS_NORMALIZATION, 1.0)\n        sec_fav_odds_score = min(float(second_favorite_odds) / SEC_FAV_ODDS_NORMALIZATION, 1.0)\n\n        # Weighted average\n        odds_score = (fav_odds_score * FAV_ODDS_WEIGHT) + (sec_fav_odds_score * SEC_FAV_ODDS_WEIGHT)\n        final_score = (field_score * FIELD_SIZE_SCORE_WEIGHT) + (odds_score * ODDS_SCORE_WEIGHT)\n\n        return round(final_score * 100, 2)\n\nclass AnalyzerEngine:\n    \"\"\"Discovers and manages all available analyzer plugins.\"\"\"\n    def __init__(self):\n        self.analyzers: Dict[str, Type[BaseAnalyzer]] = {}\n        self._discover_analyzers()\n\n    def _discover_analyzers(self):\n        # In a real plugin system, this would inspect a folder.\n        # For now, we register them manually.\n        self.register_analyzer('trifecta', TrifectaAnalyzer)\n        log.info(\"AnalyzerEngine discovered plugins\", available_analyzers=list(self.analyzers.keys()))\n\n    def register_analyzer(self, name: str, analyzer_class: Type[BaseAnalyzer]):\n        self.analyzers[name] = analyzer_class\n\n    def get_analyzer(self, name: str, **kwargs) -> BaseAnalyzer:\n        analyzer_class = self.analyzers.get(name)\n        if not analyzer_class:\n            log.error(\"Requested analyzer not found\", requested_analyzer=name)\n            raise ValueError(f\"Analyzer '{name}' not found.\")\n        return analyzer_class(**kwargs)",
    "python_service/security.py": "# python_service/security.py\n\nimport secrets\nfrom fastapi import Security, HTTPException, status, Depends\nfrom fastapi.security import APIKeyHeader\n\nfrom .config import Settings, get_settings\n\nAPI_KEY_NAME = \"X-API-Key\"\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)\n\nasync def verify_api_key(\n    key: str = Security(api_key_header),\n    settings: Settings = Depends(get_settings)\n):\n    \"\"\"\n    Verifies the provided API key against the one in settings using a\n    timing-attack resistant comparison.\n    \"\"\"\n    if secrets.compare_digest(key, settings.API_KEY):\n        return True\n    else:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Invalid or missing API Key\"\n        )",
    "web_platform/frontend/package.json": "{\n  \"name\": \"frontend\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"scripts\": { \"dev\": \"next dev\", \"build\": \"next build\", \"start\": \"next start\" },\n  \"dependencies\": {\n    \"next\": \"14.1.0\",\n    \"react\": \"^18\",\n    \"react-dom\": \"^18\",\n    \"socket.io-client\": \"^4.7.4\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20\",\n    \"@types/react\": \"^18\",\n    \"@types/react-dom\": \"^18\",\n    \"autoprefixer\": \"^10.0.1\",\n    \"postcss\": \"^8\",\n    \"tailwindcss\": \"^3.3.0\",\n    \"typescript\": \"^5\"\n  }\n}",
    "web_platform/frontend/tailwind.config.ts": "import type { Config } from 'tailwindcss'\n\nconst config: Config = {\n  content: [\n    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\nexport default config",
    "web_platform/frontend/tsconfig.json": "{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"dom\",\n      \"dom.iterable\",\n      \"esnext\"\n    ],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": false,\n    \"noEmit\": true,\n    \"incremental\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ]\n  },\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n}\n",
    "web_platform/frontend/app/globals.css": "@tailwind base;\n@tailwind components;\n@tailwind utilities;",
    "web_platform/frontend/app/layout.tsx": "// web_platform/frontend/app/layout.tsx\nimport './globals.css';\nimport type { Metadata } from 'next';\nimport { Inter } from 'next/font/google';\n\nconst inter = Inter({ subsets: ['latin'] });\n\nexport const metadata: Metadata = {\n  title: 'Checkmate Live',\n  description: 'Real-time horse racing analysis.',\n};\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={inter.className}>{children}</body>\n    </html>\n  );\n}",
    "web_platform/frontend/app/page.tsx": "// web_platform/frontend/app/page.tsx\nimport { LiveRaceDashboard } from '../src/components/LiveRaceDashboard';\n\nexport default function HomePage() {\n  return <LiveRaceDashboard />;\n}",
    ".gitignore": "# Byte-compiled / optimized files\n__pycache__/\n*.pyc\n\n# Distribution / packaging\nbuild/\ndist/\n*.egg-info/\n\n# Unit test / coverage reports\n.pytest_cache/\n.coverage\n\n# Environments\n.venv/\nvenv/\nenv/\n\n# IDE settings\n.vscode/\n.idea/\n\n# Database files\n*.db\n*.sqlite\n*.sqlite3\n\n# Node.js\nnode_modules/\n/ui/node_modules/\n/ui/build/\n\n# Environment files\n.env\n",
    "convert_to_json.py": "import json\nimport os\nimport re\nimport sys\nfrom multiprocessing import Process, Queue\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_DIR = 'ReviewableJSON'\nFILE_PROCESSING_TIMEOUT = 10  # Seconds to wait before killing a hung file read\n\n# --- Core Functions ---\ndef parse_manifest_for_links(manifest_path):\n    \"\"\"Parses a manifest file to extract raw GitHub file links.\"\"\"\n    if not os.path.exists(manifest_path):\n        return []\n    with open(manifest_path, 'r', encoding='utf-8') as f:\n        content = f.read()\n    return re.findall(r'(https://raw\\.githubusercontent\\.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/[-/\\w\\.]+)', content)\n\ndef _sandboxed_file_read(file_path, q):\n    \"\"\"This function runs in a separate process to read a file.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        q.put({\"file_path\": file_path, \"content\": content})\n    except Exception as e:\n        q.put({\"error\": str(e)})\n\ndef convert_file_to_json_sandboxed(file_path):\n    \"\"\"Reads a file in a sandboxed process with a timeout.\"\"\"\n    q = Queue()\n    p = Process(target=_sandboxed_file_read, args=(file_path, q))\n    p.start()\n    p.join(timeout=FILE_PROCESSING_TIMEOUT)\n\n    if p.is_alive():\n        p.terminate()\n        p.join() # Ensure termination is complete\n        return {\"error\": f\"Timeout: File processing took longer than {FILE_PROCESSING_TIMEOUT} seconds.\"}\n\n    if not q.empty():\n        return q.get()\n    return {\"error\": \"Unknown error in sandboxed read process.\"}\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'='*60}\\nStarting IRONCLAD JSON backup process...\\n{'='*60}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    all_links = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        links = parse_manifest_for_links(manifest)\n        all_links.extend(links)\n        print(f\"    --> Found {len(links)} links.\")\n\n    if not all_links:\n        print(\"\\n[FATAL] No links found in any manifest. Aborting.\")\n        return\n\n    print(f\"\\nFound a total of {len(all_links)} unique files to process.\")\n    processed_count, failed_count = 0, 0\n\n    for link in set(all_links): # Use set to avoid processing duplicate links\n        local_path = '/'.join(link.split('/main/')[1:])\n        print(f\"\\nProcessing: {local_path}\")\n\n        json_data = convert_file_to_json_sandboxed(local_path)\n\n        if json_data and \"error\" not in json_data:\n            output_path = os.path.join(OUTPUT_DIR, local_path + '.json')\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(json_data, f, indent=4)\n\n            print(f\"    [SUCCESS] Saved backup to {output_path}\")\n            processed_count += 1\n        else:\n            error_msg = json_data.get(\"error\", \"Unknown error\") if json_data else \"File not found\"\n            print(f\"    [ERROR] Failed to process {local_path}: {error_msg}\")\n            failed_count += 1\n\n    print(f\"\\n{'='*60}\\nBackup process complete.\\nSuccessfully processed: {processed_count}/{len(all_links)}\\nFailed/Skipped: {failed_count}\\n{'='*60}\")\n\n    if failed_count > 0:\n        sys.exit(1) # Exit with an error code if any files failed\n\nif __name__ == \"__main__\":\n    main()",
    "run_fortuna.bat": "@echo off\nREM ============================================================================\nREM  Fortuna Faucet: Master Launcher (v2 - Perfected)\nREM ============================================================================\n\necho [INFO] Launching the Fortuna Faucet application...\n\nREM --- Launch Backend ---\necho [BACKEND] Starting FastAPI server... (New window)\nstart \"Fortuna Backend\" cmd /c \"call .\\\\.venv\\\\Scripts\\\\activate.bat && cd python_service && uvicorn api:app --reload\"\n\nREM --- Launch Frontend ---\necho [FRONTEND] Starting Next.js development server... (New window)\nstart \"Fortuna Frontend\" cmd /c \"cd web_platform/frontend && npm run dev\"\n\nREM --- Open Browser ---\necho [UI] Waiting 5 seconds for the frontend server to initialize...\ntimeout /t 5 /nobreak >nul\necho [UI] Opening the Fortuna Faucet dashboard in your default browser...\nstart http://localhost:3000\n\necho [SUCCESS] Both pillars of Fortuna Faucet have been launched.\n\n:eof",
    "setup_windows.bat": "@echo off\nREM ============================================================================\nREM  Project Gemini: WHOLE-SYSTEM Windows Setup Script\nREM ============================================================================\n\necho [INFO] Starting full-stack setup for Project Gemini...\n\nREM --- Section 1: Python Backend Setup ---\necho.\necho [BACKEND] Checking for Python installation...\npython --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Python is not found. Please install Python 3.8+ and add to PATH.\n    goto :eof\n)\necho [BACKEND] Python found.\n\necho [BACKEND] Creating Python virtual environment in '.\\\\.venv\\\\'...\nif not exist .\\\\.venv ( python -m venv .venv )\n\necho [BACKEND] Installing dependencies from 'python_service/requirements.txt'...\ncall .\\\\.venv\\\\Scripts\\\\activate.bat && pip install -r python_service/requirements.txt\nif %errorlevel% neq 0 (\n    echo [ERROR] Backend setup failed.\n    goto :eof\n)\necho [SUCCESS] Python backend setup complete.\n\nREM --- Section 2: TypeScript Frontend Setup ---\necho.\necho [FRONTEND] Checking for Node.js installation...\nnode --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Node.js is not found. Please install Node.js (LTS).\n    goto :eof\n)\necho [FRONTEND] Node.js found.\n\necho [FRONTEND] Installing dependencies from 'package.json'...\ncd web_platform/frontend\nnpm install\nif %errorlevel% neq 0 (\n    echo [ERROR] Frontend setup failed. Check npm errors.\n    cd ../..\n    goto :eof\n)\ncd ../..\necho [SUCCESS] TypeScript frontend setup complete.\n\nREM --- Final Instructions ---\necho.\necho ============================================================================\nREM  FULL-STACK SETUP COMPLETE!\nREM  You can now launch the entire application with 'run_fortuna.bat'\nREM ============================================================================\n\n:eof",
    ".env.example": "# .env.example\n# Copy this file to .env and fill in your actual credentials.\n\n# --- Application Security (Required) ---\nAPI_KEY=\"YOUR_SECRET_API_KEY_HERE\"\n\n# --- Betfair API Credentials (Required for LiveOddsMonitor) ---\nBETFAIR_APP_KEY=\"YOUR_APP_KEY_HERE\"\nBETFAIR_USERNAME=\"YOUR_USERNAME_HERE\"\nBETFAIR_PASSWORD=\"YOUR_PASSWORD_HERE\"\n\n# --- Optional Adapter Keys ---\nTVG_API_KEY=\"\"\nRACING_AND_SPORTS_TOKEN=\"\"\nPOINTSBET_API_KEY=\"\"\n\n# --- CORS Configuration (Optional) ---\n# A comma-separated list of allowed origins for the API.\n# Example: ALLOWED_ORIGINS=\"http://localhost:3000,https://your-production-domain.com\"\nALLOWED_ORIGINS=\"http://localhost:3000,http://localhost:3001\"\n\n# --- Greyhound Adapter (Optional) ---\n# To enable the Greyhound adapter, provide the full base URL for the API.\n# If this is left blank, the adapter will be disabled.\nGREYHOUND_API_URL=\"\"\n",
    "python_service/requirements.txt": "requests==2.31.0\npython-dotenv==1.0.0\npydantic==2.5.2\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\naiohttp==3.9.0\nhttpx==0.24.1\npytest==8.4.2\n\nstructlog\nrespx\npytest-asyncio\nstreamlit\npandas\ntabula-py\nlxml\nbeautifulsoup4\npikepdf\npydantic-settings==2.1.0\nslowapi==0.1.8\n\ntenacity\n",
    "README.md": "# Fortuna Faucet\n\nThis repository contains the Fortuna Faucet project, a global, multi-source horse racing analysis tool. The project is a two-pillar system: a powerful, asynchronous Python backend that performs all data gathering, and a feature-rich TypeScript frontend.\n\n---\n\n## \ud83d\ude80 Quick Start\n\n### 1. Configure Your Environment\n\nRun the setup script to ensure Python and Node.js are correctly configured and all dependencies are installed.\n\n```batch\n# From the project root:\nsetup_windows.bat\n```\n\n### 2. Launch the Application\n\nRun the master launch script. This will start both the Python backend and the TypeScript frontend servers in parallel.\n\n```batch\n# From the project root:\nrun_fortuna.bat\n```\n\nThe backend API will be available at `http://localhost:8000`.\nThe frontend will be available at `http://localhost:3000`.\n\n### 4. Using the API\n\nTo use the API directly (e.g., with `curl` or other tools), you must provide the `API_KEY` set in your `.env` file via the `X-API-Key` header. This is required for all endpoints except `/health`.\n\n```bash\n# Example: Test the qualified races endpoint\ncurl -H \"X-API-Key: YOUR_SECRET_API_KEY_HERE\" http://localhost:8000/api/races/qualified/trifecta\n```\n",
    "ARCHITECTURAL_MANDATE.md": "# The Fortuna Faucet Architectural Mandate\n\n## The Prime Directive: The Two-Pillar System\n\nThe project's architecture is a lean, hyper-powerful, two-pillar system chosen for its clarity, maintainability, and performance.\n\n## Pillar 1: The Asynchronous Python Backend\n\nThe backend is a modern, asynchronous service built on **FastAPI**. Its architecture includes:\n\n1.  **The `OddsEngine`:** A central, async orchestrator for data collection.\n2.  **The Resilient `BaseAdapter`:** An abstract base class providing professional-grade features.\n3.  **The Adapter Fleet:** A modular system of 'plugin' adapters for data sources.\n4.  **Pydantic Data Contracts:** Strict, validated Pydantic models for data integrity.\n5.  **The `TrifectaAnalyzer` (Intelligence Layer):** A dedicated module for scoring and qualifying opportunities.\n\n## Pillar 2: The TypeScript Frontend\n\nThe frontend is a modern, feature-rich web application built on **Next.js** and **TypeScript**.",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `scrape-sort_races-toteboards`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n",
    "STATUS.md": "# Project Status: Foundation Rebuilt, Hardening in Progress\n\n**Date:** 2025-10-03\n\n## Current State\n\n*   **Architecture:** The backend has been successfully rebuilt into a superior, asynchronous FastAPI application, as defined by 'Operation: Grand Synthesis'. The new foundation is stable, tested, and features a resilient `BaseAdapter` pattern.\n\n*   **Status:** The foundational refactoring is complete. The first two data adapters (`Betfair`, `TVG`) have been implemented on the new architecture. We are now in a new phase of development: **'Phase 2: Hardening & Expansion.'**\n\n*   **Documentation:** All core strategic documents and manifests have been synchronized with the new technical reality.\n\n*   **Next Steps:** Our immediate priority is to act on the verified intelligence from our Oracle (Jules1003). The next missions will focus on implementing critical API security features (rate limiting, authentication) and continuing the build-out of our adapter fleet.",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2) ---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "PROJECT_MANIFEST.md": "# Checkmate V8: Project Manifest (Final)\n\n**Purpose:** To categorize all files, distinguishing between the active **CORE** system and **LEGACY** components.\n\n---\n\n## CORE ARCHITECTURE (Ultimate Solo)\n\n*   `.env`: **CORE** - Centralized configuration.\n*   `ARCHITECTURAL_MANDATE.md`: **CORE** - The project's final strategic blueprint.\n*   `README.md`: **CORE** - The primary entry point.\n*   `STATUS.md`: **CORE** - The final status report.\n*   `setup_windows.bat`: **CORE** - The environment setup script for the CORE architecture.\n\n---\n\n## LEGACY & HISTORICAL ARTIFACTS\n\n*   `launcher.py`: **LEGACY** - The orchestrator for the deprecated Penta-Hybrid system.\n*   All other files and directories not listed in CORE are considered **LEGACY** R&D assets.",
    "ROADMAP_APPENDICES.md": "# Checkmate: Strategic Appendices\n\n**Purpose:** This document is the permanent home for the high-value strategic intelligence salvaged from the deprecated `ROADMAP.md`. It contains our long-term goals and a library of resources to accelerate development.\n\n---\n\n## Appendix A: V3 Adapter Backlog (The \"Treasure Chest\")\n\nThis is the definitive, prioritized list of data sources to be implemented.\n\n### Category 1: High-Value Data Feeds (API-First)\n*   BetfairDataScientistThoroughbred\n*   BetfairDataScientistGreyhound\n*   racingandsports\n*   sportinglife (requires investigation)\n*   racingpost (requires auth)\n\n### Category 2: Premium Global Sources (Scraping)\n*   timeform\n*   attheraces\n*   racingtv\n*   oddschecker\n*   betfair\n*   horseracingnation\n*   brisnet\n\n### Category 3: North American Authorities & ADWs\n*   equibase\n*   drf\n*   fanduel\n*   twinspires\n*   1stbet\n*   nyrabets\n*   xpressbet\n\n### Category 4: European Authorities & Markets\n*   francegalop\n*   deutschergalopp\n*   svenskgalopp\n*   pmu\n\n### Category 5: Asia-Pacific & Rest of World\n*   tab\n*   punters\n*   racingaustralia\n*   hkjc\n*   jra\n*   goldcircle\n*   emiratesracing\n\n### Category 6: Specialized Disciplines (Harness & Greyhound)\n*   usta\n*   standardbredcanada\n*   harnessracingaustralia\n*   gbgb\n*   grireland\n*   thedogs\n\n---\n\n## Appendix B: Open-Source Intelligence Leads\n\nA curated list of projects and resources to accelerate development.\n\n1.  **joenano/rpscrape:** https://github.com/joenano/rpscrape\n2.  **Daniel57910/horse-scraper:** https://github.com/Daniel57910/horse-scraper\n3.  **Web Scraping for HKJC:** https://gist.github.com/tomfoolc/ef039b229c8e97bd40c5493174bca839\n3.  **Web Scraping for HKJC:** https://gist.github.com/tomfoolc/ef039b229c8e97bd40c5493174bca839\n4.  **LibHunt horse-racing projects:** https://www.libhunt.com/topic/horse-racing\n5.  **Web data scraping blog:** https://www.3idatascing.com/how-does-web-data-scraping-help-in-horse-racing-and-greyhound/\n6.  **Fawazk/Greyhoundscraper:** https://github.com/Fawazk/Greyhoundscraper\n7.  **Betfair Hub Models Scraping Tutorial:** https://betfair-datascientists.github.io/tutorials/How_to_Automate_3/\n8.  **scrapy-horse-racing:** https://github.com/chrism-attmann/scrapy-horse-racing\n9.  **horse-racing-data:** https://github.com/jeffkub/horse-racing-data\n\n\n## C. Un-Mined Gems (Future Campaign Candidates)\n\n*Discovered during a full operational review. These represent high-value, validated concepts from the project's history that are candidates for future development campaigns.*\n\n### C1. The Intelligence Layer (\"The Analyst\")\n\n- **Concept:** A dedicated analysis and scoring engine (`analyzer.py`) that sits on top of the `OddsEngine`. It would provide a high-value `/api/races/qualified` endpoint, transforming the API from a data funnel into a source of actionable intelligence.\n- **Origin:** Inspired by the `TrifectaAnalyzer` logic in the legacy `checkmate_engine.py` prototype. Formally proposed as \"Operation: Activate the Analyst\".\n- **Value:** Fulfills the project's original vision of finding opportunities, not just collecting data. Creates a clean architectural separation between data collection and business logic.\n\n### C2. The Legacy Test Suite (\"The Oracle's Library\")\n\n- **Concept:** Repurpose the vast collection of existing tests and mock data located in `attic/legacy_tests_pre_triage`.\n- **Origin:** Identified during the full repository file catalog audit.\n- **Value:** Provides a massive shortcut to production hardening. Allows the project to increase test coverage and resilience by validating the CORE services against hundreds of historical edge cases.\n\n### C3. The AI Architectural Reviews (\"The Council's Wisdom\")\n\n- **Concept:** Synthesize the expert analysis and architectural recommendations from the multiple AI model reviews stored in the Digital Attic (`*.md.txt` files).\n- **Origin:** Explicitly mentioned in the Gemini928 handoff memo as \"Architectural Parables\".\n- **Value:** A source of high-level architectural consulting. These documents may contain actionable advice on performance, security, or design patterns that could significantly improve the current architecture.\n\n### C4. The Interactive Dashboard Prototype (\"The Command Deck\")\n\n- **Concept:** Create a modern, internal, real-time command deck for visualizing engine data and testing new `Analyzer` models.\n- **Origin:** Inspired by the `portable_demo_v2.py` Streamlit application from the attic.\n- **Value:** An invaluable tool for development, debugging, and real-time operational insight, far more intuitive than raw logs or API calls.",
    "python_service/config.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Centralized Configuration\n# =================================\u00e1=============================================\n# This module, restored by the Great Correction, provides a centralized and\n# validated source for all application settings using pydantic-settings.\n# ==============================================================================\n\nfrom pydantic_settings import BaseSettings\nfrom functools import lru_cache\nfrom typing import List, Optional\n\nclass Settings(BaseSettings):\n    # --- Application Security ---\n    API_KEY: str\n\n    # --- Betfair API Credentials ---\n    BETFAIR_APP_KEY: str = \"\"\n    BETFAIR_USERNAME: str = \"\"\n    BETFAIR_PASSWORD: str = \"\"\n\n    # --- Other Adapter Keys ---\n    TVG_API_KEY: str = \"\"\n    RACING_AND_SPORTS_TOKEN: str = \"\"\n    POINTSBET_API_KEY: str = \"\"\n    GREYHOUND_API_URL: Optional[str] = None\n\n    # --- CORS Configuration ---\n    ALLOWED_ORIGINS: List[str] = [\"http://localhost:3000\", \"http://localhost:3001\"]\n\n    class Config:\n        env_file = \".env\"\n        case_sensitive = True\n\n@lru_cache()\ndef get_settings() -> Settings:\n    \"\"\"Returns a cached instance of the application settings.\"\"\"\n    return Settings()",
    "python_service/logging_config.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: Logging Configuration\n# ==============================================================================\n# This module, restored by the Great Correction, provides a centralized\n# configuration for structured logging using structlog.\n# ==============================================================================\n\nimport logging\nimport sys\nimport structlog\n\ndef configure_logging():\n    \"\"\"Configures structlog for JSON-based structured logging.\"\"\"\n    logging.basicConfig(\n        format=\"%(message)s\",\n        stream=sys.stdout,\n        level=logging.INFO,\n    )\n\n    structlog.configure(\n        processors=[\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.add_logger_name,\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.StackInfoRenderer(),\n            structlog.processors.format_exc_info,\n            structlog.processors.JSONRenderer(),\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )",
    "tests/conftest.py": "import pytest\nfrom fastapi.testclient import TestClient\nfrom unittest.mock import patch\nfrom python_service.config import Settings\n\n@pytest.fixture(autouse=True)\ndef override_settings_for_tests():\n    \"\"\"\n    Patches the Settings class for all tests to prevent loading .env files\n    and to provide a consistent, mock configuration. This runs automatically.\n    \"\"\"\n    class TestSettings(Settings):\n        class Config:\n            env_file = None\n\n    mock_settings = TestSettings(\n        BETFAIR_APP_KEY=\"test_key\",\n        BETFAIR_USERNAME=\"test_user\",\n        BETFAIR_PASSWORD=\"test_password\",\n        API_KEY=\"test_api_key\",\n        TVG_API_KEY=\"test_tvg_key\",\n        RACING_AND_SPORTS_TOKEN=\"test_ras_token\",\n        POINTSBET_API_KEY=\"test_pb_key\"\n    )\n    with patch('python_service.config.Settings', return_value=mock_settings):\n        yield\n\n@pytest.fixture\ndef client():\n    \"\"\"\n    Creates a TestClient for the API. The app is imported *inside* this\n    fixture to ensure the settings patch is active before initialization.\n    \"\"\"\n    from python_service.api import app\n    with TestClient(app) as c:\n        yield c",
    "tests/test_api.py": "# tests/test_api.py\n\nimport pytest\nfrom unittest.mock import patch, AsyncMock\nfrom datetime import datetime\nfrom decimal import Decimal\n\nfrom python_service.models import Race, Runner, OddsData, RaceDay\n\n# The 'client' fixture is automatically available from tests/conftest.py\n\ndef test_health_check(client):\n    \"\"\"\n    SPEC: The /health endpoint should be available and return a healthy status.\n    \"\"\"\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"ok\"}\n\n# Patch where the function is LOOKED UP (in the api module), not where it's defined.\n@patch('python_service.api.fetch_all_races', new_callable=AsyncMock)\ndef test_get_races_success(mock_fetch, client):\n    \"\"\"\n    SPEC: The /api/races endpoint should return a list of RaceDay objects with a valid API key.\n    \"\"\"\n    # ARRANGE\n    now = datetime.now()\n    mock_raceday = RaceDay(\n        track_name=\"Test Park\",\n        races=[\n            Race(\n                id=\"test_race_1\",\n                venue=\"Test Park\",\n                race_number=1,\n                start_time=now,\n                runners=[\n                    Runner(\n                        number=1,\n                        name=\"Test Runner 1\",\n                        odds={\n                            \"TestSource\": OddsData(\n                                win=Decimal(\"5.0\"),\n                                source=\"TestSource\",\n                                last_updated=now\n                            )\n                        }\n                    )\n                ],\n                source=\"TestSource\"\n            )\n        ]\n    )\n    mock_fetch.return_value = [mock_raceday]\n    headers = {\"X-API-Key\": \"test_api_key\"}\n\n    # ACT\n    response = client.get(\"/api/races\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    response_data = response.json()\n    assert len(response_data) == 1\n    assert response_data[0]['track_name'] == \"Test Park\"\n    mock_fetch.assert_awaited_once()\n\n@patch('python_service.api.get_adapter_statuses')\ndef test_get_all_adapter_statuses_success(mock_get_statuses, client):\n    \"\"\"\n    SPEC: The /api/adapters/status endpoint should return status data for all adapters.\n    \"\"\"\n    mock_status_data = [\n        {'adapter_name': 'AtTheRaces', 'status': 'OK'},\n        {'adapter_name': 'BetfairExchange', 'status': 'OK'},\n        {'adapter_name': 'BetfairGreyhound', 'status': 'OK'},\n        {'adapter_name': 'Harness Racing (USTA)', 'status': 'OK'},\n        {'adapter_name': 'Racing and Sports', 'status': 'OK'},\n        {'adapter_name': 'Racing and Sports Greyhound', 'status': 'OK'},\n        {'adapter_name': 'SportingLife', 'status': 'OK'},\n        {'adapter_name': 'Timeform', 'status': 'OK'},\n        {'adapter_name': 'TVG', 'status': 'OK'}\n    ]\n    mock_get_statuses.return_value = mock_status_data\n    headers = {\"X-API-Key\": \"test_api_key\"}\n\n    response = client.get(\"/api/adapters/status\", headers=headers)\n\n    assert response.status_code == 200\n    assert response.json() == mock_status_data\n    mock_get_statuses.assert_called_once()\n\n@patch('python_service.api.fetch_all_races', new_callable=AsyncMock)\ndef test_get_qualified_races_success(mock_fetch, client):\n    \"\"\"\n    SPEC: The /api/races/qualified endpoint should correctly filter races.\n    \"\"\"\n    # ARRANGE\n    now = datetime.now()\n    # This race should pass the TrifectaAnalyzer's default criteria\n    passing_race = Race(\n        id=\"passing_race\", venue=\"Test Park\", race_number=1, start_time=now, source=\"Test\",\n        runners=[\n            Runner(number=1, name=\"Fav\", odds={\"Test\": OddsData(win=Decimal(\"3.0\"), source=\"Test\", last_updated=now)}),\n            Runner(number=2, name=\"SecondFav\", odds={\"Test\": OddsData(win=Decimal(\"4.5\"), source=\"Test\", last_updated=now)}),\n            Runner(number=3, name=\"ThirdFav\", odds={\"Test\": OddsData(win=Decimal(\"5.0\"), source=\"Test\", last_updated=now)})\n        ]\n    )\n    # This race should fail because the favorite's odds are too low\n    failing_race = Race(\n        id=\"failing_race\", venue=\"Test Park\", race_number=2, start_time=now, source=\"Test\",\n        runners=[\n            Runner(number=1, name=\"TooHotFav\", odds={\"Test\": OddsData(win=Decimal(\"1.5\"), source=\"Test\", last_updated=now)})\n        ]\n    )\n\n    mock_fetch.return_value = [RaceDay(track_name=\"Test Park\", races=[passing_race, failing_race])]\n    headers = {\"X-API-Key\": \"test_api_key\"}\n\n    # ACT\n    response = client.get(\"/api/races/qualified/trifecta\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    qualified_races = response.json()\n    assert len(qualified_races) == 1\n    assert qualified_races[0]['id'] == \"passing_race\"\n    assert 'qualification_score' in qualified_races[0]\n    mock_fetch.assert_awaited_once()"
}