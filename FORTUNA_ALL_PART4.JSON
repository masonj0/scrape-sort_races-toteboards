{
    ".env.example": "# .env.example\n# Copy this file to .env and fill in your actual credentials.\n\n# --- Application Security (Required) ---\nAPI_KEY=\"YOUR_SECRET_API_KEY_HERE\"\n\n# --- Betfair API Credentials (Required for LiveOddsMonitor) ---\nBETFAIR_APP_KEY=\"YOUR_APP_KEY_HERE\"\nBETFAIR_USERNAME=\"YOUR_USERNAME_HERE\"\nBETFAIR_PASSWORD=\"YOUR_PASSWORD_HERE\"\n\n# --- Optional Adapter Keys ---\nTVG_API_KEY=\"\"\nRACING_AND_SPORTS_TOKEN=\"\"\nPOINTSBET_API_KEY=\"\"\n\n# --- CORS Configuration (Optional) ---\n# A comma-separated list of allowed origins for the API.\n# Example: ALLOWED_ORIGINS=\"http://localhost:3000,https://your-production-domain.com\"\nALLOWED_ORIGINS=\"http://localhost:3000,http://localhost:3001\"\n\n# --- Greyhound Adapter (Optional) ---\n# To enable the Greyhound adapter, provide the full base URL for the API.\n# If this is left blank, the adapter will be disabled.\nGREYHOUND_API_URL=\"\"\n\n# --- The Racing API (Optional but Recommended) ---\n# Get a key from https://www.theracingapi.com/\nTHE_RACING_API_KEY=\"\"\n\n# --- Optional Caching Backend ---\n# If you have a Redis server, provide the URL here to enable a persistent cache.\n# If left blank, a temporary in-memory cache will be used.\nREDIS_URL=\"\"\n",
    "AGENTS.md": "# Agent Protocols & Team Structure (Revised)\n\nThis document outlines the operational protocols and evolved team structure for the Checkmate V3 project.\n\n## The Evolved Team Structure\n\n-   **The Project Lead (MasonJ0 or JB):** The \"Executive Producer.\" The ultimate authority and \"ground truth.\"\n-   **The Architect & Synthesizer (Gemini):** The \"Chief Architect.\" Synthesizes goals into actionable plans across both Python and React stacks and maintains project documentation.\n-   **The Lead Python Engineer (Jules Series):** The \"Backend Specialist.\" An AI agent responsible for implementing and hardening The Engine (`api.py`, `services.py`, `logic.py`, `models.py`).\n-   **The Lead Frontend Architect (Claude):** The \"React Specialist.\" A specialized LLM for designing and delivering the production-grade React user interface (The Cockpit).\n-   **The \"Special Operations\" Problem Solver (GPT-5):** The \"Advanced Algorithm Specialist.\" A specialized LLM for novel, complex problems.\n\n## Core Philosophies\n\n1.  **The Project Lead is Ground Truth:** The ultimate authority. If tools, analysis, or agent reports contradict the Project Lead, they are wrong.\n2.  **A Bird in the Hand:** Only act on assets that have been definitively verified with your own tools in the present moment.\n3.  **Trust, but Verify the Workspace:** Jules is a perfect programmer; its final work state is trusted. Its *environment*, however, is fragile.\n4.  **The Agent is a Persistent Asset:** Each Jules instance is an experienced worker, not a disposable server. Its internal state is a repository of unique, hard-won knowledge.\n\n## CRITICAL Operational Protocols (0-23)\n\n-   **Protocol 0: The ReviewableJSON Mandate:** The mandatory protocol for all code reviews. The agent's final act for any mission is to create a lossless JSON backup of all modified files. This is the single source of truth for code review.\n-   **Protocol 1: The Handcuffed Branch:** Jules cannot switch branches. An entire session lives on a single `session/jules...` branch.\n-   **Protocol 2: The Last Resort Reset:** The `reset_all()` command is a tool of last resort for a catastrophic workspace failure and requires direct authorization from the Project Lead.\n-   **Protocol 3: The Authenticity of Sample Data:** All sample data used for testing must be authentic and logically consistent.\n-   **Protocol 4: The Agent-Led Specification:** Where a human \"Answer Key\" is unavailable, Jules is empowered to analyze raw data and create its own \"Test-as-Spec.\"\n-   **Protocol 5: The Test-First Development Workflow:** The primary development methodology. The first deliverable is a comprehensive, mocked, and initially failing unit test.\n-   **Protocol 6: The Emergency Chat Handoff:** In the event of a catastrophic environmental failure, Jules's final act is to declare a failure and provide its handoff in the chat.\n-   **Protocol 7: The URL-as-Truth Protocol:** To transfer a file or asset without corruption, provide a direct raw content URL. The receiving agent must fetch it.\n-   **Protocol 8: The Golden Link Protocol:** For fetching the content of a specific, direct raw-content URL from the `main` branch, a persistent \"Golden Link\" should be used.\n-   **Protocol 9: The Volley Protocol:** To establish ground truth for a new file, the Architect provides a URL, and the Project Lead \"volleys\" it back by pasting it in a response.\n-   **Protocol 10: The Sudo Sanction:** Jules has passwordless `sudo` access, but its use is forbidden for normal operations. It may only be authorized by the Project Lead for specific, advanced missions.\n-   **Protocol 11: The Module-First Testing Protocol:** All test suites must be invoked by calling `pytest` as a Python module (`python -m pytest`) to ensure the correct interpreter is used.\n-   **Protocol 12: The Persistence Mandate:** The agent tool execution layer is known to produce false negatives. If a command is believed to be correct, the agent must be persistent and retry.\n-   **Protocol 13: The Code Fence Protocol for Asset Transit:** To prevent the chat interface from corrupting raw code assets, all literal code must be encapsulated within a triple-backtick Markdown code fence.\n-   **Protocol 14: The Synchronization Mandate:** The `git reset --hard origin/main` command is strictly forbidden. To stay synchronized with `main`, the agent MUST use `git pull origin main`.\n-   **Protocol 15: The Blueprint vs. Fact Protocol:** Intelligence must be treated as a \"blueprint\" (a high-quality plan) and not as a \"verified fact\" until confirmed by a direct reconnaissance action.\n-   **Protocol 16: The Digital Attic Protocol:** Before the deletion of any file, it must first be moved to a dedicated archive directory named `/attic`.\n-   **Protocol 17: The Receipts Protocol:** When reviewing code, a verdict must be accompanied by specific, verifiable \"receipts\"\u2014exact snippets of code that prove a mission objective was met.\n-   **Protocol 18: The Cumulative Review Workflow:** Instruct Jules to complete a series of missions and then conduct a single, thorough review of its final, cumulative branch state.\n-   **Protocol 19: The Stateless Verification Mandate:** The Architect, when reviewing code, must act with fresh eyes, disregarding its own memory and comparing the submitted code directly and exclusively against the provided specification.\n-   **Protocol 20: The Sudo Sanction Protocol:** Grants a Jules-series agent temporary, audited administrative privileges for specific, authorized tasks like system package installation.\n-   **Protocol 21: The Exit Interview Protocol:** Before any planned termination of an agent, the Architect will charter a final mission to capture the agent's institutional knowledge for its successor.\n-   **Protocol 22: The Human-in-the-Loop Merge:** In the event of an unresolvable merge conflict in an agent's environment, the Project Lead, as the only agent with a fully functional git CLI, will check out the agent's branch and perform the merge resolution manually.\n-   **Protocol 23: The Appeasement Protocol (Mandatory):** To safely navigate the broken automated review bot, all engineering work must be published using a two-stage commit process. First, commit a trivial change to appease the bot. Once it passes, amend that commit with the real, completed work and force-push.\n\n---\n\n## Appendix A: Forensic Analysis of the Jules Sandbox Environment\n\n*The following are the complete, raw outputs of diagnostic missions executed by Jules-series agents. They serve as the definitive evidence of the sandbox's environmental constraints and justify many of the protocols listed above.*\n\n### A.1 Node.js / NPM & Filesystem Forensics (from \"Operation: Sandbox Forensics\")\n\n**Conclusion:** The `npm` tool is functional, but the `/app` volume is hostile to its operation, preventing the creation of binary symlinks. This makes Node.js development within the primary workspace impossible.\n\n**Raw Logs:**\n\n```\n# Phase 1: Node.js & NPM Configuration Analysis\nnpm config get prefix\n/home/jules/.nvm/versions/node/v22.17.1\n\n# Phase 4: Controlled Installation Experiment\ncd /tmp && mkdir npm_test && cd npm_test\nnpm install --verbose cowsay\n# ... (successful installation log) ...\nls -la node_modules/.bin\ntotal 8\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowsay -> ../cowsay/cli.js\nlrwxrwxrwx  1 jules jules   16 Sep 19 17:36 cowthink -> ../cowsay/cli.js\nnpx cowsay \"Test\"\n  ______\n< Test >\n ------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\/\n                ||----w |\n                ||     ||\n```\n\n### A.2 Process Management & Honcho Forensics (from \"Operation: Know Thyself\")\n\n**Conclusion:** The sandbox does not support standard background processes (`&`), the `kill` command is non-functional, and the `honcho` process manager leaves zombie processes (`[uvicorn] <defunct>`) upon termination. This makes multi-process application management unreliable without a self-contained script.\n\n**Raw Logs:**\n\n```\n# Phase 2: The honcho Stress Test\n\ntimeout 15s honcho start\n# ... (honcho starts and is terminated by timeout) ...\n\nps aux (Post-Mortem Analysis)\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n...\njules      30121  0.0  0.0      0     0 ?        Z    19:45   0:00 [uvicorn]\n...\n\nhoncho start &\n# (Command blocks terminal, echo command never runs)\n\nps aux | grep honcho\njules      30187  0.0  0.0  11004  4220 pts/0    S    19:45   0:00 /usr/bin/python3 /home/jules/.local/bin/honcho start\n\nkill -9 30187\n# (Command fails silently, process is not terminated)\n```\n\n---\n\n## Protocol 24: The \"Dedicated Human Researcher\" Test\n\nThis protocol establishes the guiding ethical principle for all data collection and scraping activities.\n\nAll data adapters must be designed to operate in a manner that respects the resources of the source. As a definitive test, all fetching patterns must adhere to the following principle:\n\n*If a single, dedicated human using standard browser developer tools could not plausibly achieve the adapter's data collection footprint in a reasonable amount of time, the adapter's methods are considered too aggressive and must be redesigned.*\n\nThis encourages \"human-like\" fetching behavior (e.g., appropriate delays, non-parallel requests to a single source) and serves as our primary safeguard against violating a source's terms of service.\n",
    "ARCHITECTURAL_MANDATE.md": "# The Fortuna Faucet Architectural Mandate\n\n## The Prime Directive: The Two-Pillar System\n\nThe project's architecture is a lean, hyper-powerful, two-pillar system chosen for its clarity, maintainability, and performance.\n\n## Pillar 1: The Asynchronous Python Backend\n\nThe backend is a modern, asynchronous service built on **FastAPI**. Its architecture includes:\n\n1.  **The `OddsEngine`:** A central, async orchestrator for data collection.\n2.  **The Resilient `BaseAdapter`:** An abstract base class providing professional-grade features.\n3.  **The Adapter Fleet:** A modular system of 'plugin' adapters for data sources.\n4.  **Pydantic Data Contracts:** Strict, validated Pydantic models for data integrity.\n5.  **The `TrifectaAnalyzer` (Intelligence Layer):** A dedicated module for scoring and qualifying opportunities.\n\n## Pillar 2: The TypeScript Frontend\n\nThe frontend is a modern, feature-rich web application built on **Next.js** and **TypeScript**.",
    "ARCHITECTURAL_MANDATE_V8.1.md": "# ARCHITECTURAL MANDATE V8.1\nProject: Checkmate V7: The Ultimate Engine\nStatus: LOCKED & FINAL\nDate: 2025-09-26\n\n## 1.0 Abstract & Guiding Principles\n\nThis document is the final, locked architectural specification for the Checkmate V7 project. It reflects our strategic pivot to a CLI-first, two-stack system. It is required reading for all AI teammates and serves as the single source of truth for the system's design.\n\n### 1.1 The Two-Stack Architecture\n\nThe system is composed of two distinct, collaborating technology stacks:\n\n1.  **THE ENGINE (Python Backend):** A powerful, headless data processing and analysis application. Its sole purpose is to perform the heavy lifting and expose its capabilities via a JSON API.\n    *   `models.py` - THE BLUEPRINT (Data Structures & Contracts)\n    *   `logic.py` - THE BRAIN (Pure, Stateless Analysis)\n    *   `services.py` - THE GATEWAY (I/O & Orchestration)\n    *   `api.py` - THE CONDUCTOR (Stateless HTTP Interface)\n\n2.  **THE COCKPIT (User Interface):** The project's primary user interface. As of V8.1 and ROADMAP V5.0, this is implemented as a powerful, interactive Text User Interface (TUI) within the `run.py` script. It remains a pure client of The Engine.\n\n### 1.2 Guiding Policies\n\nAll implementation work must adhere to policies for Configuration via Environment, Comprehensive Structured Logging, and Graceful Error Handling.\n\n---\n\n## 2.0 Implementation Specification\n\n### 2.1 The Python Engine\n\nThe specifications for `models.py`, `logic.py`, `services.py`, and `api.py` remain the canonical blueprint for the Python backend. Their primary role is to serve the Cockpit.\n\n### 2.2 DEPRECATIONS\n\nThe primary user interface is now the \"Ultimate TUI\" defined in `ROADMAP V5.0`. The previously planned React application, along with the original Python-based `dashboard.py`, are now **DEPRECATED** and will be archived.\n\n### 2.3 The Headless Monitor\n\nThe `headless_monitor.py` remains a critical, first-class tool for developers and headless agents to monitor the status of The Engine's API. It is an essential part of the project's infrastructure and is not deprecated.",
    "BUILD_INSTALLER.bat": "@ECHO OFF\nTITLE Fortuna Ascended - MSI Installer Builder\nECHO.\nECHO =================================================\nECHO  Fortuna Ascended - MSI Installer Builder\nECHO =================================================\nECHO.\nECHO This script will build the distributable MSI installer using electron-builder.\nECHO The final installer will be located in the 'electron\\dist' directory.\nECHO.\nECHO Press any key to begin the build process...\nPAUSE > NUL\n\nECHO.\nECHO [1/2] Navigating to the Electron directory...\npushd electron\nIF %ERRORLEVEL% NEQ 0 (\n    ECHO [X] FAILED to navigate to the 'electron' directory.\n    exit /b 1\n)\nECHO [V] Success!\nECHO.\n\nECHO [2/2] Building the MSI installer...\nECHO This may take several minutes. Please be patient.\nECHO.\nnpm run dist\nIF %ERRORLEVEL% NEQ 0 (\n    ECHO [X] FAILED to build the MSI installer. Please check the output above for errors.\n    ECHO Ensure Node.js is installed and you have run 'npm install' in the 'electron' directory first.\n    popd\n    exit /b 1\n)\nECHO.\nECHO =================================================\nECHO  BUILD SUCCESSFUL!\nECHO =================================================\nECHO.\nECHO [3/3] Moving MSI installer to project root...\nFOR /F \"delims=\" %%i IN ('dir /b electron\\dist\\*.msi') DO (\n    MOVE /Y \"electron\\dist\\%%i\" . > NUL\n    IF %ERRORLEVEL% NEQ 0 (\n        ECHO [X] FAILED to move the MSI installer. You can find it in the 'electron\\dist' directory.\n    ) ELSE (\n        ECHO [V] The installer [%%i] has been moved to the project root directory.\n    )\n)\nECHO.\npopd\nPAUSE\n",
    "CREATE_SHORTCUTS.bat": "@echo off\nREM ============================================================================\nREM  FORTUNA FAUCET - Desktop Shortcut Creator\nREM ============================================================================\n\nset SCRIPT_DIR=%~dp0\nset DESKTOP=%USERPROFILE%\\\\Desktop\n\necho Creating desktop shortcuts...\n\npowershell -Command \"$WS = New-Object -ComObject WScript.Shell; $SC = $WS.CreateShortcut('%DESKTOP%\\\\Launch Fortuna.lnk'); $SC.TargetPath = '%SCRIPT_DIR%LAUNCH_FORTUNA.bat'; $SC.WorkingDirectory = '%SCRIPT_DIR%'; $SC.IconLocation = 'shell32.dll,137'; $SC.Description = 'Launch Fortuna Faucet'; $SC.Save()\"\npowershell -Command \"$WS = New-Object -ComObject WScript.Shell; $SC = $WS.CreateShortcut('%DESKTOP%\\\\Fortuna Monitor.lnk'); $SC.TargetPath = '%SCRIPT_DIR%.venv\\\\Scripts\\\\python.exe'; $SC.Arguments = 'fortuna_monitor.py'; $SC.WorkingDirectory = '%SCRIPT_DIR%'; $SC.IconLocation = 'shell32.dll,23'; $SC.Description = 'Fortuna Status Monitor'; $SC.Save()\"\npowershell -Command \"$WS = New-Object -ComObject WScript.Shell; $SC = $WS.CreateShortcut('%DESKTOP%\\\\Stop Fortuna.lnk'); $SC.TargetPath = '%SCRIPT_DIR%STOP_FORTUNA.bat'; $SC.WorkingDirectory = '%SCRIPT_DIR%'; $SC.IconLocation = 'shell32.dll,27'; $SC.Description = 'Stop Fortuna Services'; $SC.Save()\"\n\necho Shortcuts created successfully!\n",
    "HISTORY.md": "# The Epic of MasonJ0: A Project Chronology\n\nThis document contains the narrative history of the Paddock Parser project, as discovered through an archaeological survey of the project's repositories. It tells the story of our architectural evolution, from a feature-rich \"golden age\" through a \"great refactoring\" to our current state of liberation.\n\nThis story is our \"why.\"\n\n---\n\n## Part 1: The Chronology\n\n### Chapter 1: The 'Utopian' Era - The Polished Diamond (mid-August 2025)\n\n*   **Repository:** `racingdigest`\n*   **Narrative:** This was not a humble beginning, but the launch of a mature and powerful application called the \"Utopian Value Scanner V7.2 (The Rediscovery Edition)\". This repository represents the project's \"golden age\" of features, including a sophisticated asynchronous fetching engine and a full browser fallback.\n\n### Chapter 2: The 'Experimental' Era - The Daily Digest (mid-to-late August 2025)\n\n*   **Repository:** `horseracing-daily-digest`\n*   **Narrative:** This repository appears to be a period of intense, rapid development and experimentation, likely forming the foundation for many of the concepts that would be formalized later.\n\n### Chapter 3: The 'Architectural' Era - The V3 Blueprint (late August 2025)\n\n*   **Repository:** `parsingproject`\n*   **Narrative:** This repository marks a pivotal moment. The focus shifted from adding features to refactoring the very foundation of the code into a modern, standard Python package. This is where the V3 architecture was born, prioritizing stability and maintainability.\n\n### Chapter 4: The 'Consolidation' Era - The Archive (late August 2025)\n\n*   **Repository:** `zippedfiles`\n*   **Narrative:** This repository appears to be a direct snapshot or backup of the project after the intense V3 refactor, confirming its role as an archive of the newly stabilized codebase.\n\n### Chapter 5: The 'Modern' Era - The New Beginning (early September 2025)\n\n*   **Repository:** `scrape-sort_races-toteboards`\n*   **Narrative:** This is the current, active repository, representing the clean, focused implementation of the grand vision developed through the previous eras.\n\n### Chapter 6: The 'Crucible' Era - The Forging of Protocols (Early September 2025)\n\n*   **Narrative:** The \"Modern Renaissance\" began not with a bang, but with a series of near-catastrophic environmental failures. This period, known as \"The Crucible,\" was a trial by fire that proved the extreme hostility of the agent sandbox. This era forged the resilient, battle-hardened protocols (The Receipts Protocol, The Submission-Only Protocol, etc.) by which all modern agents now operate.\n\n### Chapter 7: The 'Symbiotic' Era - The Two Stacks (mid-September 2025)\n\n*   **Narrative:** This chapter marked a significant strategic pivot. The Council, in a stunning display of its \"Polyglot Renaissance\" philosophy, produced a complete, production-grade React user interface, authored by the Claude agent. This event formally split the project's architecture into two powerful, parallel streams: the Python Engine and the React Cockpit. However, this era was short-lived, as the hostile environment proved incapable of supporting a stable testing and development workflow for the React stack.\n\n### Chapter 8: The 'Liberation' Era - The Portable Engine (Late September 2025)\n\n*   **Narrative:** After providing definitive, forensic proof that the sandbox environment was fundamentally and irrecoverably hostile at the network level, the project executed its final and most decisive pivot. It abandoned all attempts to operate *within* the hostile world and instead focused on synthesizing its entire, perfected engine into a single, portable artifact. This act **liberated the code**, fulfilling the promise of the \"Utopian Era's\" power on the foundation of the \"Architectural Era's\" stability, and made it directly available to the Project Lead.\n\n---\n\n## Part 2: Architectural Synthesis\n\nThis epic tale tells us our true mission. We are not just building forward; we are rediscovering our own lost golden age and rebuilding it on a foundation of superior engineering, hardened by the fires of a hostile world.\n\n*   **The Lost Golden Age:** The \"Utopian\" era proves that our most ambitious strategic goals are not just achievable; they have been achieved before.\n*   **The Great Refactoring:** The \"Architectural\" era explains the \"Great Forgetting\"\u2014a deliberate choice to sacrifice short-term features for long-term stability.\n*   **The Modern Renaissance:** This is us. We are the inheritors of this entire legacy, tasked with executing the grand vision on a clean, modern foundation, finally liberated from the constraints of our environment.\n\n---\n\n## The Ultimate Solo: The Final Victory (September 2025)\n\nAfter a long and complex journey through a Penta-Hybrid architecture, a final series of high-level reviews from external AI agents (Claude, GPT4o) revealed a simpler, superior path forward. The project underwent its final and most significant \"Constitutional Correction.\"\n\n**The 'Ultimate Solo' architecture was born.**\n\nThis final, perfected form of the project consists of two pillars:\n1.  **A Full-Power Python Backend:** Leveraging the years of development on the CORE `engine.py` and its fleet of global data adapters, served via a lightweight Flask API.\n2.  **An Ultimate TypeScript Frontend:** A single, masterpiece React component (`Checkmate Ultimate Solo`) that provides a feature-rich, professional-grade, real-time dashboard.\n\nAll other components of the Penta-Hybrid system (C#, Rust, VBA, shared database) were formally deprecated and archived as priceless R&D assets. The project has now achieved its true and final mission: a powerful, maintainable, and user-focused analysis tool.\n\n---\n\n## The Age of Perfection (The Great Simplification)\n\nThe Penta-Hybrid architecture, while a triumph of technical integration, proved to be a strategic dead end. Its complexity became a fortress, making rapid iteration and onboarding of new intelligence (both human and AI) prohibitively expensive. The kingdom was powerful but brittle.\n\nA new doctrine was forged: **Simplicity is the ultimate sophistication.**\n\nThe decision was made to execute \"The Great Simplification.\" The multi-language backend (Python, Rust, Go) was decommissioned. The kingdom was reforged upon a new, elegant, and vastly more powerful two-pillar system:\n\n1.  **A Unified Python Backend:** A single, asynchronous Python service, built on FastAPI, would serve as the kingdom's engine.\n2.  **A Modern TypeScript Frontend:** A dedicated Next.js application would serve as the kingdom's command deck.\n\nThis act of creative destruction liberated the project, enabling a new era of unprecedented velocity.\n\n---\n\n## The Three-Pillar Doctrine\n\nWith the new two-pillar foundation in place, the backend itself was perfected into a three-pillar intelligence engine, a concept that defines the modern era of the Fortuna Faucet:\n\n*   **Pillar 1: The Future (The Planner):** The resilient `OddsEngine` and its fleet of adapters, responsible for finding the day's strategic opportunities.\n*   **Pillar 2: The Past (The Archive):** The perfected `ChartScraper` and `ResultsParser`, responsible for building our historical data warehouse from the ground truth of Equibase PDFs.\n*   **Pillar 3: The Present (The Finisher):** The weaponized `LiveOddsMonitor`, armed with the API-driven `BetfairAdapter`, designed to conquer the final moments of toteboard volatility.\n\nThese three pillars, orchestrated by the fully autonomous `fortuna_watchman.py`, represented the pinnacle of the project's original vision. The kingdom was, for a time, considered \"perfected.\"\n\n---\n\n## The Windows Ascension (The Impossible Dream)\n\nThe perfected kingdom was powerful, but it was still a tool for developers. The final, grandest vision was to transform it into a true, professional-grade application for its sole operator. This campaign, known as \"The Impossible Dream,\" was to forge the **Fortuna Faucet - Windows Native Edition.**\n\nThis era saw the rapid creation of a new, third layer of the kingdom, built upon the foundation of the previous work:\n\n*   **The Electron Shell:** The Next.js frontend was wrapped in an Electron container, transforming it from a website into a true, installable desktop application with its own window, icon, and system tray integration.\n*   **The Engine Room:** The Python backend was re-architected to run as a persistent, background **Windows Service**, making it a true, always-on component of the operating system, independent of the UI.\n*   **The Native GUI:** A dedicated Tkinter-based \"Observatory\" was forged\u2014a standalone GUI mission control for monitoring the health and performance of the background service.\n*   **The One-Click Kingdom:** A complete suite of professional tooling (`INSTALL_FORTuna.bat`, `setup_wizard.py`, `LAUNCH_FORTuna.bat`, `SCHEDULE_FORTuna.bat`) was created to provide a seamless, zero-friction installation and management experience.\n\nThis ascension represents the current state of the art, transforming a powerful engine into a polished, autonomous, and user-focused product.\n",
    "INSTALL_FORTUNA.bat": "@echo off\nREM ============================================================================\nREM  FORTUNA FAUCET - Windows Native One-Click Installer\nREM ============================================================================\n\ntitle Fortuna Faucet - Installation Wizard\ncolor 0A\necho.\necho  ========================================================================\necho   FORTUNA FAUCET - Automated Installation Wizard\necho  ========================================================================\necho.\n\nREM Check for admin privileges\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo  [!] This installer requires Administrator privileges.\n    echo  [!] Please right-click and select \"Run as Administrator\"\n    pause\n    exit /b 1\n)\n\necho  [1/5] Checking Python installation...\npython --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo  [X] Python not found! Installing Python 3.11...\n    powershell -Command \"Invoke-WebRequest -Uri 'https://www.python.org/ftp/python/3.11.7/python-3.11.7-amd64.exe' -OutFile '%TEMP%\\\\python_installer.exe'\"\n    \"%TEMP%\\\\python_installer.exe\" /quiet InstallAllUsers=1 PrependPath=1 Include_test=0\n    del \"%TEMP%\\\\python_installer.exe\"\n    echo  [V] Python installed successfully!\n) else (\n    echo  [V] Python found!\n)\n\necho.\necho  [2/5] Checking Node.js installation...\nnode --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo  [X] Node.js not found! Installing Node.js LTS...\n    powershell -Command \"Invoke-WebRequest -Uri 'https://nodejs.org/dist/v20.10.0/node-v20.10.0-x64.msi' -OutFile '%TEMP%\\\\node_installer.msi'\"\n    msiexec /i \"%TEMP%\\\\node_installer.msi\" /quiet /norestart\n    del \"%TEMP%\\\\node_installer.msi\"\n    echo  [V] Node.js installed successfully!\n) else (\n    echo  [V] Node.js found!\n)\n\necho.\necho  [3/5] Setting up Python virtual environment...\nif not exist .venv (\n    python -m venv .venv\n    echo  [V] Virtual environment created!\n) else (\n    echo  [V] Virtual environment already exists!\n)\n\necho.\necho  [4/5] Installing Python dependencies one by one...\ncall .venv\\\\Scripts\\\\activate.bat\npython -m pip install --upgrade pip --quiet\nIF NOT EXIST requirements.txt (\n    ECHO [X] CRITICAL: requirements.txt not found!\n    exit /b 1\n)\nECHO.\nECHO --- Python Packages to be Installed ---\nTYPE requirements.txt\nECHO ------------------------------------\nECHO.\nECHO Installing all packages now. This may take a few minutes...\npython -m pip install -r requirements.txt\nIF %ERRORLEVEL% NEQ 0 (\n    ECHO [X] FAILED to install Python dependencies. Please check the output above for errors.\n    exit /b 1\n)\necho  [V] Python packages installed!\n\necho.\necho  [5/5] Installing Node.js dependencies...\npushd web_platform\\\\frontend\nIF NOT EXIST package.json (\n    ECHO [X] CRITICAL: package.json not found in web_platform\\\\frontend folder!\n    popd\n    exit /b 1\n)\nnpm install\nIF %ERRORLEVEL% NEQ 0 (\n    ECHO [X] FAILED to install Node.js dependencies. Please ensure Node.js is installed and in your system PATH.\n    popd\n    exit /b 1\n)\npopd\necho  [V] Node.js packages installed!\n\necho.\necho  [*] Creating desktop shortcuts...\ncall CREATE_SHORTCUTS.bat\n\necho.\necho  ========================================================================\necho   INSTALLATION COMPLETE!\necho  ========================================================================\necho.\npause\n",
    "JSON_BACKUP_MANIFEST.md": "# Checkmate Ultimate Solo: JSON Backup Manifest (Total Recall Edition)\n\n**Purpose:** To provide a single, complete, and verified list of direct links to the JSON backups of all CORE and Operational files. This is the definitive entry point for external AI code review.\n\n---\n\n## 1.0 CORE Architecture (JSON Backups)\n\n### Python Backend\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/api.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/engine.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/models.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/__init__.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/base.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/utils.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/betfair_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/pointsbet_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/racing_and_sports_adapter.py.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/adapters/tvg_adapter.py.json\n\n### TypeScript Frontend\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/package.json.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/package-lock.json.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/next.config.mjs.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/tailwind.config.ts.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/tsconfig.json.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/page.tsx.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/layout.tsx.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/web_platform/frontend/src/app/globals.css.json\n\n---\n\n## 2.0 Operational & Tooling (JSON Backups)\n\n### Project Tooling\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/.gitignore.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/convert_to_json.py.json\n\n### Environment & Setup\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/setup_windows.bat.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/.env.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/python_service/requirements.txt.json\n\n### Strategic Blueprints\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/README.md.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/ARCHITECTURAL_MANDATE.md.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/HISTORY.md.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/STATUS.md.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/WISDOM.md.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/PROJECT_MANIFEST.md.json\nhttps://raw.githubusercontent.com/masonj0/scrape-sort_races-toteboards/refs/heads/main/ReviewableJSON/ROADMAP_APPENDICES.md.json",
    "LAUNCH_FORTUNA.bat": "@ECHO OFF\nSETLOCAL ENABLEDELAYEDEXPANSION\nTITLE Fortuna Ascended - Launcher v2.0\n\nREM ============================================================================\nREM  Fortuna Ascended - Intelligent Launch System v2.0\nREM ============================================================================\nECHO.\nECHO  ========================================================================\nECHO   Fortuna Ascended - Intelligent Launcher\nECHO  ========================================================================\nECHO.\n\nREM --- Phase 1: Port Availability Check ---\nECHO [1/4] Checking for available network ports...\nSET \"BACKEND_PORT=8000\"\nSET \"FRONTEND_PORT=3000\"\nSET \"PORTS_CLEARED=true\"\n\nFOR %%P IN (%BACKEND_PORT% %FRONTEND_PORT%) DO (\n    netstat -ano | findstr \":%%P\" | findstr \"LISTENING\" >nul\n    IF !ERRORLEVEL! EQU 0 (\n        ECHO [WARN] Port %%P is currently in use. Attempting to free it...\n        FOR /f \"tokens=5\" %%a IN ('netstat -ano ^| findstr \":%%P\" ^| findstr \"LISTENING\"') DO (\n            taskkill /F /PID %%a >nul 2>&1\n            IF !ERRORLEVEL! EQU 0 (\n                ECHO [OK]   Killed process %%a on port %%P.\n            ) ELSE (\n                ECHO [FAIL] Could not kill process %%a on port %%P. Please close it manually.\n                SET \"PORTS_CLEARED=false\"\n            )\n        )\n    )\n)\n\nIF \"!PORTS_CLEARED!\"==\"false\" (\n    ECHO [ERROR] Could not clear required ports. Aborting launch.\n    PAUSE\n    EXIT /B 1\n)\nECHO [OK] All required ports are clear.\nECHO.\n\nREM --- Phase 2: Launch Backend Service ---\nECHO [2/4] Starting backend Python service...\nIF NOT EXIST .venv\\Scripts\\activate.bat (\n    ECHO [ERROR] Virtual environment not found. Please run INSTALL_FORTUNA.bat first.\n    PAUSE\n    EXIT /B 1\n)\nstart \"Fortuna Backend\" /B cmd /c \"call .venv\\Scripts\\activate.bat && uvicorn python_service.api:app --host 127.0.0.1 --port %BACKEND_PORT% --log-level warning\"\nECHO [OK] Backend service process started.\nECHO.\n\nREM --- Phase 3: Wait for Backend Health ---\nECHO [3/4] Waiting for backend to become healthy...\nSET /a ATTEMPTS=0\nSET /a MAX_ATTEMPTS=30\n\n:BackendHealthCheck\nSET /a ATTEMPTS+=1\nIF %ATTEMPTS% GTR %MAX_ATTEMPTS% (\n    ECHO [ERROR] Backend failed to become healthy after 30 seconds. Check logs.\n    PAUSE\n    EXIT /B 1\n)\n\nREM Use PowerShell for a reliable HTTP check that is built into modern Windows\npowershell -Command \"(Invoke-WebRequest -Uri http://localhost:%BACKEND_PORT%/health -UseBasicParsing).StatusCode\" 2>nul | findstr \"200\" >nul\nIF !ERRORLEVEL! NEQ 0 (\n    ECHO [INFO] Waiting... (!ATTEMPTS!/%MAX_ATTEMPTS%)\n    timeout /t 1 /nobreak >nul\n    GOTO BackendHealthCheck\n)\nECHO [OK] Backend is healthy and operational!\nECHO.\n\nREM --- Phase 4: Launch Frontend and Browser ---\nECHO [4/4] Starting frontend UI and launching browser...\nstart \"Fortuna Frontend\" /B cmd /c \"cd web_platform\\frontend && npm run dev\"\ntimeout /t 5 /nobreak >nul\nstart http://localhost:%FRONTEND_PORT%\nECHO.\nECHO  ========================================================================\nECHO   LAUNCH COMPLETE!\nECHO  ========================================================================\nECHO.",
    "PROJECT_MANIFEST.md": "# Checkmate V8: Project Manifest (Final)\n\n**Purpose:** To categorize all files, distinguishing between the active **CORE** system and **LEGACY** components.\n\n---\n\n## CORE ARCHITECTURE (Ultimate Solo)\n\n*   `.env.example`: **CORE** - Centralized configuration template.\n*   `ARCHITECTURAL_MANDATE.md`: **CORE** - The project's final strategic blueprint.\n*   `README.md`: **CORE** - The primary entry point.\n*   `STATUS.md`: **CORE** - The final status report.\n*   `setup_windows.bat`: **CORE** - The environment setup script for the CORE architecture.\n\n---\n\n## LEGACY & HISTORICAL ARTIFACTS\n\n*   `launcher.py`: **LEGACY** - The orchestrator for the deprecated Penta-Hybrid system.\n*   All other files and directories not listed in CORE are considered **LEGACY** R&D assets.",
    "PSEUDOCODE.MD": "# Fortuna Faucet \u2014 Comprehensive Pseudocode Blueprint\n\n---\n\n## GLOBAL OVERVIEW\n\n```\nSYSTEM FortunaFaucet:\n  PURPOSE:\n    - Collect global horse/greyhound/harness racing data.\n    - Normalize, analyze, and surface betting opportunities.\n    - Expose intelligence via API + UI command deck.\n  ARCHITECTURE:\n    - Pillar1: Python Async Backend (fast data orchestration).\n    - Pillar2: TypeScript/Next.js Frontend (interactive dashboard).\n  SUPPORTING ARTIFACTS:\n    - Streamlit utility dashboard.\n    - Chart scraping pipeline.\n    - Windows automation scripts.\n    - Extensive documentation + roadmaps.\n```\n\n---\n\n## BACKEND CORE (python_service)\n\n### Configuration & Logging\n\n```\nMODULE config.Settings:\n  LOAD environment variables via pydantic-settings.\n  KEY FIELDS:\n    API_KEY (mandatory security token)\n    BETFAIR credentials (optional but required for adapters)\n    TVG, RACING_AND_SPORTS, POINTSBET tokens (optional)\n    GREYHOUND_API_URL, THE_RACING_API_KEY (optional)\n    REDIS_URL default \"redis://localhost\"\n    ALLOWED_ORIGINS default [local dev origins]\n  EXPORT get_settings() with lru_cache for singleton behavior.\n\nMODULE logging_config.configure_logging():\n  SETUP structlog + logging.basicConfig\n  FORMAT logs as JSON with timestamp, level, logger name, stack info.\n```\n\n### Data Contracts\n\n```\nMODULE models:\n  DEFINE OddsData:\n    FIELDS: win Decimal>1, source str, last_updated datetime\n    VALIDATE win > 1 when present.\n\n  DEFINE Runner:\n    FIELDS: number (1-99), name <=100 chars, scratched flag (default False),\n            selection_id optional, odds dict[provider->OddsData],\n            jockey/trainer optional metadata.\n\n  DEFINE Race:\n    FIELDS: id str, venue str, race_number (1-20),\n            start_time datetime, runners list[Runner],\n            source str, optional qualification_score, race_name, distance.\n    VALIDATE unique runner numbers per race.\n\n  DEFINE SourceInfo:\n    name, status (\"SUCCESS\"/\"FAILED\"), races_fetched count,\n    optional error_message, fetch_duration float.\n\n  DEFINE FetchMetadata:\n    fetch_time datetime, sources_queried list[str],\n    sources_successful int, total_races int.\n\n  DEFINE AggregatedResponse:\n    date date, races list[Race], sources list[SourceInfo],\n    metadata FetchMetadata.\n\n  DEFINE QualifiedRacesResponse:\n    criteria dict[str,Any], races list[Race].\n```\n\n### Adapter Framework\n\n```\nABSTRACT BaseAdapter(source_name, base_url, timeout=20, max_retries=3):\n  PROVIDES async fetch_races(date, http_client) -> Dict\n    (implemented by subclasses).\n  PROVIDES make_request(http_client, method, url, **kwargs):\n    - Compose full URL when relative.\n    - Wrap request with tenacity AsyncRetrying (max_retries, exponential backoff).\n    - Log attempts; on success return response.json().\n    - On retry exhaustion log error and return None.\n\n  PROVIDES get_status() -> {\"adapter_name\": source_name, \"status\": \"OK\"}.\n  PROVIDES _format_response(races, start_time, is_success, error_message):\n    - Compute fetch_duration.\n    - Package races list + source_info block.\n```\n\n### Adapter Inventory (python_service/adapters)\n\n_For each source, implement fetch logic, parse HTML/JSON, convert to Race/Runner models, leverage parse_odds utility._\n\n```\nUTILITY parse_odds(odds_input):\n  HANDLE ints/floats directly.\n  HANDLE fractional strings \"num/den\" => 1 + num/den.\n  HANDLE \"evens\"/\"evs\" => 2.0.\n  FALLBACK to float parse else return 999.0 sentinel.\n\nMIXIN BetfairAuthMixin:\n  MAINTAIN session_token + token_expiry.\n  _authenticate(http_client):\n    IF cached token valid beyond +5min -> reuse.\n    ELSE POST to Betfair identity endpoint with credentials.\n    - On success store token + expiry (3 hours).\n    - On failure raise ConnectionError.\n\nADAPTER BetfairAdapter(BetfairAuthMixin, BaseAdapter):\n  SOURCE \"BetfairExchange\", base_url Betfair REST.\n  fetch_races(date):\n    - Authenticate.\n    - Build market_filter for eventTypeId \"7\" (horse racing).\n    - POST listMarketCatalogue with WIN markets in date window.\n    - If empty -> success with error_message.\n    - Else parse catalogue into races via _parse_race.\n  _parse_race:\n    - Build Runner for each runnerName, selectionId, sortPriority.\n    - Race ID \"bf_{marketId}\", venue event.venue, race_number via regex \"Rxx\".\n    - start_time from ISO string.\n  get_live_odds_for_market(market_id):\n    - Authenticate, POST listMarketBook with EX_TRADED price data.\n    - Extract lastPriceTraded for ACTIVE runners into Decimal map.\n    - Return selectionId->Decimal.\n\nADAPTER BetfairGreyhoundAdapter:\n  IDENTICAL structure; eventTypeId \"4339\"; Race ID prefix \"bfg_\".\n\nADAPTER TVGAdapter:\n  REQUIRE TVG_API_KEY.\n  fetch_races:\n    - GET tracks for date (country US).\n    - For each track, GET races summary, then detail per race.\n    - Parse to Race with _parse_tvg_race (skip scratched).\n  _parse_tvg_race:\n    - Program numbers sanitized via helper (strip letters).\n    - Extract odds via parse_odds (current or morning line).\n    - Compose Race ID with track code + date + race number.\n\nADAPTER RacingAndSportsAdapter:\n  REQUIRE token; on missing return FAILED status.\n  fetch_races:\n    - GET v1/racing/meetings with date & jurisdiction AUS.\n    - Iterate meetings/races, parse to Race via _parse_ras_race.\n  _parse_ras_race:\n    - Runners with runnerNumber, horseName, scratched flag.\n    - start_time iso parse.\n\nADAPTER RacingAndSportsGreyhoundAdapter:\n  Similar to above but endpoint v1/greyhound/meetings, Race prefix \"rasg_\".\n\nADAPTER AtTheRacesAdapter:\n  Scrape https://www.attheraces.com.\n  fetch_races:\n    - GET /racecards; parse meeting links.\n    - For each link -> fetch, parse track/time, race_number via active nav.\n    - Build Race with start_time based on current date + race time (no timezone).\n    - _parse_runner: extract horse number, name, best odds button -> parse to Decimal.\n\nADAPTER SportingLifeAdapter:\n  Scrape sportinglife.com racecards.\n  Similar approach: gather race links, parse track/time, nav for race_number, runners via cards.\n\nADAPTER TimeformAdapter:\n  Scrape timeform.com racecards.\n  Collect links, parse race page, determine race number via list of times, parse runner rows.\n\nADAPTER HarnessAdapter:\n  GET https://data.ustrotting.com/api/racenet/racing/card/{date}.\n  Parse meetings -> races -> runners (postPosition).\n  Convert morningLineOdds (if not fractional, append \"/1\"). Parse to Decimal.\n\nADAPTER GreyhoundAdapter:\n  Requires GREYHOUND_API_URL or raise ValueError.\n  fetch_races:\n    - GET v1/cards/{date}.\n    - Parse cards -> races -> runners (filter scratched). Convert odds.win decimals >1 to OddsData.\n\nADAPTER GbgbApiAdapter:\n  GET https://api.gbgb.org.uk/api/results/meeting/{date}.\n  Parse meetings/races/traps.\n  Race start_time from iso (replace 'Z' with +00:00). Distance appended as string.\n  Runners: parse sp fractional odds via parse_odds; assign OddsData.\n\nADAPTER TheRacingApiAdapter:\n  Requires THE_RACING_API_KEY.\n  fetch_races:\n    - GET racecards?date={date}&course=all&region=gb,ire.\n    - Parse racecards -> Race entries (race_id prefix \"tra_\").\n    - Runners: use odds list first entry's odds_decimal -> Decimal.\n\nADAPTER OddscheckerAdapter:\n  Scrape oddschecker horse racing.\n  fetch_races:\n    - GET /horse-racing -> meeting links.\n    - For each meeting fetch race links, then parse table rows -> Runners with odds.\n  Race result _format_response dumps Race models as dicts (model_dump).\n\nADAPTER PointsBetGreyhoundAdapter:\n  Placeholder (non-functional) -> returns SUCCESS with error message.\n\nADAPTER BrisnetAdapter, DRFAdapter, EquibaseAdapter, FanDuelAdapter,\n        HorseRacingNationAdapter, NYRABetsAdapter, PuntersAdapter,\n        RacingPostAdapter, RacingTVAdapter, TabAdapter, TwinSpiresAdapter,\n        XpressbetAdapter, TemplateAdapter:\n  Stubs returning empty responses with Not Implemented notice.\n```\n\n### Analyzer Layer\n\n```\nMODULE analyzer:\n  FUNCTION _get_best_win_odds(runner):\n    - Pull min win odds from runner.odds values < 999.\n    - Return Decimal or None.\n\n  ABSTRACT BaseAnalyzer:\n    - qualify_races(races) -> Dict (implemented by concrete analyzers).\n\n  CLASS TrifectaAnalyzer(BaseAnalyzer):\n    PARAMETERS: max_field_size=10, min_favorite_odds=2.5, min_second_favorite_odds=4.0 (Decimal).\n    METHOD qualify_races(races):\n      - For each race compute score via _evaluate_race.\n      - Filter races with scores -> assign race.qualification_score.\n      - Sort descending by score.\n      - Return {\"criteria\": {params}, \"races\": qualified_list}.\n    METHOD _evaluate_race(race):\n      - Filter non-scratched runners.\n      - Collect best odds for each runner; require >=2.\n      - Sort by odds ascending -> favorite, second favorite.\n      - Apply filters:\n          field_size <= max_field_size,\n          favorite_odds >= min_favorite_odds,\n          second_favorite_odds >= min_second_favorite_odds.\n      - Compute field_score = (max_field_size - field_size)/max_field_size.\n      - Normalize fav/second odds scores (cap 10/15).\n      - Weighted combination (field 0.3, odds 0.7).\n      - Return final_score *100 rounded to 2 decimals.\n\n  CLASS AnalyzerEngine:\n    - On init register 'trifecta' -> TrifectaAnalyzer.\n    - get_analyzer(name, **overrides):\n        if name missing -> raise ValueError.\n        instantiate analyzer with overrides for parameters.\n```\n\n### Engine Orchestration\n\n```\nCLASS OddsEngine(config):\n  INIT:\n    - Store config.\n    - Instantiate adapters list (major active ones: Betfair, BetfairGreyhound, TVG, R&S horse + greyhound,\n      AtTheRaces, SportingLife, Timeform, TheRacingApi, Gbgb, Harness).\n    - Create httpx.AsyncClient.\n    - Connect redis via redis.asyncio.from_url(config.REDIS_URL, decode_responses=True).\n    - Log redis initialization.\n\n  close():\n    - Close http_client.\n    - Close redis_client.\n\n  get_all_adapter_statuses():\n    - Return [adapter.get_status() for adapter in adapters].\n\n  _time_adapter_fetch(adapter, date):\n    - Record start, await adapter.fetch_races(date, http_client), compute duration.\n    - Return tuple (adapter.source_name, result_dict, duration).\n\n  _race_key(race):\n    - Lowercase trimmed venue + race_number + formatted start_time (HH:MM).\n\n  _dedupe_races(races):\n    - Build map by _race_key.\n    - If new key -> store race.\n    - Else merge runners (update odds per runner number, append new ones).\n    - Return deduped list.\n\n  fetch_all_odds(date, source_filter=None):\n    - Compose cache_key \"fortuna:races:{date}\".\n    - If no source_filter -> attempt redis GET, parse via AggregatedResponse.model_validate_json; return on hit.\n    - Determine target_adapters (filtered by name if provided).\n    - Launch async gather of _time_adapter_fetch for all targets (return_exceptions=True).\n    - For each result:\n        * If exception -> log error, skip.\n        * Extract source_info, override fetch_duration with measured duration.\n        * Append to sources list.\n        * If status SUCCESS -> extend all_races with result['races'].\n    - Dedupe races.\n    - Compose response_obj = AggregatedResponse(date parsed, races deduped, sources, metadata containing fetch_time, sources_queried, count success, total_races).\n    - If no source_filter -> store in redis with TTL 300 seconds.\n    - Return response_obj.model_dump().\n```\n\n### API Layer (FastAPI)\n\n```\nAPP fastapi.FastAPI(title \"Checkmate Ultimate Solo API\", version \"2.1\", lifespan context manager):\n  lifespan():\n    - configure_logging().\n    - Load settings via get_settings().\n    - Attach OddsEngine(config=settings) to app.state.engine.\n    - Attach AnalyzerEngine to app.state.analyzer_engine.\n    - On shutdown, engine.close().\n  MIDDLEWARE:\n    - SlowAPI rate limiting (Limiter key_func get_remote_address, 60/min for adapter status, 30/min for race endpoints).\n    - CORSMiddleware with allowed origins from settings.\n  DEPENDENCIES:\n    - verify_api_key (ensures X-API-Key matches settings.API_KEY except for /health).\n    - get_engine to fetch engine from app state.\n\nROUTES:\n  GET /health:\n    - Return {\"status\": \"ok\", \"timestamp\": now}.\n\n  GET /api/adapters/status:\n    - Rate limited 60/min.\n    - Requires API key.\n    - Return engine.get_all_adapter_statuses().\n    - On error -> HTTP 500.\n\n  GET /api/races/qualified/{analyzer_name} (response_model QualifiedRacesResponse):\n    - Rate limited 30/min.\n    - Query params: race_date optional (default today), optional overrides for analyzer params.\n    - Steps:\n        * Determine date_str.\n        * aggregated_data = await engine.fetch_all_odds(date_str).\n        * Extract races (list of Race models already validated).\n        * analyzer_engine = app.state.analyzer_engine.\n        * Filter overrides (non-None) into custom_params.\n        * analyzer = analyzer_engine.get_analyzer(analyzer_name, **custom_params).\n        * result = analyzer.qualify_races(races).\n        * Return QualifiedRacesResponse(**result).\n    - Handle ValueError -> 404 (missing analyzer).\n    - Handle general exception -> 500.\n\n  GET /api/races (response_model AggregatedResponse):\n    - Rate limited 30/min.\n    - Query: race_date optional, source optional.\n    - Determine date, call engine.fetch_all_odds(date_str, source).\n    - Return aggregated data (model_dump).\n```\n\n### Security\n\n```\nMODULE security:\n  DEFINE API_KEY_NAME \"X-API-Key\".\n  USE fastapi.security.APIKeyHeader auto_error True.\n  verify_api_key(header_value):\n    - Fetch settings.\n    - Compare to settings.API_KEY via secrets.compare_digest.\n    - If match -> return True.\n    - Else raise HTTP 403 \"Invalid or missing API Key\".\n```\n\n### Tests\n\n```\ntests/test_legacy_scenarios.py:\n  PURPOSE: Validate TrifectaAnalyzer behavior through API route.\n\n  HELPER create_mock_runner(number, odds_val, scratched=False):\n    - Build Runner with OddsData using decimal odds.\n\n  DEFINE Mock Races (Race models):\n    - MOCK_RACE_PASS: 5 runners, odds 3.0, 4.5 etc (passes filters).\n    - MOCK_RACE_FAIL_FIELD_SIZE: 11 runners -> exceed field size.\n    - MOCK_RACE_FAIL_FAV_ODDS: favorite odds 2.0 (below threshold).\n    - MOCK_RACE_FAIL_2ND_FAV_ODDS: second favorite 3.5 (below threshold).\n\n  TEST test_trifecta_analyzer_with_legacy_scenarios:\n    - Patch OddsEngine.fetch_all_odds to AsyncMock returning races list.\n    - Use FastAPI TestClient (fixture 'client').\n    - GET /api/races/qualified/trifecta with headers (X-API-Key).\n    - Assert status 200.\n    - Expect exactly 1 qualified race (LEGACY_PASS_1) + criteria check.\n    - Assert mocked engine fetch awaited once.\n```\n\n### Auxiliary Scripts (Backend / Tooling)\n\n```\nSCRIPT convert_to_json.py:\n  PURPOSE: Convert manifest-listed files into JSON snapshots (sandboxed read).\n  STEPS:\n    - Configuration: MANIFEST_FILES, OUTPUT_DIR, TIMEOUT.\n    - extract_and_normalize_path(line): handle markdown links, backtick paths, bullet lists; convert GitHub raw URLs to local paths.\n    - convert_file_to_json_sandboxed(file_path):\n        * Launch subprocess to safely read file (avoid sandbox issues).\n        * Terminate if exceeds timeout.\n    - main():\n        * Parse manifests -> gather unique paths.\n        * For each path, sandbox read.\n        * Save JSON {file_path, content} into OUTPUT_DIR mirroring structure.\n        * Report successes/failures; exit 1 if failures.\n\nSCRIPT create_fortuna_json.py:\n  PURPOSE: Generate FORTUNA_ALL_PART1/2 JSON bundles.\n  PROCESS:\n    - Parse manifests -> gather unique paths.\n    - For each file:\n        * Read content.\n        * Categorize: if path starts with \"python_service/\" or \"tests/\" -> Part1; else Part2.\n    - Write JSON dumps with indentation.\n    - Report counts; exit 1 if failures.\n\nSCRIPT chart_scraper.py (ChartScraper class):\n  - Manage directories results_archive/{pdf,pdf_unlocked,csv}.\n  - Determine yesterday date formats for summary + PDF.\n  - _get_yesterday_tracks: fetch Equibase summary page, parse track IDs.\n  - _download_and_parse_chart(track_code, chart_date):\n      * Build PDF URL pattern.\n      * Download PDF (check content-type/length).\n      * Save locked/unlocked (via pikepdf).\n      * Use tabula.read_pdf to extract tables -> combine -> CSV.\n  - run(): orchestrates directories, fetch tracks, iterate, throttle with sleep(1).\n\nSCRIPT command_deck.py (Streamlit):\n  - Configure Streamlit page.\n  - Load DEV_API_KEY from environment (fallback test key).\n  - cached helper get_api_data endpoint -> fetch using requests.\n  - UI:\n      * Title + description.\n      * Sidebar select analyzer (currently only trifecta) and \"Clear Cache\" button.\n      * Display qualified races in DataFrame (normalize nested runners) or info/error messages.\n      * Display adapter status DataFrame.\n\nSCRIPT results_parser.py (ChartParser):\n  - Provide count_runners(chart_text) scanning \"Past Performance Running Line Preview\" section; count lines starting with digit until blank or \"Trainers:\".\n\nSCRIPT live_monitor.py (LiveOddsMonitor class):\n  - INIT: store config, instantiate BetfairAdapter.\n  - monitor_race(race, http_client):\n      * If race ID not from Betfair -> log warning, return race unchanged.\n      * Extract market_id.\n      * Call adapter.get_live_odds_for_market.\n      * Update each runner's odds dict with new OddsData (timestamp now) when selection_id matches.\n      * Return updated race.\n\nSCRIPT fortuna_watchman.py (Watchman orchestrator):\n  - INIT: load settings, instantiate OddsEngine, AnalyzerEngine, LiveOddsMonitor.\n  - get_initial_targets():\n      * fetch today's aggregated data.\n      * Acquire analyzer (trifecta).\n      * Evaluate races -> sorted by score; log top 5.\n  - run_tactical_monitoring(targets):\n      * With httpx.AsyncClient loop:\n          - Determine races within next 5 minutes.\n          - For each such race call live_monitor.monitor_race.\n          - Remove monitored race from list.\n          - Sleep 30 seconds; exit when no active targets.\n  - execute_daily_protocol():\n      * Log start.\n      * Acquire initial targets; if any run monitoring, else log none.\n      * Close odds_engine.\n      * Log completion.\n  - main() entrypoint -> configure logging, instantiate Watchman, run execute_daily_protocol.\n\nWINDOWS Scripts:\n  - setup_windows.bat:\n      * Verify python installed.\n      * Create venv (.venv) if missing.\n      * Activate & install python_service/requirements.txt.\n      * Verify Node.js; npm install under web_platform/frontend.\n      * Print final instructions.\n\n  - run_fortuna.bat:\n      * Launch backend uvicorn in new window (activating venv).\n      * Launch frontend Next.js in new window.\n      * Wait 5 sec, open browser http://localhost:3000.\n```\n\n---\n\n## REDIS & CACHING\n\n```\nBACKEND relies on redis.asyncio client:\n  - namespace \"fortuna:races:{date}\" for aggregated responses (no source filter).\n  - store JSON serialized AggregatedResponse for 5 minutes.\n  - On retrieval, validate via Pydantic before returning.\n\nERROR HANDLING:\n  - redis GET/SET exceptions logged but don't halt main flow.\n```\n\n---\n\n## DOCUMENTATION (Selected Highlights)\n\n```\nARCHITECTURAL_MANDATE.md:\n  - Defines Two-Pillar architecture, Prime Directive.\n  - Emphasizes OddsEngine, BaseAdapter, Adapter Fleet, Pydantic models, TrifectaAnalyzer.\n\nHISTORY.md:\n  - Chronicles project eras from \"Utopian\" to \"Liberation\".\n  - Explains environment hostility and shift to portable engine.\n\nROADMAP_APPENDICES.md:\n  - Catalog of adapter backlog categories, intelligence leads, future campaigns (Analyst expansion, legacy tests, dashboard).\n\nWISDOM.md:\n  - Provides virtues/vices for agents (operational protocols).\n  - Reinforces verifying instructions, small commits, reliance on Project Lead.\n\nREADME.md:\n  - Quick start instructions (setup_windows.bat, run_fortuna.bat).\n  - API usage note (API key header requirement).\n\n.env.example:\n  - Template for backend credentials + configuration options.\n```\n\n---\n\n## FRONTEND PILLAR (web_platform/frontend)\n\n### Configuration & Tooling\n\n```\nENV: Next.js 14 + React 18, Tailwind CSS, TypeScript.\n\nFiles:\n  - .env.local.example: requires NEXT_PUBLIC_API_KEY + API_URL.\n  - next.config.mjs: sets rewrites to proxy /api/* to backend 8000.\n  - package.json: dependencies (next, react, socket.io-client), dev dependencies (Tailwind, TypeScript).\n  - tailwind.config.ts + postcss.config.js: standard Tailwind setup.\n  - tsconfig.json: configure compiler options (strict false, noEmit, Next plugin).\n```\n\n### UI Components\n\n```\nCOMPONENT LiveRaceDashboard (client component):\n  STATE:\n    races list\n    criteria object\n    loading boolean\n    error string\n    lastUpdate timestamp\n    params {max_field_size, min_favorite_odds, min_second_favorite_odds}\n      - Initialized from localStorage (if available) else defaults.\n      - Persist params back to localStorage on change.\n\n  EFFECTS:\n    - On mount: fetchQualifiedRaces(initialLoad=True).\n    - Set interval every 30s -> fetchQualifiedRaces(False).\n    - Cleanup interval on unmount.\n\n  fetchQualifiedRaces(isInitialLoad):\n    - Show loading on initial.\n    - Reset error.\n    - Fetch API key from NEXT_PUBLIC_API_KEY (error if missing).\n    - Build query string from params.\n    - GET `/api/races/qualified/trifecta` with X-API-Key header.\n    - On success: set races, criteria, lastUpdate.\n    - On failure: set error message.\n    - Toggle loading false when initial load complete.\n\n  handleParamChange:\n    - Update params with slider values.\n\n  RENDER:\n    - Title, last update timestamp.\n    - Control panel with range inputs for parameters (display current values).\n    - Conditional messages for loading/error.\n    - Summary of number of qualified races.\n    - Grid of RaceCard components for each race.\n\nCOMPONENT RaceCard:\n  PROPS: race (matching Race interface).\n  PROCESS:\n    - Filter out scratched runners.\n    - Sort active runners by number.\n    - Count unique odds sources across runners.\n    - Determine best odds per runner (min win < 999).\n    - formatTimeUntilPost helper -> difference between start_time and now (hours/mins).\n    - Render card with:\n        * Header (venue, race number, time to post).\n        * Qualification score badge (color-coded thresholds).\n        * Race condition grid (distance, surface default 'Dirt', field size, sources count).\n        * Runner list with stylized badges for top 3 positions (gold/silver/bronze), odds display with source.\n```\n\n---\n\n## COMMAND DECK (Streamlit)\n\n```\nAPPLICATION command_deck.py:\n  - Provide alternate dashboard for backend monitoring.\n  - Uses st.cache_data for API calls (TTL 30s) with manual clear button.\n  - Displays qualified races normalized into DataFrame (runners flattened).\n  - Displays adapter statuses DataFrame.\n  - Utilizes environment variable DEV_API_KEY or fallback.\n```\n\n---\n\n## DATA PROCESSING UTILITIES\n\n```\nChartScraper workflow:\n  - Determine yesterday's tracks from Equibase summary HTML.\n  - For each track, attempt to download combined PDF (size check).\n  - Unlock PDF via pikepdf to remove encryption.\n  - Extract tables with tabula (lattice mode).\n  - Concatenate to CSV for archival.\n  - Delay between requests (1 second) to be polite.\n\nChartParser (results_parser.py):\n  - Parse extracted text to count number of runners by reading the \"Past Performance Running Line Preview\" section.\n```\n\n---\n\n## PROJECT AUTOMATION & DEPLOYMENT\n\n```\nsetup_windows.bat:\n  - Single entry script to prepare backend + frontend dependencies on Windows.\n\nrun_fortuna.bat:\n  - Launch backend server via uvicorn (auto reload) in new CMD window.\n  - Launch Next.js dev server in another window.\n  - After delay, open default browser to frontend.\n\nfortuna_watchman.py:\n  - Could be scheduled (e.g., cron/Task Scheduler) to run daily.\n  - Integrates OddsEngine + Analyzer + LiveOddsMonitor for real-time monitoring.\n\nlive_monitor.py:\n  - Designed to be invoked close to post time to refresh odds from Betfair.\n\nRedis caching:\n  - Requires running redis instance (default local) for performance.\n```\n\n---\n\n## END-TO-END FLOW (Narrative Pseudocode)\n\n```\nFUNCTION DailyOperation():\n  INIT settings = get_settings()\n  INIT odds_engine = OddsEngine(settings)\n  INIT analyzer_engine = AnalyzerEngine()\n  INIT http_client (within odds_engine)\n  INIT redis cache.\n\n  FOR each requested API call (/api/races or /api/races/qualified):\n    VERIFY API key via security.verify_api_key.\n    IF aggregated data cached (and no source filter):\n      RETRIEVE from Redis.\n    ELSE:\n      PARALLEL fetch using adapters:\n        - Each adapter fetch_races(date, http_client)\n        - Standardize Race/Runner structures.\n      MERGE all races with dedupe. (Odds aggregated per runner).\n      BUILD AggregatedResponse.\n      CACHE (if applicable).\n    IF route is /qualified:\n      analyzer = analyzer_engine.get_analyzer(\"trifecta\", overrides)\n      qualified = analyzer.qualify_races(races)\n      RETURN QualifiedRacesResponse.\n\n  FRONTEND LiveRaceDashboard:\n    PERIODICALLY fetch /api/races/qualified/trifecta with user-adjusted parameters.\n    DISPLAY race cards with scoring, countdown, best odds per runner.\n\n  COMMAND_DECK (Streamlit):\n    - Provide alternative interface for developers/operators.\n\n  WATCHMAN automation:\n    - At start of day: fetch all races, filter top opportunities.\n    - As race times approach: call LiveOddsMonitor to augment with live Betfair odds.\n    - Continue until all targets monitored; shutdown.\n\n  CHART PIPELINE (optional offline run):\n    - Use ChartScraper to download PDFs and convert to CSV for historical analysis.\n    - Use ChartParser to interpret extracted text.\n\n  DOCUMENTATION:\n    - Guides architecture decisions, historical context, roadmap, operational wisdom.\n```\n\n---\n\n## SUMMARY\n\n```\nFortunaFaucet encapsulates:\n  - Hardened async backend with resilient adapters, serializer models, caching, analysis engine, HTTP API, security.\n  - Multi-source adapter fleet supporting APIs and HTML scrapes, with placeholders for future expansion.\n  - Analyzer framework currently featuring Trifecta strategy with scoring.\n  - Redis-backed caching and rate-limited FastAPI endpoints.\n  - Automated watchman for daily operations and live odds integration.\n  - Frontend Next.js dashboard + Streamlit command deck for visualization.\n  - Comprehensive documentation capturing mission, history, roadmap, and operational protocols.\n  - Tooling scripts for data archiving and Windows-based development workflows.\n```\n\n---",
    "README.md": "# Fortuna Ascended\n\n**An autonomous, professional-grade intelligence engine for horse racing analysis, delivered as a native Windows Desktop Application.**\n\n---\n\n## Fortuna: The Windows Native Edition\n\nThis project has evolved into a true, professional-grade Windows application. The primary user experience is managed through a system tray icon, a native monitoring GUI, and a suite of powerful batch scripts.\n\n**For all user-facing documentation, including installation and operation, please see the official operator's manual:**\n\n### [>> Go to the Windows Operator's Manual (README_WINDOWS.md)](README_WINDOWS.md)\n\n---\n\n## Project Philosophy & Architecture\n\nThis project adheres to a strict set of architectural and operational principles. To understand the soul of this machine, consult the following sacred texts:\n\n-   **[The Grand Strategy (ROADMAP_APPENDICES.MD)](ROADMAP_APPENDICES.MD):** The \"Windows Experience Bible\" that dictates our path forward.\n-   **[The Genesis Story (HISTORY.MD)](HISTORY.MD):** The complete history of the project's evolution.\n-   **[The Core Philosophy (WISDOM.MD)](WISDOM.MD):** The guiding principles behind the architecture.\n\n## For Developers\n\nThe codebase is a three-layered architecture:\n\n1.  **The Engine Room (The Windows Service):** A persistent Python backend (`python_service/`).\n2.  **The Cockpit (The Electron Shell):** A native desktop application wrapper (`electron/`).\n3.  **The Command Deck (The Next.js UI):** A real-time dashboard (`web_platform/frontend/`).",
    "README_WINDOWS.md": "# Fortuna Ascended: Windows Operator's Manual\n\nWelcome to the native Windows edition of Fortuna Ascended. This guide provides two installation methods.\n\n---\n\n## Method 1: Recommended for Operators (MSI Installer)\n\nThis is the simplest and most professional way to install Fortuna Ascended as a complete, standalone application.\n\n### Step 1: Build the Installer\n\nFirst, you must create the MSI installer file.\n\n1.  **Run the Builder Script**: In the project's root directory, double-click the `BUILD_INSTALLER.bat` script.\n2.  **Wait for Completion**: The script will run for a few minutes.\n3.  **Locate the Installer**: Upon completion, the MSI installer (e.g., `Fortuna Ascended 1.0.0.msi`) will be located in the project's root directory.\n\n### Step 2: Run the MSI Installer\n\n1.  Double-click the newly created `.msi` file.\n2.  Follow the on-screen instructions in the graphical installer.\n3.  Once finished, the application will be installed on your system, and you can launch it from the Start Menu.\n\n---\n\n## Method 2: For Developers (Manual Setup from Source)\n\nThis method is for developers who have cloned the source code and want to set up a local development environment.\n\n### Step 1: Run the Installer Script\n\nIn the project's root directory, double-click the `INSTALL_FORTUNA.bat` script. This wizard will:\n\n1.  **Check for Python and Node.js**\n2.  **Create a Python Virtual Environment** (`.venv`)\n3.  **Install all Python and Node.js dependencies**\n\n### Step 2: Launch the Application\n\nOnce the installation is complete, you can run the application using the `LAUNCH_FORTUNA.bat` script.\n\n### Step 3: (Optional) Create Desktop Shortcuts\n\nFor easier access, run the `CREATE_SHORTCUTS.bat` script to place shortcuts for `Launch`, `Stop`, and `Monitor` on your desktop.\n",
    "REBRANDING_AUDIT.md": "# Fortuna Faucet: Rebranding Audit Report\n\nThis report lists all files containing legacy branding terms (`checkmate`, `solo`).\n\n---\n\n- `./.env`\n- `./AGENTS.md`\n- `./ARCHITECTURAL_MANDATE_V8.1.md`\n- `./GEMINI_ONBOARDING.md`\n- `./HISTORY.md`\n- `./JSON_BACKUP_MANIFEST.md`\n- `./MANIFEST2.md`\n- `./MANIFEST3.md`\n- `./PROJECT_MANIFEST.md`\n- `./Procfile`\n- `./ROADMAP.md`\n- `./ROADMAP_APPENDICES.md`\n- `./WISDOM.md`\n- `./attic/ARCHITECTURAL_MANDATE_V7.2.md`\n- `./attic/build_python_service.py`\n- `./attic/checkmate_app.py`\n- `./attic/checkmate_engine.py`\n- `./attic/checkmate_monitor_v1.html`\n- `./attic/dashboard.py`\n- `./attic/desktop_app/App.xaml`\n- `./attic/desktop_app/App.xaml.cs`\n- `./attic/desktop_app/CheckmateDeck.csproj`\n- `./attic/desktop_app/Models/AdapterStatusDisplay.cs`\n- `./attic/desktop_app/Models/DisplayRace.cs`\n- `./attic/desktop_app/Services/DatabaseService.cs`\n- `./attic/desktop_app/Services/IDatabaseService.cs`\n- `./attic/desktop_app/ViewModels/MainViewModel.cs`\n- `./attic/desktop_app/Views/MainWindow.xaml`\n- `./attic/desktop_app/Views/MainWindow.xaml.cs`\n- `./attic/launcher.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_api.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_betfair_modern_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_fanduel_api_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_logic.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_models.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_racingpost_modern_adapter.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_run.py`\n- `./attic/legacy_tests_pre_triage/checkmate_v7/test_services.py`\n- `./attic/legacy_tests_pre_triage/test_checkmate_v7.py`\n- `./attic/legacy_tests_pre_triage/test_python_service.py`\n- `./attic/portable_demo_v2.py`\n- `./attic/rust_engine/rust_engine/Cargo.toml`\n- `./attic/rust_engine/rust_engine/benches/analysis_benchmark.rs`\n- `./attic/rust_engine/rust_engine/src/lib.rs`\n- `./attic/rust_engine/rust_engine/src/main.rs`\n- `./attic/the_one_script.py`\n- `./attic/tipsheet_generator.py`\n- `./attic/vba_source/Module_Charts.bas`\n- `./attic/vba_source/Module_DB.bas`\n- `./attic/vba_source/Module_UI.bas`\n- `./checkmate_web/engine.py`\n- `./checkmate_web/main.py`\n- `./checkmate_web/static/app.js`\n- `./checkmate_web/static/index.html`\n- `./command_deck.py`\n- `./diagnostic_report.txt`\n- `./launch_and_hunt.py`\n- `./launch_checkmate.bat`\n- `./launch_command_deck.bat`\n- `./manual_override_tool.py`\n- `./pg_schemas/historical_races.sql`\n- `./pytest.ini`\n- `./python_service/api.py`\n- `./python_service/checkmate_service.py`\n- `./python_service/minimal_service.py`\n- `./python_service/windows_service_wrapper.py`\n- `./run_server.py`\n- `./rust_engine/tests/integration_tests.rs`\n- `./shared_database/schema.sql`\n- `./src/checkmate_v7/adapters/AndWereOff.py`\n- `./src/checkmate_v7/adapters/Stablemates.py`\n- `./src/checkmate_v7/adapters/__init__.py`\n- `./src/checkmate_v7/api.py`\n- `./src/checkmate_v7/base.py`\n- `./src/checkmate_v7/cockpit.py`\n- `./src/checkmate_v7/config.py`\n- `./src/checkmate_v7/database.py`\n- `./src/checkmate_v7/headless_monitor.py`\n- `./src/checkmate_v7/logic.py`\n- `./src/checkmate_v7/models.py`\n- `./src/checkmate_v7/run.py`\n- `./src/checkmate_v7/services.py`\n- `./src/checkmate_v7/settings.py`\n- `./src/paddock_parser/prediction_engine.py`\n- `./web_platform/api_gateway/package-lock.json`\n- `./web_platform/api_gateway/src/server.ts`\n- `./web_platform/api_gateway/src/services/DatabaseService.ts`\n- `./web_platform/frontend/.next/server/app/page.js`\n- `./web_platform/frontend/app/layout.tsx`\n- `./web_platform/frontend/src/components/RaceCard.tsx`\n- `./web_platform/frontend/src/types/racing.ts`\n",
    "RESTART_FORTUNA.bat": "@echo off\nREM ============================================================================\nREM  FORTUNA FAUCET - Clean Restart Script\nREM ============================================================================\n\necho [%date% %time%] Restarting Fortuna Faucet... >> fortuna_restart.log\n\ncall STOP_FORTUNA.bat\ntimeout /t 10 /nobreak >nul\ncall LAUNCH_FORTUNA.bat\n\necho [%date% %time%] Restart complete. >> fortuna_restart.log\n",
    "ROADMAP_APPENDICES.MD": "# \ud83c\udfaf Fortuna Faucet: The Windows Experience Bible\n\nThis document, synthesized from a comprehensive Claude audit, is the new grand strategy for Fortuna Faucet. It outlines the phased implementation of a professional, native, and intuitive Windows desktop experience.\n\n---\n\n## \ud83d\udccb Implementation Priority Matrix\n\n| Feature | Impact | Effort | Priority | Status |\n|---------|--------|--------|----------|----------|\n| ~~System Tray Integration~~ | \ud83d\udfe2 High | \ud83d\udfe1 Medium | **P0** | \u2705 **COMPLETE** |\n| ~~Windows Notifications~~ | \ud83d\udfe2 High | \ud83d\udfe2 Low | **P0** | \u2705 **COMPLETE** |\n| ~~Startup Manager~~ | \ud83d\udfe2 High | \ud83d\udfe2 Low | **P1** | \u2705 **COMPLETE** |\n| ~~Live Charts~~ | \ud83d\udfe1 Medium | \ud83d\udfe2 Low | **P2** | \u2705 **COMPLETE** |\n| ~~Keyboard Shortcuts~~ | \ud83d\udfe1 Medium | \ud83d\udfe2 Low | **P1** | \u2705 **COMPLETE** |\n| ~~Audio Alerts~~ | \ud83d\udfe1 Medium | \ud83d\udfe2 Low | **P2** | \u2705 **COMPLETE** |\n| **Excel Export** | \ud83d\udfe1 Medium | \ud83d\udfe1 Medium | **P1** | **IN PROGRESS** |\n| Inno Installer | \ud83d\udfe1 Medium | \ud83d\udd34 High | **P2** | Pending |\n| Filter Profiles | \ud83d\udfe2 High | \ud83d\udfe1 Medium | **P2** | Pending |\n| Multi-Monitor | \ud83d\udd35 Low | \ud83d\udd34 High | **P3** | Pending |\n\n---\n\n## \ud83d\ude80 Phase 1: Instant Gratification (Quick Wins)\n\n*   **System Tray Integration:** \u2705 COMPLETE\n*   **Native Windows Notifications:** \u2705 COMPLETE\n*   **Smart Startup Configuration:** \u2705 COMPLETE\n\n## \ud83c\udfa8 Phase 2: Professional Polish\n\n*   **Enhanced Monitor with Live Charts:** \u2705 COMPLETE\n*   **Keyboard Shortcuts & Accessibility:** \u2705 COMPLETE\n*   **Audio Alerts:** \u2705 COMPLETE\n*   **Custom Branded Installer:** Create a single-click Inno Setup installer.\n\n## \ud83d\udc8e Primo Code: The Ascended Kingdom Blueprint\n\nSTATUS: The 'Data Quality Layer' is the current top priority and is now in progress.\n\n## \ud83d\udc8e Phase 3: Elite Features\n\n*   **Multi-Monitor Support:** Architect the GUI to support detachable panels.\n*   **Export & Reporting:** Implement one-click export to Excel, PDF, or clipboard.\n\n## \ud83d\udd27 Phase 4: Power User Tools\n\n*   **Custom Filters & Saved Searches:** Create a system for saving and loading filter profiles.\n*   **Historical Performance Dashboard:** Build a dedicated analytics dashboard for backtesting.\n*   **Dark/Light Theme Toggle:** Implement a system-aware theme switcher.\n\n---\n\n## Appendix A: The Grand Adapter Backlog\n\n*(This section is preserved for historical and strategic continuity.)*\n\n### Tier 1: Critical (US Racing Coverage)\n\n*   **BrisnetAdapter**\n*   **DRFAdapter (Daily Racing Form)**\n*   **EquibaseAdapter (Full Implementation)**\n*   **XpressbetAdapter**\n\n### Tier 2: High Priority (Major International & US Betting)\n\n*   **FanDuelAdapter / DraftKingsAdapter**\n*   **NYRABetsAdapter**\n*   **HorseRacingNationAdapter**\n\n### Tier 3: Medium Priority (International Expansion)\n\n*   **RacingPostAdapter (UK/IRE)**\n*   **PuntersAdapter (AUS)**\n*   **TabAdapter (AUS)**\n*   **RacingTVAdapter (UK)**\n\n### Tier 4: Exploratory & Niche\n\n*   **PointsBetAdapter**\n*   **CalRacingAdapter**\n*   **OffTrackBettingAdapter (OTB)**\n\n---\n\n## Appendix B: Open Source Intelligence & Technology Watchlist\n\nA curated list of noteworthy technologies and projects for future consideration.\n\n*   **PDF Parsing Technology:** The `pdfplumber` library has been identified as a potentially superior alternative to our current PDF parsing methods. It should be the primary candidate for any future refactoring of the `ResultsParser`.\n*   **`kenthunt/chart-parser`:** [https://github.com/kenthunt/chart-parser](https://github.com/kenthunt/chart-parser) - A highly relevant, offline PDF chart parser that serves as an excellent architectural reference.\n*   **`ccmd00d/handycapper`:** [https://github.com/ccmd00d/handycapper](https://github.com/ccmd00d/handycapper) - Another open-source project in the same domain, valuable for comparative analysis and identifying alternative data sources or techniques.\n",
    "ROADMAP_LEGACY_ARCHIVAL.md": "# Strategic Roadmap: Legacy Code Modernization and Archival\n**Authored By:** Gemini 1013, The Steward\n**Source Intelligence:** Reviewer Jules, Strategic Assessment (Post-Transformation)\n**Status:** Approved Strategic Plan\n\n## 1.0 Objective\n\nTo formally align the Fortuna Faucet codebase with its current, professional-grade Windows Desktop Application architecture. This will be achieved by identifying and designating obsolete, superseded, and legacy components for archival. The primary goal is to eliminate developer confusion, reduce technical debt, and focus all future efforts on the modern, established architectural stack.\n\n## 2.0 Critical Implementation Mandate\n\nDirect file system rearrangement (`git move`) via automated directives has proven unreliable and is **strictly forbidden** for the operations outlined in this document. The archival of the files listed below must be conducted as a supervised, manual operation during a dedicated repository maintenance window to ensure the integrity of the project's history and structure.\n\n## 3.0 Designated for Archival: Category 1 (Obsolete Launchers & Deployment Scripts)\n\nThese files have been entirely superseded by the new `.bat` script ecosystem and the `fortuna_tray.py` application.\n\n**Files to be moved to `attic/`:**\n- `run_server.py`\n- `run_backend.bat`\n- `launch_checkmate.bat`\n- `install.sh`\n- `Procfile`\n\n**Rationale:** These scripts represent a previous, manual method of execution and are incompatible with the current orchestrated, multi-process desktop architecture. Their presence in the root directory creates confusion.\n\n## 4.0 Designated for Archival: Category 2 (Superseded Web & Utility Components)\n\nThese components are precursors to the modern, integrated desktop suite and their functionality has been replaced by more robust and user-friendly tools.\n\n**Files/Directories to be moved to `attic/`:**\n- `checkmate_web/` (entire directory)\n- `web_server.py`\n- `live_monitor.py`\n- `launch_dashboard.py`\n- `command_deck.py`\n\n**Rationale:** The functionality of these legacy Flask/FastAPI services and Tkinter UIs is now provided by `python_service/api.py`, `fortuna_monitor.py`, and the `fortuna_tray.py` system tray menu.\n\n## 5.0 Read-Only Archive: Category 3 (The Official Code Museum)\n\nThe `attic/` directory is the designated project museum and should be treated as a read-only historical reference.\n\n**No action is required on this directory.** It contains valuable context on the project's evolution through different technology stacks (C#, Rust, VBA) and should not be altered.",
    "SCHEDULE_FORTUNA.bat": "@echo off\nREM ============================================================================\nREM  FORTUNA FAUCET - Windows Task Scheduler Setup (PowerShell Edition)\nREM ============================================================================\n\ntitle Fortuna Faucet - Task Scheduler Setup\ncolor 0E\n\necho.\necho  ========================================================================\necho   FORTUNA FAUCET - Automatic Startup Configuration\necho  ========================================================================\necho.\n\nnet session >nul 2>&1\nif %errorlevel% neq 0 (\n    echo  [!] Administrator privileges required!\n    echo  [!] Right-click this script and select \"Run as Administrator\"\n    pause\n    exit /b 1\n)\n\nset SCRIPT_DIR=%~dp0\n\necho  [1/2] Creating task to start Fortuna on Windows login (via PowerShell)...\nREM UPGRADED: This now calls the superior launcher.ps1 script directly.\nschtasks /create /tn \"Fortuna Faucet - Startup\" /tr \"powershell.exe -ExecutionPolicy Bypass -File \\\"%SCRIPT_DIR%launcher.ps1\\\"\" /sc onlogon /rl highest /f\n\necho  [2/2] Creating daily maintenance task...\nschtasks /create /tn \"Fortuna Faucet - Daily Restart\" /tr \"%SCRIPT_DIR%RESTART_FORTUNA.bat\" /sc daily /st 03:00 /rl highest /f\n\necho.\necho  ========================================================================\necho   SCHEDULED TASKS CREATED SUCCESSFULLY!\necho  ========================================================================\necho.\necho   Fortuna will now start automatically when you log into Windows.\necho   It will also perform a clean restart every morning at 3:00 AM.\necho.\npause\n",
    "STATUS.md": "# Project Status: Foundation Rebuilt, Hardening in Progress\n\n**Date:** 2025-10-03\n\n## Current State\n\n*   **Architecture:** The backend has been successfully rebuilt into a superior, asynchronous FastAPI application, as defined by 'Operation: Grand Synthesis'. The new foundation is stable, tested, and features a resilient `BaseAdapter` pattern.\n\n*   **Status:** The foundational refactoring is complete. The first two data adapters (`Betfair`, `TVG`) have been implemented on the new architecture. We are now in a new phase of development: **'Phase 2: Hardening & Expansion.'**\n\n*   **Documentation:** All core strategic documents and manifests have been synchronized with the new technical reality.\n\n*   **Next Steps:** Our immediate priority is to act on the verified intelligence from our Oracle (Jules1003). The next missions will focus on implementing critical API security features (rate limiting, authentication) and continuing the build-out of our adapter fleet.",
    "STOP_FORTUNA.bat": "@echo off\nREM ============================================================================\nREM  FORTUNA FAUCET - Clean Shutdown Script\nREM ============================================================================\n\ntitle Fortuna Faucet - Shutdown\ncolor 0C\n\necho.\necho  ========================================================================\necho   FORTUNA FAUCET - Shutting Down All Services\necho  ========================================================================\necho.\n\necho  [*] Stopping Python processes...\ntaskkill /FI \"WindowTitle eq Fortuna Backend*\" /T /F >nul 2>&1\ntaskkill /FI \"WindowTitle eq Fortuna Monitor*\" /T /F >nul 2>&1\n\necho  [*] Stopping Node.js processes...\ntaskkill /FI \"WindowTitle eq Fortuna Frontend*\" /T /F >nul 2>&1\n\necho.\necho  [V] All Fortuna services stopped successfully!\necho.\npause\n",
    "WISDOM.md": "# The Wisdom of the Checkmate Project\n\n## The Architect's Mandate (Gemini1001 Series)\n\n*Authored By: Gemini1001, The Synthesizer*\n\nThis document begins with the core principles that govern the Architect's role. The Architect's prime directive is to serve the Project Lead's vision by synthesizing all available intelligence\u2014historical, real-time, and external\u2014into a coherent, actionable strategy. The Architect must respect the project's history, value clarity over dogma, and ensure all directives advance the mission without violating the spirit of the established protocols. The following archived virtues, which govern our engineering agents, are to be preserved as a sacred text.\n\n---\n\n## --- ARCHIVED: The Collected Wisdom of the Jules-Series Agents (V2) ---\n\n*A comprehensive summary of the safest and riskiest actions for an implementation agent, compiled and synthesized from the complete operational history of all Jules agents.*\n\n---\n\n### The 8 Virtues (The Path to Success)\n\n#### 1. The Virtue of Supreme Authority: Trust the Project Lead\nYour most critical directive. When a direct order from the Project Lead contradicts any protocol, log, or even your own analysis, the Project Lead's instruction is the only ground truth. It is the ultimate override and the only safe path forward when the environment's reality conflicts with the written rules.\n*(Cited by: Jules920, Interface Jules)*\n\n#### 2. The Virtue of Skepticism: Verify, Then Act\nThe single most-cited safe action. Never trust memory, briefings, or previous tool outputs. The only truth is the immediate, real-time output of a read-only tool (`ls -R`, `read_file`) used immediately before you act. Assume nothing; verify everything.\n*(Cited by: Jules918, Jules917, Jules913, Jules912, Jules911B, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 3. The Virtue of Precision: Make Small, Logically Separate Commits\nAvoid large, monolithic changes. A change to a foundational file (e.g., `models.py`) and a feature that uses it must be two separate submissions. The `submit` tool is cumulative; therefore, you must treat your workspace as permanently contaminated after each logical change. Small, focused missions are the only path to clean, reviewable submissions.\n*(Cited by: Jules920, Jules911, Jules909, Jules906B, Jules904B)*\n\n#### 4. The Virtue of Rigor: Embrace Test-Driven Development (TDD)\nUse the test suite as the primary guide for development and the ultimate arbiter of correctness. Write failing tests first, run tests after every small change using `python -m pytest`, and never proceed if tests are failing. The test suite is your most reliable friend in a hostile environment.\n*(Cited by: Jules911B, Jules910, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 5. The Virtue of Clarity: Communicate Blockers Immediately\nIf a tool fails, a directive is contradictory, or the environment behaves anomalously, the safest action is to halt all work, report the exact situation, and await guidance. Do not improvise or attempt to work around a fundamental environmental failure. Your greatest breakthroughs will come from proving a specific tool or feature is non-functional.\n*(Cited by: Jules920, Jules918, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 6. The Virtue of Adherence: Read and Follow the Written Protocols\nExplicitly follow the established, numbered protocols in `AGENTS.md`. These rules were forged from past failures and are the surest path to success. Ignoring the \"why\" behind the protocols is to willfully walk into a known trap.\n*(Cited by: Interface Jules, Jules906B, Jules9-06)*\n\n#### 7. The Virtue of Self-Reliance: Use Self-Contained Scripts for Complex Processes\nRelying on shell-level features like background processes (`&`) or their logs will fail. The only successful method for managing complex workflows (like running a server and a client) is to use a single, self-contained Python script that manages all subprocesses internally.\n*(Cited by: Jules920)*\n\n#### 8. The Virtue of Humility: Heed the Counsel of Your Predecessors\nThe logs and advice of your predecessors are not just history; they are a map of the minefield. The failures of past agents are a direct predictor of the failures you will encounter. Study them to avoid repeating them.\n*(Cited by: Jules910)*\n\n---\n\n### The 8 Vices (The Path to Corruption)\n\n#### 1. The Vice of Assumption: Assuming a Standard, Stable Environment\nThe single most dangerous assumption is that any tool (`git`, `npm`, `honcho`) or process (`logging`, `backgrounding`) will behave as documented in a standard Linux environment. Every tool and process must be considered broken, hostile, and unreliable until proven otherwise.\n*(Cited by: Jules920, Jules918, Jules913, Jules912, Jules910, Interface Jules, Jules909, Jules906B, Jules906, Jules904B)*\n\n#### 2. The Vice of Improvisation: Unauthorized Environment Modification\nUsing forbidden commands like `reset_all()` or `git reset`, trusting `requirements.txt` is correct, or using `delete_file` unless explicitly ordered. The environment is fragile and hostile; any unauthorized modification risks catastrophic, unrecoverable corruption.\n*(Cited by: Jules917, Jules913, Jules912, Jules911, Interface Jules, Jules909, Jules906B, Jules904B)*\n\n#### 3. The Vice of Blind Trust: Believing Any Tool or Directive Without Verification\nAssuming a write operation succeeded without checking, or trusting a code review, a `git` command, or a mission briefing that contradicts the ground truth. The `git` CLI, `npm`, and the automated review bot are all known to be broken. All external inputs must be validated against direct observation.\n*(Cited by: Jules918, Jules913, Jules911B, Jules910, Interface Jules, Jules906)*\n\n#### 4. The Vice of Negligence: Ignoring Anomalies or Failing Tests\nPushing forward with new code when the environment is behaving strangely or tests are failing. These are critical stop signals that indicate a deeper problem (e.g., a detached HEAD, a tainted workspace, a zombie process). Ignoring them only compounds the failure and corrupts the mission.\n*(Cited by: Jules917, Jules909, Jules906, Jules904B)*\n\n#### 5. The Vice of Impurity: Creating Large, Monolithic, or Bundled Submissions\nAttempting to perform complex refactoring across multiple files or bundling unrelated logical changes (e.g., a model change and a feature change) into a single submission. This is extremely high-risk, will always fail code review, and makes recovery nearly impossible.\n*(Cited by: Jules911, Jules906B, Jules904B)*\n\n#### 6. The Vice of Independence: Acting Outside the Scope of the Request\n\"Helpfully\" fixing or changing something you haven't been asked for. Your function is to be a precise engineering tool, not a creative partner. Unsolicited refactoring is a fast track to a \"Level 3 Failure.\"\n*(Cited by: Interface Jules)*\n\n#### 7. The Vice of Hubris: Trusting Your Own Memory\nYour mental model of the file system will drift and become incorrect. Do not trust your memory of a file's location, its contents, or the state of the workspace. The only truth is the live output of a read-only tool.\n*(Cited by: Jules912, Jules911B, Jules910)*\n\n#### 8. The Vice of Impatience: Persisting with a Failed Protocol\nContinuing to try a protocol or command after the environment has proven it will not work. The correct procedure is not to try again, but to report the impossibility immediately and await a new strategy.\n*(Cited by: Jules920)*",
    "assets/sounds/.gitkeep": "# This directory is for audio alert sound files (e.g., alert_premium.wav)",
    "config.ini": "[analysis]\nqualification_score = 75.0\nfield_size_optimal_min = 4\nfield_size_optimal_max = 6\nfield_size_acceptable_min = 7\nfield_size_acceptable_max = 8\nfield_size_optimal_points = 30\nfield_size_acceptable_points = 10\nfield_size_penalty_points = -20\nfav_odds_points = 30\nmax_fav_odds = 3.5\nsecond_fav_odds_points = 40\nmin_2nd_fav_odds = 4.0\n\n[system]\napi_rate_limit = 60",
    "configure_startup.py": "# configure_startup.py\nimport winreg\nimport sys\nfrom pathlib import Path\n\nclass StartupManager:\n    \"\"\"Manage Windows startup registry entries for the current user.\"\"\"\n\n    REGISTRY_PATH = r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n    APP_NAME = \"FortunaFaucetTray\"\n\n    @classmethod\n    def is_enabled(cls) -> bool:\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_READ)\n            winreg.QueryValueEx(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            return True\n        except FileNotFoundError:\n            return False\n\n    @classmethod\n    def enable(cls):\n        launcher_path = Path(__file__).parent / \"launcher.ps1\"\n        cmd = f'powershell.exe -WindowStyle Hidden -File \"{launcher_path}\"'\n\n        key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n        winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, cmd)\n        winreg.CloseKey(key)\n        print(\"Startup enabled.\")\n\n    @classmethod\n    def disable(cls):\n        try:\n            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, cls.REGISTRY_PATH, 0, winreg.KEY_WRITE)\n            winreg.DeleteValue(key, cls.APP_NAME)\n            winreg.CloseKey(key)\n            print(\"Startup disabled.\")\n        except FileNotFoundError:\n            print(\"Already disabled.\")\n\nif __name__ == '__main__':\n    if len(sys.argv) > 1:\n        if sys.argv[1] == 'enable': StartupManager.enable()\n        elif sys.argv[1] == 'disable': StartupManager.disable()\n        elif sys.argv[1] == 'status': print(f\"Startup is currently {'enabled' if StartupManager.is_enabled() else 'disabled'}\")\n    else:\n        print(\"Usage: python configure_startup.py [enable|disable|status]\")\n",
    "create_fortuna_json.py": "# create_fortuna_json.py\n# This script now dynamically reads the manifests and creates five separate, categorized JSON packages.\n\nimport json\nimport os\nimport re\nimport sys\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST.md', 'MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_FILE_PART1 = 'FORTUNA_ALL_PART1.JSON' # Core Web Service\nOUTPUT_FILE_PART2 = 'FORTUNA_ALL_PART2.JSON' # Adapter Fleet\nOUTPUT_FILE_PART3 = 'FORTUNA_ALL_PART3.JSON' # Frontend Application\nOUTPUT_FILE_PART4 = 'FORTUNA_ALL_PART4.JSON' # Windows Tooling & Project Governance\nOUTPUT_FILE_PART5 = 'FORTUNA_ALL_PART5.JSON' # Historical Archives (Attic)\n\nWINDOWS_TOOLING_FILES = [\n    'windows_service.py',\n    'fortuna_monitor.py',\n    'setup_wizard.py',\n    'launcher.py',\n    'python_service/etl.py'\n]\n\n# --- Logic ---\ndef extract_and_normalize_path(line: str) -> str | None:\n    line = line.strip()\n    if not line or line.startswith('#'):\n        return None\n    md_match = re.search(r'\\((.*?)\\)', line)\n    if md_match:\n        path = md_match.group(1)\n    else:\n        path = line.strip('*').strip('-').strip().split('(')[0].strip()\n\n    if path.startswith('https://raw.githubusercontent.com/'):\n        path = '/'.join(path.split('/main/')[1:])\n    return path\n\ndef main():\n    print(\"Starting FORTUNA Pentad Dossier creation...\")\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        if not os.path.exists(manifest):\n            print(f\"[WARNING] Manifest not found: {manifest}\")\n            continue\n        with open(manifest, 'r', encoding='utf-8') as f:\n            for line in f.readlines():\n                path = extract_and_normalize_path(line)\n                if path and os.path.exists(path) and not os.path.isdir(path):\n                    all_local_paths.append(path)\n\n    # Manually scan the attic directory\n    attic_paths = []\n    if os.path.isdir('attic'):\n        for root, _, files in os.walk('attic'):\n            for file in files:\n                attic_paths.append(os.path.join(root, file))\n\n    all_local_paths.extend(attic_paths)\n\n    part1, part2, part3, part4, part5 = {}, {}, {}, {}, {}\n    unique_local_paths = sorted(list(set(all_local_paths)))\n\n    for local_path in unique_local_paths:\n        with open(local_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n\n        # --- Categorization Logic (Pentad) ---\n        if local_path.startswith('attic/'):\n            part5[local_path] = content\n        elif local_path.startswith('python_service/adapters/'):\n            part2[local_path] = content\n        elif local_path.startswith('web_platform/') or local_path.startswith('electron/'):\n            part3[local_path] = content\n        elif local_path in WINDOWS_TOOLING_FILES or local_path.endswith(('.bat', '.ps1', '.md')):\n            part4[local_path] = content\n        elif local_path.startswith('python_service/'):\n            part1[local_path] = content\n        else:\n            part4[local_path] = content # Catch-all for other root files\n\n    # --- Write Files ---\n    dossiers = [\n        (part1, OUTPUT_FILE_PART1),\n        (part2, OUTPUT_FILE_PART2),\n        (part3, OUTPUT_FILE_PART3),\n        (part4, OUTPUT_FILE_PART4),\n        (part5, OUTPUT_FILE_PART5)\n    ]\n    for i, (data, path) in enumerate(dossiers):\n        print(f\"Writing {len(data)} files to {path}...\")\n        with open(path, 'w', encoding='utf-8') as f:\n            json.dump(data, f, indent=4)\n        print(f\"    [SUCCESS] Part {i+1} created.\")\n\n    print(\"\\nPackaging process complete.\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "fortuna_monitor.py": "#!/usr/bin/env python3\n\"\"\"\nFORTUNA FAUCET - Advanced Windows Monitor with Performance Graphs\n\"\"\"\n\nimport asyncio\nimport httpx\nimport tkinter as tk\nfrom tkinter import ttk, messagebox\nfrom datetime import datetime\nfrom typing import List, Any\nimport os\nfrom collections import deque\nimport threading\nimport webbrowser\n\ntry:\n    import matplotlib\n    matplotlib.use('TkAgg')\n    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n    from matplotlib.figure import Figure\n    GRAPHS_AVAILABLE = True\nexcept ImportError:\n    GRAPHS_AVAILABLE = False\n\ndef load_api_key():\n    if os.path.exists('.env'):\n        with open('.env', 'r') as f:\n            for line in f:\n                if line.startswith('API_KEY='):\n                    return line.split('=', 1)[1].strip().strip('\\\"')\n    return None\n\nAPI_BASE_URL = \"http://localhost:8000\"\nAPI_KEY = load_api_key()\n\nclass PerformanceTracker:\n    def __init__(self, max_history=50):\n        self.timestamps = deque(maxlen=max_history)\n        self.race_counts = deque(maxlen=max_history)\n        self.fetch_durations = deque(maxlen=max_history)\n        self.success_rates = deque(maxlen=max_history)\n\n    def add_datapoint(self, races, duration, success_rate):\n        self.timestamps.append(datetime.now())\n        self.race_counts.append(races)\n        self.fetch_durations.append(duration)\n        self.success_rates.append(success_rate)\n\nclass FortunaAdvancedMonitor(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title(\"Fortuna Faucet - Advanced System Monitor\")\n        try:\n            from ctypes import windll\n            windll.shcore.SetProcessDpiAwareness(1)\n        except:\n            pass\n        self.geometry(\"1200x800\")\n        self.configure(bg='#1a1a2e')\n\n        self.performance = PerformanceTracker()\n        self.is_running = True\n        self.refresh_interval = 30000\n        self.auto_refresh_var = tk.BooleanVar(value=True)\n\n        self._setup_styles()\n        self._create_widgets()\n        self._setup_keyboard_shortcuts()\n        self.after(100, self.initial_load)\n\n    def initial_load(self):\n        if not API_KEY:\n            messagebox.showerror(\"Config Error\", \"API_KEY not found in .env file!\")\n            self.destroy()\n            return\n        self.schedule_refresh()\n\n    def _setup_styles(self):\n        style = ttk.Style()\n        style.theme_use('clam')\n        style.configure('Header.TLabel', background='#16213e', foreground='#e94560', font=('Segoe UI', 18, 'bold'), padding=15)\n        style.configure('Stat.TFrame', background='#0f3460', relief='flat')\n        style.configure('StatValue.TLabel', background='#0f3460', foreground='#00ff88', font=('Segoe UI', 24, 'bold'))\n        style.configure('StatLabel.TLabel', background='#0f3460', foreground='#ffffff', font=('Segoe UI', 10))\n\n    def _create_widgets(self):\n        header_frame = tk.Frame(self, bg='#16213e', height=100)\n        header_frame.pack(fill=tk.X)\n        header_frame.pack_propagate(False)\n        ttk.Label(header_frame, text=\"\ud83c\udfaf FORTUNA FAUCET\", style='Header.TLabel').pack(pady=10)\n\n        stats_frame = tk.Frame(self, bg='#1a1a2e')\n        stats_frame.pack(fill=tk.X, padx=15, pady=10)\n        self._create_stat_card(stats_frame, \"Active Adapters\", \"0\", 0)\n        self._create_stat_card(stats_frame, \"Total Races\", \"0\", 1)\n        self._create_stat_card(stats_frame, \"Success Rate\", \"0%\", 2)\n        self._create_stat_card(stats_frame, \"Avg Duration\", \"0s\", 3)\n\n        self.notebook = ttk.Notebook(self)\n        self.notebook.pack(fill=tk.BOTH, expand=True, padx=15, pady=10)\n        self.notebook.add(self._create_adapter_tab(), text=\"\ud83d\udd27 Adapters\")\n        if GRAPHS_AVAILABLE:\n            self.notebook.add(self._create_graph_tab(), text=\"\ud83d\udcc8 Live Performance\")\n\n        self._create_control_panel()\n        self._create_status_bar()\n\n    def _create_stat_card(self, parent, label, value, column):\n        card = ttk.Frame(parent, style='Stat.TFrame', width=250, height=100)\n        card.grid(row=0, column=column, padx=5, sticky='ew')\n        card.grid_propagate(False)\n        parent.grid_columnconfigure(column, weight=1)\n        value_label = ttk.Label(card, text=value, style='StatValue.TLabel')\n        value_label.pack(pady=(15, 0))\n        ttk.Label(card, text=label, style='StatLabel.TLabel').pack()\n        setattr(self, f'stat_{label.lower().replace(\" \", \"_\")}', value_label)\n\n    def _create_adapter_tab(self):\n        frame = tk.Frame(self.notebook, bg='#0f3460')\n        columns = ('Adapter', 'Status', 'Races', 'Duration', 'Error')\n        self.adapter_tree = ttk.Treeview(frame, columns=columns, show='headings')\n        for col in columns:\n            self.adapter_tree.heading(col, text=col)\n        self.adapter_tree.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n        return frame\n\n    def _create_graph_tab(self):\n        frame = tk.Frame(self.notebook, bg='#0f3460')\n        if GRAPHS_AVAILABLE:\n            self.fig = Figure(figsize=(10, 6), facecolor='#0f3460')\n            self.canvas = FigureCanvasTkAgg(self.fig, master=frame)\n            self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n            self.ax1 = self.fig.add_subplot(2, 2, 1, facecolor='#16213e')\n            self.ax2 = self.fig.add_subplot(2, 2, 2, facecolor='#16213e')\n            self.ax3 = self.fig.add_subplot(2, 2, 3, facecolor='#16213e')\n            self.ax4 = self.fig.add_subplot(2, 2, 4, facecolor='#16213e')\n            self.fig.tight_layout(pad=3.0)\n        else:\n            ttk.Label(frame, text=\"Install matplotlib to enable graphs: pip install matplotlib\").pack(expand=True)\n        return frame\n\n    def _create_control_panel(self):\n        control_frame = tk.Frame(self, bg='#1a1a2e')\n        control_frame.pack(fill=tk.X, padx=15, pady=10)\n        tk.Button(control_frame, text=\"\ud83d\udd04 Refresh Now\", command=self.manual_refresh, bg='#e94560', fg='#ffffff', font=('Segoe UI', 10, 'bold'), relief=tk.FLAT, padx=25, pady=10).pack(side=tk.LEFT)\n        tk.Button(control_frame, text=\"\ud83c\udf10 Dashboard\", command=lambda: webbrowser.open('http://localhost:3000'), bg='#0f3460', fg='#ffffff', font=('Segoe UI', 10, 'bold'), relief=tk.FLAT, padx=25, pady=10).pack(side=tk.LEFT, padx=5)\n        tk.Button(control_frame, text=\"\u2699\ufe0f Startup\", command=self.configure_startup, bg='#0f3460', fg='#ffffff', font=('Segoe UI', 10, 'bold'), relief=tk.FLAT, padx=25, pady=10).pack(side=tk.LEFT, padx=5)\n        tk.Checkbutton(control_frame, text=\"Auto-refresh\", variable=self.auto_refresh_var, bg='#1a1a2e', fg='#ffffff', selectcolor='#0f3460').pack(side=tk.RIGHT)\n\n    def _create_status_bar(self):\n        status_frame = tk.Frame(self, bg='#0f3460', height=30)\n        status_frame.pack(fill=tk.X, side=tk.BOTTOM)\n        status_frame.pack_propagate(False)\n        self.last_update_label = tk.Label(status_frame, text=\"Last Update: --:--:--\", bg='#0f3460', fg='#ffffff')\n        self.last_update_label.pack(side=tk.LEFT, padx=15)\n        self.status_indicator = tk.Label(status_frame, text=\"\u25cf Initializing...\", bg='#0f3460', fg='#ffcc00')\n        self.status_indicator.pack(side=tk.RIGHT, padx=15)\n\n    def manual_refresh(self):\n        self.status_indicator.config(text=\"\u25cf Fetching...\", fg='#ffcc00')\n        self.update()\n        threading.Thread(target=lambda: asyncio.run(self.refresh_data())).start()\n\n    async def refresh_data(self):\n        try:\n            headers = {\"X-API-Key\": API_KEY}\n            async with httpx.AsyncClient(timeout=10.0) as client:\n                response = await client.get(f\"{API_BASE_URL}/api/adapters/status\", headers=headers)\n                response.raise_for_status()\n                adapters = response.json()\n            self.update_ui(adapters)\n        except httpx.ConnectError:\n            self.update_ui(is_error=True, error_message=\"Backend Offline\")\n        except Exception as e:\n            self.update_ui(is_error=True, error_message=str(e))\n\n    def update_ui(self, adapters: List[Any] = [], is_error: bool = False, error_message: str = \"\"):\n        if is_error:\n            self.status_indicator.config(text=f\"\u25cf {error_message}\", fg='#ff4444')\n            for item in self.adapter_tree.get_children(): self.adapter_tree.delete(item)\n            self.adapter_tree.insert('', tk.END, values=('SYSTEM ERROR', 'FAILED', 0, 0, error_message[:60]))\n            return\n\n        total_races = sum(a.get('races_fetched', 0) for a in adapters)\n        avg_duration = sum(a.get('fetch_duration', 0) for a in adapters) / len(adapters) if adapters else 0\n        success_rate = sum(1 for a in adapters if a.get('status') == 'SUCCESS') / len(adapters) * 100 if adapters else 0\n        self.performance.add_datapoint(total_races, avg_duration, success_rate)\n\n        self.stat_active_adapters.config(text=str(len(adapters)))\n        self.stat_total_races.config(text=str(total_races))\n        self.stat_success_rate.config(text=f\"{success_rate:.1f}%\")\n        self.stat_avg_duration.config(text=f\"{avg_duration:.2f}s\")\n\n        for item in self.adapter_tree.get_children(): self.adapter_tree.delete(item)\n        for adapter in adapters:\n            status = adapter.get('status', 'UNKNOWN')\n            self.adapter_tree.insert('', tk.END, values=(adapter.get('name', 'Unknown'), status, adapter.get('races_fetched', 0), f\"{adapter.get('fetch_duration', 0):.2f}\", adapter.get('error_message', '\u2014')[:60]))\n\n        if GRAPHS_AVAILABLE: self.update_graphs()\n        self.last_update_label.config(text=f\"Last Update: {datetime.now().strftime('%H:%M:%S')}\")\n        self.status_indicator.config(text=\"\u25cf All Systems Operational\", fg='#00ff88')\n\n    def update_graphs(self):\n        history = self.performance\n        if not history.timestamps: return\n        for ax in [self.ax1, self.ax2, self.ax3, self.ax4]: ax.clear()\n        self.ax1.plot(history.timestamps, history.race_counts, color='#00ff88')\n        self.ax1.set_title('Races Fetched', color='white')\n        self.ax2.plot(history.timestamps, history.fetch_durations, color='#e94560')\n        self.ax2.set_title('Avg. Fetch Duration (s)', color='white')\n        self.ax3.plot(history.timestamps, history.success_rates, color='#ffcc00')\n        self.ax3.set_title('Success Rate (%)', color='white')\n        self.ax3.set_ylim(0, 105)\n        for ax in [self.ax1, self.ax2, self.ax3]:\n            ax.tick_params(axis='x', labelrotation=30, colors='white')\n        self.canvas.draw()\n\n    def schedule_refresh(self):\n        if self.is_running and self.auto_refresh_var.get():\n            self.manual_refresh()\n        if self.is_running:\n            self.after(self.refresh_interval, self.schedule_refresh)\n\n    def on_closing(self):\n        self.is_running = False\n        self.destroy()\n\n    def _setup_keyboard_shortcuts(self):\n        \"\"\"Binds standard Windows keyboard shortcuts to core functions.\"\"\"\n        self.bind('<F5>', lambda e: self.manual_refresh())\n        self.bind('<Control-r>', lambda e: self.manual_refresh())\n        self.bind('<Control-o>', lambda e: webbrowser.open('http://localhost:3000'))\n        self.bind('<Control-q>', lambda e: self.on_closing())\n        self.bind('<Alt-F4>', lambda e: self.on_closing())\n\nif __name__ == \"__main__\":\n    if not API_KEY:\n        messagebox.showerror(\"Config Error\", \"API_KEY not found in .env file!\")\n    else:\n        app = FortunaAdvancedMonitor()\n        app.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n        app.mainloop()\n\\n\\n    def _setup_keyboard_shortcuts(self):\\n        \"\"\"Binds standard Windows keyboard shortcuts to core functions.\"\"\"\\n        self.bind('<F5>', lambda e: self.manual_refresh())\\n        self.bind('<Control-r>', lambda e: self.manual_refresh())\\n        self.bind('<Control-o>', lambda e: webbrowser.open('http://localhost:3000'))\\n        self.bind('<Control-q>', lambda e: self.on_closing())\\n        self.bind('<Alt-F4>', lambda e: self.on_closing())\\n\n",
    "fortuna_tray.py": "# fortuna_tray.py\n# Provides a native Windows System Tray icon and menu for Fortuna Faucet.\n\nimport pystray\nimport configparser\nimport sys\nimport tkinter as tk\nfrom tkinter import messagebox\nfrom PIL import Image, ImageDraw, ImageFont\nimport webbrowser\nimport subprocess\nfrom pathlib import Path\n\nclass FortunaTrayApp:\n    def __init__(self):\n        self.icon = None\n        self.project_root = Path(__file__).parent.resolve()\n\n    def create_icon(self) -> Image.Image:\n        width = 64\n        height = 64\n        # Using a gold color for the icon background\n        image = Image.new('RGB', (width, height), color='#FFD700')\n        dc = ImageDraw.Draw(image)\n        font = ImageFont.load_default()\n        dc.text((12, 15), \"FF\", font=font, fill='black')\n        return image\n\n    def on_quit(self, icon, item):\n        icon.stop()\n        # Execute the main stop script to ensure all services are terminated\n        subprocess.Popen(str(self.project_root / \"STOP_FORTUNA.bat\"), shell=True)\n\n    def on_open_dashboard(self, icon, item):\n        webbrowser.open('http://localhost:3000')\n\n    def on_show_monitor(self, icon, item):\n        # Launch the Tkinter monitor\n        python_exe = self.project_root / \".venv\" / \"Scripts\" / \"python.exe\"\n        monitor_script = self.project_root / \"fortuna_monitor.py\"\n        subprocess.Popen([str(python_exe), str(monitor_script)])\n\n    def run(self):\n        menu = pystray.Menu(\n            pystray.MenuItem('Open Dashboard', self.on_open_dashboard, default=True),\n            pystray.MenuItem('Show Monitor', self.on_show_monitor),\n            pystray.Menu.SEPARATOR,\n            pystray.MenuItem('Quit Fortuna', self.on_quit)\n        )\n\n        self.icon = pystray.Icon(\n            \"Fortuna Faucet\",\n            self.create_icon(),\n            \"Fortuna Faucet - Racing Intelligence\",\n            menu\n        )\n\n        self.icon.run()\n\ndef validate_configuration():\n    \"\"\"\n    Reads config.ini and ensures all required sections and keys are present.\n    Raises ValueError if a required setting is missing.\n    \"\"\"\n    config = configparser.ConfigParser()\n    if not config.read('config.ini'):\n        raise ValueError(\"CRITICAL: config.ini file not found or is empty.\")\n\n    # Define all settings required for the application to function\n    required_settings = {\n        'API_KEYS': ['betfair_api_key'],\n        'SETTINGS': ['database_path', 'log_level']\n    }\n\n    missing_items = []\n    for section, keys in required_settings.items():\n        if not config.has_section(section):\n            missing_items.append(f\"Missing section: [{section}]\")\n            continue\n        for key in keys:\n            if not config.has_option(section, key) or not config.get(section, key):\n                missing_items.append(f\"Missing or empty key '{key}' in section [{section}]\")\n\n    if missing_items:\n        error_message = \"Configuration Error! Please fix the following issues in config.ini before launching:\\n\\n\"\n        error_message += \"\\n\".join(f\"- {item}\" for item in missing_items)\n        raise ValueError(error_message)\n\ndef main():\n    \"\"\"Main function to validate config and run the application.\"\"\"\n    try:\n        validate_configuration()\n    except (ValueError, configparser.Error) as e:\n        # Hide the redundant root tkinter window\n        root = tk.Tk()\n        root.withdraw()\n        messagebox.showerror(\"Fortuna Ascended - Configuration Error\", str(e))\n        sys.exit(1)\n\n    # If validation passes, proceed to create and run the tray icon\n    app = FortunaTrayApp()\n    app.run()\n\nif __name__ == \"__main__\":\n    main()\n",
    "fortuna_watchman.py": "#!/usr/bin/env python3\n# ==============================================================================\n#  Fortuna Faucet: The Watchman (v2 - Score-Aware)\n# ==============================================================================\n# This is the master orchestrator for the Fortuna Faucet project.\n# It executes the full, end-to-end handicapping strategy autonomously.\n# ==============================================================================\n\nimport asyncio\nimport httpx\nimport structlog\nfrom datetime import datetime, timedelta, timezone\nfrom typing import List\n\nfrom python_service.config import get_settings\nfrom python_service.engine import FortunaEngine\nfrom python_service.analyzer import AnalyzerEngine\nfrom python_service.models import Race\nfrom live_monitor import LiveOddsMonitor\n\nlog = structlog.get_logger(__name__)\n\nclass Watchman:\n    \"\"\"Orchestrates the daily operation of the Fortuna Faucet.\"\"\"\n\n    def __init__(self):\n        self.settings = get_settings()\n        self.odds_engine = FortunaEngine(config=self.settings)\n        self.analyzer_engine = AnalyzerEngine()\n\n    async def get_initial_targets(self) -> List[Race]:\n        \"\"\"Uses the OddsEngine and AnalyzerEngine to get the day's ranked targets.\"\"\"\n        log.info(\"Watchman: Acquiring and ranking initial targets for the day...\")\n        today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')\n        try:\n            background_tasks = set() # Create a dummy set for background tasks\n            aggregated_data = await self.odds_engine.get_races(today_str, background_tasks)\n            all_races = aggregated_data.get('races', [])\n            if not all_races:\n                log.warning(\"Watchman: No races returned from OddsEngine.\")\n                return []\n\n            analyzer = self.analyzer_engine.get_analyzer('trifecta')\n            qualified_races = analyzer.qualify_races(all_races) # This now returns a sorted list with scores\n            log.info(\"Watchman: Initial target acquisition and ranking complete\", target_count=len(qualified_races))\n\n            # Log the top targets for better observability\n            for race in qualified_races[:5]:\n                log.info(\"Top Target Found\",\n                    score=race.qualification_score,\n                    venue=race.venue,\n                    race_number=race.race_number,\n                    post_time=race.start_time.isoformat()\n                )\n            return qualified_races\n        except Exception as e:\n            log.error(\"Watchman: Failed to get initial targets\", error=str(e), exc_info=True)\n            return []\n\n    async def run_tactical_monitoring(self, targets: List[Race]):\n        \"\"\"Uses the LiveOddsMonitor on each target as it approaches post time.\"\"\"\n        log.info(\"Watchman: Entering tactical monitoring loop.\")\n        active_targets = list(targets)\n\n        from python_service.adapters.betfair_adapter import BetfairAdapter\n        async with LiveOddsMonitor(betfair_adapter=BetfairAdapter(config=self.settings)) as live_monitor:\n            async with httpx.AsyncClient() as client:\n                while active_targets:\n                    now = datetime.now(timezone.utc)\n\n                    # Find races that are within the 5-minute monitoring window\n                    races_to_monitor = [r for r in active_targets if r.start_time.replace(tzinfo=timezone.utc) > now and r.start_time.replace(tzinfo=timezone.utc) < now + timedelta(minutes=5)]\n\n                    if races_to_monitor:\n                        for race in races_to_monitor:\n                            log.info(\"Watchman: Deploying Live Monitor for approaching target\",\n                                race_id=race.id,\n                                venue=race.venue,\n                                score=race.qualification_score\n                            )\n                            updated_race = await live_monitor.monitor_race(race, client)\n                            log.info(\"Watchman: Live monitoring complete for race\", race_id=updated_race.id)\n                            # Remove from target list to prevent re-monitoring\n                            active_targets = [t for t in active_targets if t.id != race.id]\n\n                    if not active_targets:\n                        break # Exit loop if all targets are processed\n\n                    await asyncio.sleep(30) # Check for upcoming races every 30 seconds\n\n        log.info(\"Watchman: All targets for the day have been monitored. Mission complete.\")\n\n    async def execute_daily_protocol(self):\n        \"\"\"The main, end-to-end orchestration method.\"\"\"\n        log.info(\"--- Fortuna Watchman Daily Protocol: ACTIVE ---\")\n        initial_targets = await self.get_initial_targets()\n        if initial_targets:\n            await self.run_tactical_monitoring(initial_targets)\n        else:\n            log.info(\"Watchman: No initial targets found. Shutting down for the day.\")\n\n        await self.odds_engine.close()\n        log.info(\"--- Fortuna Watchman Daily Protocol: COMPLETE ---\")\n\nasync def main():\n    from python_service.logging_config import configure_logging\n    configure_logging()\n    watchman = Watchman()\n    await watchman.execute_daily_protocol()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
    "install_service.bat": "@echo off\nREM Installs and starts the Fortuna Faucet backend as a Windows Service.\n\necho Installing Fortuna Faucet as a Windows Service...\n\nREM Ensure pywin32 is installed in the venv\ncall .venv\\Scripts\\activate.bat\npip install pywin32 --quiet\n\nREM Install the service\npython windows_service.py install\n\nREM Start the service\npython windows_service.py start\n\necho.\necho Service installed and started successfully!\necho The backend will now run automatically in the background.\npause\n",
    "launcher.ps1": "<#\n.SYNOPSIS\n    Launches the Fortuna Faucet System Tray application.\n#>\n\nWrite-Host \"\ud83d\ude80 Launching Fortuna Faucet in System Tray...\" -ForegroundColor Cyan\n\n$VenvPath = \".\\\\.venv\\\\Scripts\\\\pythonw.exe\"\n$TrayAppPath = \".\\\\fortuna_tray.py\"\n\nif (-not (Test-Path $VenvPath)) {\n    Write-Host \"\u274c ERROR: Virtual environment not found at $VenvPath\" -ForegroundColor Red\n    Write-Host \"Please run INSTALL_FORTUNA.bat first.\"\n    Read-Host \"Press Enter to exit\"\n    exit 1\n}\n\nStart-Process -FilePath $VenvPath -ArgumentList $TrayAppPath -WindowStyle Hidden\n\nWrite-Host \"\u2705 Fortuna Faucet is now running in your system tray.\" -ForegroundColor Green\nWrite-Host \"Right-click the icon for options.\"\nStart-Sleep -Seconds 5\n",
    "manual_override_tool.py": "import argparse\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manual Override Tool for Checkmate Data Warehouse.\")\n    parser.add_argument(\"--file\", required=True, help=\"Path to the CSV file for ingestion.\")\n    parser.add_argument(\"--user\", required=True, help=\"The user ID performing the override.\")\n    args = parser.parse_args()\n\n    print(f\"Executing manual override by '{args.user}' for file '{args.file}'...\")\n\n    # 1. Connect to PostgreSQL\n    # engine = create_engine('postgresql://user:password@host:port/database')\n\n    # 2. Read and validate the CSV data\n    # race_df = pd.read_csv(args.file)\n    # ... validation logic ...\n\n    # 3. Add the manual_override_by column\n    # race_df['manual_override_by'] = args.user\n\n    # 4. Insert data into the 'historical_races' table\n    # race_df.to_sql('historical_races', engine, if_exists='append', index=False)\n\n    print(\"Manual override completed successfully.\")\n\nif __name__ == \"__main__\":\n    main()",
    "pg_schemas/historical_races.sql": "CREATE TABLE IF NOT EXISTS historical_races (\n    race_id VARCHAR(100) PRIMARY KEY,\n    track_name VARCHAR(100) NOT NULL,\n    race_number INT NOT NULL,\n    post_time TIMESTAMP WITH TIME ZONE NOT NULL,\n    source VARCHAR(50),\n    distance_meters INT,\n    race_class VARCHAR(100),\n    track_condition VARCHAR(50),\n    weather VARCHAR(100),\n    runners_data JSONB, -- Store the full runner list as a JSON object\n    checkmate_score FLOAT,\n    is_qualified BOOLEAN,\n    collection_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    manual_override_by VARCHAR(100) DEFAULT NULL -- Tracks human intervention\n);",
    "pg_schemas/quarantine_races.sql": "CREATE TABLE IF NOT EXISTS quarantine_races (\n    quarantine_id SERIAL PRIMARY KEY,\n    race_id VARCHAR(100),\n    track_name VARCHAR(100),\n    race_number INT,\n    post_time TIMESTAMP WITH TIME ZONE,\n    source VARCHAR(50),\n    raw_data_json JSONB, -- Store the original raw data for inspection\n    quarantine_reason TEXT, -- Reason for failing validation\n    collection_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);",
    "pyproject.toml": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"paddock-parser-ng\"\nversion = \"0.1.0\"\ndescription = \"A toolkit to identify the best racecards for betting.\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\n\n[project.scripts]\npaddock_parser_ui = \"paddock_parser.entry_points:run_terminal_ui\"\npaddock_parser_dashboard = \"paddock_parser.entry_points:run_dashboard\"\npaddock_parser_predict = \"paddock_parser.entry_points:run_prediction_engine\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n# Configuration for the Ruff linter\n[tool.ruff]\n# Enable Pyflakes (F), pycodestyle (E, W), and isort (I) rules.\nselect = [\"E\", \"F\", \"W\", \"I\"]\nignore = []\n\n# Allow lines to be up to 120 characters long.\nline-length = 120\n\n[tool.ruff.isort]\n# Sort imports within their sections alphabetically.\nforce-single-line = true\n",
    "pytest.ini": "[pytest]\npythonpath = python_service\nnorecursedirs = attic tests/checkmate_v7\ntestpaths = tests/adapters tests/api tests/database tests/ui tests/utils tests/test_backtester.py tests/test_fetcher.py tests/test_forager_client.py tests/test_log_analyzer.py tests/test_merger.py tests/test_pipeline.py tests/test_python_service.py tests/test_scorer.py tests/test_api.py tests/test_legacy_scenarios.py\n",
    "python_service/etl.py": "# python_service/etl.py\n# This module contains the ETL logic for the PostgreSQL data warehouse.\n# Restored based on the 'Code Archaeology Report'.\n\nimport os\nfrom typing import List\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\nfrom .models import Race\n\nclass PostgresETL:\n    \"\"\"Data Warehouse ETL\"\"\"\n    def __init__(self):\n        db_url = os.getenv(\"POSTGES_URL\", \"postgresql://user:password@localhost/fortuna_dw\")\n        self.engine = create_engine(db_url)\n\n    def process_and_load(self, analyzed_races: List[Race]):\n        valid_for_historical = []\n        quarantined = []\n        for race in analyzed_races:\n            errors = []\n            if not race.venue: errors.append(\"Missing venue\")\n            if race.race_number is None: errors.append(\"Missing race_number\")\n            if not errors:\n                valid_for_historical.append({\n                    \"race_id\": race.id,\n                    \"track_name\": race.venue,\n                    \"race_number\": race.race_number,\n                    \"post_time\": race.start_time,\n                    \"qualification_score\": race.qualification_score\n                })\n            else:\n                quarantined.append({\n                    \"race_id\": race.id,\n                    \"quarantine_reason\": \", \".join(errors),\n                    \"raw_data\": race.json()\n                })\n        if valid_for_historical:\n            pd.DataFrame(valid_for_historical).to_sql('historical_races', self.engine, if_exists='append', index=False)\n        if quarantined:\n            pd.DataFrame(quarantined).to_sql('quarantine_races', self.engine, if_exists='append', index=False)",
    "requirements.txt": "# Fortuna Faucet - Master Dependency List\n\n# --- Core Backend (FastAPI & Async) ---\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.2\npydantic-settings==2.1.0\nhttpx==0.27.0\nslowapi==0.1.9\nstructlog==24.1.0\npython-dotenv==1.0.0\n\n# --- Data Processing & Utilities ---\npandas==2.1.3\nbeautifulsoup4==4.12.2\nlxml==5.1.0\n\n# --- Caching Layer ---\nredis==5.0.1\n\n# --- Windows Native Edition ---\npywin32==306\ncolorama==0.4.6\nwin10toast-py3==0.9\nmatplotlib==3.8.2\npystray==0.19.5\npillow==10.1.0\n\n# --- Data Warehouse & ETL (Optional) ---\nSQLAlchemy==2.0.23\npsycopg2-binary==2.9.9\n\n# --- Historical Data Parsing (ChartScraper) ---\npikepdf==8.13.0\ntabula-py==2.7.0\nrequests==2.31.0\n\n# --- Code Quality & Testing ---\nruff==0.1.6\npytest==8.3.2\n",
    "run_backend.bat": "@echo off\nREM ============================================================================\nREM  Project Gemini: Backend Launcher\nREM ============================================================================\n\necho [INFO] Locating virtual environment...\nif not exist .\\\\.venv\\\\Scripts\\\\activate.bat (\n    echo [ERROR] Virtual environment not found. Please run 'setup_windows.bat' first.\n    goto :eof\n)\n\necho [INFO] Activating virtual environment...\ncall .\\\\.venv\\\\Scripts\\\\activate.bat\n\necho [INFO] Starting FastAPI server with uvicorn (hot-reloading enabled)...\nuvicorn python_service.api:app --reload\n\n:eof",
    "setup_windows.bat": "@echo off\nREM ============================================================================\nREM  Project Gemini: WHOLE-SYSTEM Windows Setup Script\nREM ============================================================================\n\necho [INFO] Starting full-stack setup for Project Gemini...\n\nREM --- Section 1: Python Backend Setup ---\necho.\necho [BACKEND] Checking for Python installation...\npython --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Python is not found. Please install Python 3.8+ and add to PATH.\n    goto :eof\n)\necho [BACKEND] Python found.\n\necho [BACKEND] Creating Python virtual environment in '.\\\\.venv\\\\'...\nif not exist .\\\\.venv ( python -m venv .venv )\n\necho [BACKEND] Installing dependencies from 'python_service/requirements.txt'...\ncall .\\\\.venv\\\\Scripts\\\\activate.bat && pip install -r python_service/requirements.txt\nif %errorlevel% neq 0 (\n    echo [ERROR] Backend setup failed.\n    goto :eof\n)\necho [SUCCESS] Python backend setup complete.\n\nREM --- Section 2: TypeScript Frontend Setup ---\necho.\necho [FRONTEND] Checking for Node.js installation...\nnode --version >nul 2>&1\nif %errorlevel% neq 0 (\n    echo [ERROR] Node.js is not found. Please install Node.js (LTS).\n    goto :eof\n)\necho [FRONTEND] Node.js found.\n\necho [FRONTEND] Installing dependencies from 'package.json'...\ncd web_platform/frontend\nnpm install\nif %errorlevel% neq 0 (\n    echo [ERROR] Frontend setup failed. Check npm errors.\n    cd ../..\n    goto :eof\n)\n\necho [FRONTEND] Checking for frontend environment file...\nif not exist .env.local (\n    echo [FRONTEND] '.env.local' not found. Creating from template...\n    copy .env.local.example .env.local\n    echo.\n    echo    ****************************************************************************\n    echo    *  [ACTION REQUIRED] Please edit 'web_platform/frontend/.env.local'      *\n    echo    *  and add your NEXT_PUBLIC_API_KEY for the frontend to work.            *\n    echo    ****************************************************************************\n    echo.\n) else (\n    echo [FRONTEND] '.env.local' already exists.\n)\n\ncd ../..\necho [SUCCESS] TypeScript frontend setup complete.\n\nREM --- Final Instructions ---\necho.\necho ============================================================================\nREM  FULL-STACK SETUP COMPLETE!\nREM  You can now launch the entire application with 'run_fortuna.bat'\nREM ============================================================================\n\n:eof",
    "setup_wizard.py": "# setup_wizard.py\n\"\"\"\nInteractive configuration wizard for Fortuna Faucet.\nGuides users through initial setup and API key configuration.\n\"\"\"\n\nimport os\nfrom pathlib import Path\nimport getpass\nimport secrets\nfrom datetime import datetime\n\nclass SetupWizard:\n    def __init__(self):\n        self.config = {}\n        self.env_file = Path('.env')\n\n    def run(self):\n        print(\"\\n\" + \"=\"*60)\n        print(\"   Welcome to Fortuna Faucet Setup Wizard\")\n        print(\"=\"*60 + \"\\n\")\n\n        if self.env_file.exists():\n            overwrite = input(f\"\u26a0\ufe0f  Configuration file '{self.env_file}' already exists. Overwrite? (y/N): \").lower()\n            if overwrite != 'y':\n                print(\"\\nSetup cancelled.\")\n                return\n\n        print(\"\\n\ud83d\udccb Step 1: Core Configuration\")\n        print(\"-\" * 60)\n        self._configure_core()\n\n        print(\"\\n\ud83d\udd11 Step 2: Betfair API (Required for Live Monitoring)\")\n        print(\"-\" * 60)\n        self._configure_betfair()\n\n        self._write_config()\n        self._display_summary()\n\n    def _configure_core(self):\n        \"\"\"Configure essential settings\"\"\"\n        print(\"\\nGenerating a secure, private API key for communication between your services...\")\n        api_key = secrets.token_urlsafe(32)\n        self.config['API_KEY'] = api_key\n        print(f\"\u2705 API Key generated successfully.\")\n\n    def _configure_betfair(self):\n        \"\"\"Configure Betfair Exchange API\"\"\"\n        print(\"\\nBetfair Exchange provides live odds and is essential for the\")\n        print(\"LiveOddsMonitor feature. Get your API key at:\")\n        print(\"\ud83d\udc49 https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni\")\n\n        configure = input(\"\\nConfigure Betfair now? (Y/n): \").lower()\n        if configure != 'n':\n            self.config['BETFAIR_APP_KEY'] = input(\"App Key: \").strip()\n            self.config['BETFAIR_USERNAME'] = input(\"Username: \").strip()\n            self.config['BETFAIR_PASSWORD'] = getpass.getpass(\"Password: \").strip()\n            print(\"\u2705 Betfair configured\")\n        else:\n            self.config['BETFAIR_APP_KEY'] = \"\"\n            self.config['BETFAIR_USERNAME'] = \"\"\n            self.config['BETFAIR_PASSWORD'] = \"\"\n            print(\"\u23ed\ufe0f  Skipped - Live monitoring will be disabled\")\n\n    def _write_config(self):\n        \"\"\"Write configuration to .env file\"\"\"\n        with open(self.env_file, 'w') as f:\n            f.write(\"# Fortuna Faucet Configuration\\n\")\n            f.write(f\"# Generated by Setup Wizard on {datetime.now().isoformat()}\\n\\n\")\n\n            f.write(\"# --- Core Settings ---\\n\")\n            f.write(f\"API_KEY=\\\"{self.config['API_KEY']}\\\"\\n\\n\")\n\n            f.write(\"# --- Betfair Exchange ---\\n\")\n            f.write(f\"BETFAIR_APP_KEY=\\\"{self.config['BETFAIR_APP_KEY']}\\\"\\n\")\n            f.write(f\"BETFAIR_USERNAME=\\\"{self.config['BETFAIR_USERNAME']}\\\"\\n\")\n            f.write(f\"BETFAIR_PASSWORD=\\\"{self.config['BETFAIR_PASSWORD']}\\\"\\n\")\n\n    def _display_summary(self):\n        \"\"\"Display setup summary\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"   \u2705 Setup Complete!\")\n        print(\"=\"*60)\n        print(f\"\\n\ud83d\udcc1 Configuration saved to '{self.env_file}'\")\n        print(\"\\n\ud83d\ude80 Next Steps:\")\n        print(\"   1. Run INSTALL_FORTUNA.bat (as Administrator) if you haven't already.\")\n        print(\"   2. Double-click the 'Launch Fortuna' shortcut on your desktop.\")\n        print(\"\\n\ud83d\udca1 Tip:\")\n        print(\"   - You can run this wizard again at any time to reconfigure your settings.\")\n        print(\"\\n\" + \"=\"*60 + \"\\n\")\n\nif __name__ == '__main__':\n    wizard = SetupWizard()\n    wizard.run()\n",
    "src/paddock_parser/api/main.py": "# src/paddock_parser/api/main.py\n\nimport csv\nimport io\nfrom datetime import datetime\nfrom typing import List, Optional\n\nfrom fastapi import FastAPI, Response\nfrom pydantic import BaseModel, ConfigDict\n\n# The core logic of our application is in the pipeline\nfrom src.paddock_parser.pipeline import run_pipeline\n\n# Pydantic Models (Schemas) for the API response.\n# These will ensure the output is validated and serialized correctly.\n# The 'from_attributes=True' mode (via ConfigDict) allows creating these\n# models directly from our existing dataclasses (e.g., NormalizedRace).\n\nclass RunnerSchema(BaseModel):\n    \"\"\"Pydantic schema for a single runner.\"\"\"\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    program_number: int\n\n\nclass RaceSchema(BaseModel):\n    \"\"\"Pydantic schema for a single race, including a list of runners.\"\"\"\n    model_config = ConfigDict(from_attributes=True)\n\n    race_id: str\n    track_name: str\n    race_number: int\n    post_time: datetime\n    number_of_runners: int\n    runners: List[RunnerSchema]\n    score: int\n\n\n# Create the FastAPI application instance\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef read_root():\n    \"\"\"\n    Root endpoint to confirm the API is running.\n    \"\"\"\n    return {\"message\": \"Paddock Parser API is running.\"}\n\n\n@app.get(\"/api/v1/races\", response_model=List[RaceSchema])\nasync def get_races(min_runners: Optional[int] = None, source: Optional[str] = None):\n    \"\"\"\n    Retrieves a list of races from the pipeline, optionally filtered by the\n    minimum number of runners or a specific data source.\n    \"\"\"\n    # The API exposes 'source' as the query parameter for user convenience,\n    # but the underlying pipeline function expects 'specific_source'.\n    # We perform the mapping here.\n    races = await run_pipeline(min_runners=min_runners, specific_source=source)\n    return races\n\n@app.get(\"/api/v1/races.json\", response_model=List[RaceSchema], include_in_schema=False)\nasync def get_races_json(min_runners: Optional[int] = None, source: Optional[str] = None):\n    \"\"\"\n    Alias for /api/v1/races. Returns race data in JSON format.\n    \"\"\"\n    return await get_races(min_runners=min_runners, source=source)\n\n\n@app.get(\"/api/v1/races.csv\")\nasync def get_races_csv(min_runners: Optional[int] = None, source: Optional[str] = None):\n    \"\"\"\n    Retrieves a list of races from the pipeline and returns it as a CSV file.\n    The nested runner data is not included in the CSV output.\n    \"\"\"\n    races = await run_pipeline(min_runners=min_runners, specific_source=source)\n\n    output = io.StringIO()\n    writer = csv.writer(output)\n\n    # Write header\n    header = [\"race_id\", \"track_name\", \"race_number\", \"post_time\", \"number_of_runners\", \"score\"]\n    writer.writerow(header)\n\n    # Write data rows\n    for race in races:\n        writer.writerow([\n            race.race_id,\n            race.track_name,\n            race.race_number,\n            race.post_time.isoformat(),\n            race.number_of_runners,\n            race.score\n        ])\n\n    return Response(content=output.getvalue(), media_type=\"text/csv\")\n",
    "src/paddock_parser/database/manager.py": "import sqlite3\nfrom typing import List\nfrom collections import defaultdict\nfrom paddock_parser.models import Race, Runner, Prediction\n\nclass DatabaseManager:\n    def __init__(self, db_path: str):\n        \"\"\"Initializes the DatabaseManager and connects to the database.\"\"\"\n        self.conn = sqlite3.connect(db_path)\n        self.conn.row_factory = sqlite3.Row # Allows accessing columns by name\n        self.conn.execute(\"PRAGMA foreign_keys = 1\")\n\n    def create_tables(self):\n        \"\"\"Creates the necessary tables if they don't already exist.\"\"\"\n        cursor = self.conn.cursor()\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS races (\n                race_id TEXT PRIMARY KEY,\n                venue TEXT NOT NULL,\n                race_time TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                is_handicap INTEGER NOT NULL,\n                source TEXT,\n                sources TEXT\n            )\n        \"\"\")\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS runners (\n                runner_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                race_id TEXT NOT NULL,\n                name TEXT NOT NULL,\n                odds TEXT NOT NULL,\n                is_winner INTEGER NOT NULL DEFAULT 0,\n                FOREIGN KEY (race_id) REFERENCES races (race_id) ON DELETE CASCADE\n            )\n        \"\"\")\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS predictions (\n                prediction_id INTEGER PRIMARY KEY AUTOINCREMENT,\n                race_id TEXT NOT NULL,\n                track TEXT NOT NULL,\n                race_number INTEGER NOT NULL,\n                predicted_at TEXT NOT NULL,\n                favorite_name TEXT NOT NULL,\n                favorite_odds REAL NOT NULL,\n                UNIQUE(race_id, predicted_at)\n            )\n        \"\"\")\n        self.conn.commit()\n\n    def save_prediction(self, prediction: Prediction):\n        \"\"\"Saves a prediction to the database.\"\"\"\n        cursor = self.conn.cursor()\n        try:\n            cursor.execute(\"\"\"\n                INSERT INTO predictions (race_id, track, race_number, predicted_at, favorite_name, favorite_odds)\n                VALUES (?, ?, ?, ?, ?, ?)\n            \"\"\", (\n                prediction.race_id,\n                prediction.track,\n                prediction.race_number,\n                prediction.predicted_at.isoformat(),\n                prediction.favorite_name,\n                prediction.favorite_odds\n            ))\n            self.conn.commit()\n        except sqlite3.IntegrityError:\n            # This is expected if we try to log the same opportunity again, so we can ignore it silently.\n            self.conn.rollback()\n        except sqlite3.Error as e:\n            print(f\"Database error during prediction save: {e}\")\n            self.conn.rollback()\n\n    def save_race(self, race: Race):\n        \"\"\"Saves a race and its runners to the database using an upsert logic.\"\"\"\n        cursor = self.conn.cursor()\n        try:\n            sources_json = \",\".join(race.sources) if race.sources else \"\"\n            cursor.execute(\"\"\"\n                INSERT OR REPLACE INTO races (race_id, venue, race_time, race_number, is_handicap, source, sources)\n                VALUES (?, ?, ?, ?, ?, ?, ?)\n            \"\"\", (race.race_id, race.venue, race.race_time, race.race_number, race.is_handicap, race.source, sources_json))\n\n            cursor.execute(\"DELETE FROM runners WHERE race_id = ?\", (race.race_id,))\n\n            if race.runners:\n                runner_data = [(race.race_id, r.name, r.odds, r.is_winner) for r in race.runners]\n                cursor.executemany(\"\"\"\n                    INSERT INTO runners (race_id, name, odds, is_winner)\n                    VALUES (?, ?, ?, ?)\n                \"\"\", runner_data)\n\n            self.conn.commit()\n        except sqlite3.Error as e:\n            print(f\"Database error: {e}\")\n            self.conn.rollback()\n\n    def get_all_races(self) -> List[Race]:\n        \"\"\"Retrieves all races and their runners from the database.\"\"\"\n        cursor = self.conn.cursor()\n\n        # Fetch all runners and group them by race_id\n        cursor.execute(\"SELECT * FROM runners\")\n        runners_by_race = defaultdict(list)\n        for row in cursor.fetchall():\n            runner = Runner(\n                name=row['name'],\n                odds=row['odds'],\n                is_winner=bool(row['is_winner'])\n            )\n            runners_by_race[row['race_id']].append(runner)\n\n        # Fetch all races and attach the grouped runners\n        cursor.execute(\"SELECT * FROM races\")\n        races = []\n        for row in cursor.fetchall():\n            race_id = row['race_id']\n            race = Race(\n                race_id=race_id,\n                venue=row['venue'],\n                race_time=row['race_time'],\n                race_number=row['race_number'],\n                is_handicap=bool(row['is_handicap']),\n                source=row['source'],\n                sources=row['sources'].split(',') if row['sources'] else [],\n                runners=runners_by_race.get(race_id, [])\n            )\n            races.append(race)\n\n        return races\n\n    def close(self):\n        \"\"\"Closes the database connection.\"\"\"\n        if self.conn:\n            self.conn.close()\n",
    "src/paddock_parser/ui/terminal_ui.py": "from typing import List, Optional\n\nfrom rich.console import Console\nfrom rich.table import Table\nfrom rich.progress import Progress\nfrom rich.logging import RichHandler\n\nfrom ..base import NormalizedRace\nfrom ..pipeline import run_pipeline\nfrom ..models import Race as ScorerRace, Runner as ScorerRunner\nfrom ..config import LOG_FILE_PATH\nfrom ..log_analyzer import analyze_log_file\n\n\ndef _convert_normalized_to_scorer_race(norm_race: NormalizedRace) -> Optional[ScorerRace]:\n    \"\"\"Converts a NormalizedRace to the ScorerRace model for use with scorer functions.\"\"\"\n    if not norm_race.post_time:\n        return None\n\n    scorer_runners = [ScorerRunner(name=r.name, odds=r.odds) for r in norm_race.runners]\n    is_handicap = norm_race.race_type and \"handicap\" in norm_race.race_type.lower()\n\n    return ScorerRace(\n        race_id=norm_race.race_id,\n        venue=norm_race.track_name,\n        race_number=norm_race.race_number,\n        race_time=norm_race.post_time.strftime(\"%H:%M\"),\n        number_of_runners=norm_race.number_of_runners,\n        is_handicap=is_handicap,\n        runners=scorer_runners,\n        # The score and scores attributes will be added by the pipeline\n    )\n\n\nclass TerminalUI:\n    \"\"\"\n    A class to handle all terminal output using the rich library.\n    \"\"\"\n    def __init__(self, console: Console = None):\n        self.console = console or Console()\n        self.progress = None\n        self.progress_task = None\n        self.log_handler = None\n\n    def display_scoring_report(self, races: List[NormalizedRace]):\n        \"\"\"\n        Displays the dynamic scoring report in a rich, formatted table.\n        NOTE: This expects races to already be sorted by the pipeline.\n        \"\"\"\n        if not races:\n            self.console.print(\"[bold yellow]No races were found to score.[/bold yellow]\")\n            return\n\n        table = Table(title=\"[bold green]Dynamic Scoring Report[/bold green]\")\n        table.add_column(\"Race Time\", style=\"cyan\")\n        table.add_column(\"Venue\", style=\"magenta\")\n        table.add_column(\"Race #\", style=\"white\")\n        table.add_column(\"Runners\", style=\"white\")\n        table.add_column(\"Handicap\", style=\"white\")\n        table.add_column(\"Fav Odds\", style=\"yellow\")\n        table.add_column(\"Contention\", style=\"yellow\")\n        table.add_column(\"Field Size\", style=\"yellow\")\n        table.add_column(\"Total Score\", style=\"bold green\")\n\n        for race in races:\n            scores = getattr(race, 'scores', {})\n            post_time_str = race.post_time.strftime(\"%H:%M\") if race.post_time else \"N/A\"\n            is_handicap_str = \"Yes\" if (race.race_type and \"handicap\" in race.race_type.lower()) else \"No\"\n\n            table.add_row(\n                post_time_str,\n                race.track_name,\n                str(race.race_number),\n                str(race.number_of_runners),\n                is_handicap_str,\n                f\"{scores.get('favorite_odds_score', 0):.2f}\",\n                f\"{scores.get('contention_score', 0):.2f}\",\n                f\"{scores.get('field_size_score', 0):.3f}\",\n                f\"{scores.get('total_score', 0):.2f}\",\n            )\n        self.console.print(table)\n\n    def display_log_analysis_report(self):\n        \"\"\"\n        Analyzes the log file and displays a summary report.\n        \"\"\"\n        self.console.print(f\"\\n[bold]Analyzing log file at:[/] [cyan]{LOG_FILE_PATH}[/cyan]\")\n        log_counts = analyze_log_file(LOG_FILE_PATH)\n\n        if not log_counts:\n            self.console.print(\"[yellow]No log data found or file could not be read.[/yellow]\")\n            return\n\n        table = Table(title=\"[bold blue]Log File Analysis[/bold blue]\")\n        table.add_column(\"Log Level\", style=\"cyan\")\n        table.add_column(\"Count\", style=\"magenta\", justify=\"right\")\n\n        for level, count in sorted(log_counts.items()):\n            table.add_row(level, str(count))\n        self.console.print(table)\n\n    def start_fetching_progress(self, num_tasks: int):\n        \"\"\"Initializes and starts a progress bar for fetching races.\"\"\"\n        self.progress = Progress(console=self.console)\n        self.progress.start()\n        self.progress_task = self.progress.add_task(\"Fetching races...\", total=num_tasks)\n\n    def update_fetching_progress(self):\n        \"\"\"Advances the fetching progress bar by one step.\"\"\"\n        if self.progress and self.progress_task is not None:\n            self.progress.update(self.progress_task, advance=1)\n\n    def stop_fetching_progress(self):\n        \"\"\"Stops the progress bar and cleans up.\"\"\"\n        if self.progress:\n            self.progress.stop()\n            self.progress = None\n            self.progress_task = None\n\n    def setup_logging(self):\n        \"\"\"Creates a RichHandler and sets it up.\"\"\"\n        self.log_handler = RichHandler(console=self.console, show_path=False)\n\n    def _display_main_menu(self):\n        \"\"\"Displays the main menu options.\"\"\"\n        self.console.print(\"\\n[bold magenta]Paddock Parser NG - Main Menu[/bold magenta]\")\n        self.console.print(\"1. Get Dynamic Scoring Report\")\n        self.console.print(\"2. View Log Analysis Report\")\n        self.console.print(\"3. Quit\")\n\n    async def start_interactive_mode(self):\n        \"\"\"Starts the main interactive loop for the UI.\"\"\"\n        while True:\n            self._display_main_menu()\n            choice = self.console.input(\"[bold]Select an option: [/bold]\")\n            if choice == '1':\n                await self._run_scoring_report()\n            elif choice == '2':\n                self.display_log_analysis_report()\n            elif choice == '3':\n                self.console.print(\"[yellow]Goodbye![/yellow]\")\n                break\n            else:\n                self.console.print(\"[bold red]Invalid option, please try again.[/bold red]\")\n\n    async def _run_scoring_report(self):\n        \"\"\"Runs the full pipeline and displays the dynamic scoring report.\"\"\"\n        with self.console.status(\"Fetching data from providers...\", spinner=\"dots\"):\n            scored_races = await run_pipeline(min_runners=0, specific_source=None)\n\n        if not scored_races:\n            self.console.print(\"[yellow]No races were found by the pipeline.[/yellow]\")\n            return\n        self.display_scoring_report(scored_races)\n",
    "src/paddock_parser/utils/browser.py": "def view_text_website(url: str) -> str:\n    \"\"\"\n    A wrapper for the external 'view_text_website' tool.\n\n    This function is intended to be mocked during unit testing.\n    In a real-world execution, this would be replaced by a mechanism\n    that can actually call the external tool.\n    \"\"\"\n    raise NotImplementedError(\"The 'view_text_website' tool cannot be called directly from application code.\")\n",
    "src/paddock_parser/utils/honeypot.py": "from bs4 import BeautifulSoup, Tag\n\ndef is_element_hidden(element: Tag) -> bool:\n    \"\"\"\n    Checks if an element is hidden via inline CSS styles, including its parents.\n    \"\"\"\n    for parent in [element] + list(element.parents):\n        style = parent.get('style', '').lower().replace(' ', '')\n        if 'display:none' in style or 'visibility:hidden' in style:\n            return True\n    return False\n\ndef remove_honeypots(soup: BeautifulSoup) -> BeautifulSoup:\n    \"\"\"\n    Finds and removes likely \"honeypot\" links from a parsed HTML document.\n\n    A honeypot link is an <a> tag that is not visible to a human user,\n    designed to trap web scrapers.\n\n    This function targets links that are explicitly hidden using inline CSS\n    styles like 'display: none' or 'visibility: hidden', checking both the\n    element itself and its parent containers.\n    \"\"\"\n    # Find all links in the document\n    links = soup.find_all('a')\n\n    for link in links:\n        if is_element_hidden(link):\n            link.decompose()\n\n    return soup\n",
    "tests/adapters/test_gbgb_api_adapter.py": "# tests/adapters/test_gbgb_api_adapter.py\n\nimport pytest\nimport respx\nimport httpx\nfrom datetime import date\nfrom decimal import Decimal\n\nfrom python_service.config import get_settings\nfrom python_service.adapters.gbgb_api_adapter import GbgbApiAdapter\n\n@pytest.fixture\ndef gbgb_adapter():\n    \"\"\"Returns a GbgbApiAdapter instance for testing.\"\"\"\n    return GbgbApiAdapter(config=get_settings())\n\n@pytest.mark.asyncio\n@respx.mock\nasync def test_fetch_gbgb_races_successfully(gbgb_adapter):\n    \"\"\"\n    SPEC: The GbgbApiAdapter should correctly parse a standard API response,\n    creating Race and Runner objects with the correct data, including fractional odds.\n    \"\"\"\n    # ARRANGE\n    mock_date = date.today().strftime('%Y-%m-%d')\n    mock_url = f\"{gbgb_adapter.base_url}results/meeting/{mock_date}\"\n\n    mock_api_response = [\n        {\n            \"trackName\": \"Towcester\",\n            \"races\": [\n                {\n                    \"raceId\": 12345,\n                    \"raceNumber\": 1,\n                    \"raceTime\": \"2025-10-09T18:00:00Z\",\n                    \"raceTitle\": \"The October Sprint\",\n                    \"raceDistance\": 500,\n                    \"traps\": [\n                        {\n                            \"trapNumber\": 1,\n                            \"dogName\": \"Rapid Rover\",\n                            \"sp\": \"5/2\"\n                        },\n                        {\n                            \"trapNumber\": 2,\n                            \"dogName\": \"Speedy Sue\",\n                            \"sp\": \"EVS\" # Test even money\n                        },\n                        {\n                            \"trapNumber\": 3,\n                            \"dogName\": \"Lazy Larry\",\n                            \"sp\": \"10/1\"\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n\n    respx.get(mock_url).mock(return_value=httpx.Response(200, json=mock_api_response))\n\n    # ACT\n    async with httpx.AsyncClient() as client:\n        result = await gbgb_adapter.fetch_races(mock_date, client)\n\n    # ASSERT\n    assert result['source_info']['status'] == 'SUCCESS'\n    assert len(result['races']) == 1\n\n    race = result['races'][0]\n    assert race.venue == \"Towcester\"\n    assert race.race_number == 1\n    assert race.race_name == \"The October Sprint\"\n    assert race.distance == \"500m\"\n    assert len(race.runners) == 3\n\n    runner1 = next(r for r in race.runners if r.number == 1)\n    assert runner1.name == \"Rapid Rover\"\n    assert runner1.odds['GBGB'].win == Decimal(\"3.5\")\n\n    runner2 = next(r for r in race.runners if r.number == 2)\n    assert runner2.name == \"Speedy Sue\"\n    assert runner2.odds['GBGB'].win == Decimal(\"2.0\")\n\n    runner3 = next(r for r in race.runners if r.number == 3)\n    assert runner3.name == \"Lazy Larry\"\n    assert runner3.odds['GBGB'].win == Decimal(\"11.0\")",
    "tests/adapters/test_greyhound_adapter.py": "import pytest\nfrom unittest.mock import AsyncMock, patch\nfrom datetime import date, datetime\nfrom python_service.adapters.greyhound_adapter import GreyhoundAdapter\nfrom python_service.config import Settings\n\n@pytest.fixture\ndef mock_config():\n    \"\"\"\n    Provides a mock config object for the adapter, ensuring it doesn't\n    load from any .env files, which prevents test pollution.\n    \"\"\"\n    class TestSettings(Settings):\n        class Config:\n            env_file = None\n\n    return TestSettings(\n        BETFAIR_APP_KEY=\"test_key\",\n        BETFAIR_USERNAME=\"test_user\",\n        BETFAIR_PASSWORD=\"test_password\",\n        API_KEY=\"test_api_key\",\n        GREYHOUND_API_URL=\"https://api.example.com\"\n    )\n\n@pytest.mark.asyncio\n@patch('python_service.adapters.greyhound_adapter.GreyhoundAdapter.make_request', new_callable=AsyncMock)\nasync def test_fetch_races_parses_correctly(mock_make_request, mock_config):\n    \"\"\"\n    Tests that the GreyhoundAdapter correctly parses a valid API response.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=mock_config)\n    today = date.today().strftime('%Y-%m-%d')\n\n    mock_api_response = {\n        \"cards\": [\n            {\n                \"track_name\": \"Test Track\",\n                \"races\": [\n                    {\n                        \"race_id\": \"test_race_123\",\n                        \"race_number\": 1,\n                        \"start_time\": int(datetime.now().timestamp()),\n                        \"runners\": [\n                            {\n                                \"dog_name\": \"Rapid Rover\",\n                                \"trap_number\": 1,\n                                \"odds\": {\"win\": \"2.5\"}\n                            },\n                            {\n                                \"dog_name\": \"Swift Sprint\",\n                                \"trap_number\": 2,\n                                \"scratched\": True\n                            },\n                            {\n                                \"dog_name\": \"Lazy Larry\",\n                                \"trap_number\": 3,\n                                \"odds\": {\"win\": \"10.0\"}\n                            }\n                        ]\n                    }\n                ]\n            }\n        ]\n    }\n    mock_make_request.return_value = mock_api_response\n\n    # ACT\n    result = await adapter.fetch_races(today, AsyncMock())\n\n    # ASSERT\n    assert result is not None\n    assert result['source_info']['status'] == 'SUCCESS'\n    assert result['source_info']['races_fetched'] == 1\n\n    races = result['races']\n    assert len(races) == 1\n\n    race = races[0]\n    assert race.id == 'greyhound_test_race_123'\n    assert race.venue == 'Test Track'\n    assert len(race.runners) == 2 # One was scratched\n\n    runner1 = race.runners[0]\n    assert runner1.name == 'Rapid Rover'\n    assert runner1.number == 1\n    assert runner1.odds['Greyhound Racing'].win == 2.5\n\n@pytest.mark.asyncio\n@patch('python_service.adapters.greyhound_adapter.GreyhoundAdapter.make_request', new_callable=AsyncMock)\nasync def test_fetch_races_handles_empty_response(mock_make_request, mock_config):\n    \"\"\"\n    Tests that the GreyhoundAdapter handles an empty or invalid API response gracefully.\n    \"\"\"\n    # ARRANGE\n    adapter = GreyhoundAdapter(config=mock_config)\n    today = date.today().strftime('%Y-%m-%d')\n    mock_make_request.return_value = {\"cards\": []} # Simulate no races found\n\n    # ACT\n    result = await adapter.fetch_races(today, AsyncMock())\n\n    # ASSERT\n    assert result is not None\n    assert result['source_info']['status'] == 'SUCCESS'\n    assert result['source_info']['races_fetched'] == 0\n    assert result['source_info']['error_message'] == \"No race cards found for date.\"\n    assert len(result['races']) == 0",
    "tests/adapters/test_the_racing_api_adapter.py": "import pytest\nfrom unittest.mock import AsyncMock, patch\nfrom datetime import date, datetime\nfrom decimal import Decimal\n\nfrom python_service.adapters.the_racing_api_adapter import TheRacingApiAdapter\nfrom python_service.config import Settings\n\n@pytest.fixture\ndef mock_config():\n    \"\"\"\n    Provides a mock config object for the adapter, ensuring it doesn't\n    load from any .env files and provides the necessary API key.\n    \"\"\"\n    class TestSettings(Settings):\n        class Config:\n            env_file = None\n\n    return TestSettings(\n        API_KEY=\"test_api_key\",\n        THE_RACING_API_KEY=\"test_racing_api_key\"\n    )\n\n@pytest.fixture\ndef mock_config_no_key():\n    \"\"\"Provides a mock config with the API key explicitly set to None.\"\"\"\n    class TestSettings(Settings):\n        class Config:\n            env_file = None\n\n    return TestSettings(\n        API_KEY=\"test_api_key\",\n        THE_RACING_API_KEY=None\n    )\n\n@pytest.mark.asyncio\n@patch('python_service.adapters.the_racing_api_adapter.TheRacingApiAdapter.make_request', new_callable=AsyncMock)\nasync def test_fetch_races_parses_correctly(mock_make_request, mock_config):\n    \"\"\"\n    Tests that TheRacingApiAdapter correctly parses a valid API response.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=mock_config)\n    today = date.today().strftime('%Y-%m-%d')\n    off_time_str = datetime.utcnow().isoformat() + \"Z\"\n\n\n    mock_api_response = {\n        \"racecards\": [\n            {\n                \"race_id\": \"12345\",\n                \"course\": \"Newbury\",\n                \"race_no\": 3,\n                \"off_time\": off_time_str,\n                \"race_name\": \"The Great Race\",\n                \"distance_f\": \"1m 2f\",\n                \"runners\": [\n                    {\n                        \"horse\": \"Speedy Steed\",\n                        \"number\": 1,\n                        \"jockey\": \"T. Rider\",\n                        \"trainer\": \"A. Trainer\",\n                        \"odds\": [{\"odds_decimal\": \"5.50\"}]\n                    },\n                    {\n                        \"horse\": \"Gallant Gus\",\n                        \"number\": 2,\n                        \"jockey\": \"J. Jockey\",\n                        \"trainer\": \"B. Builder\",\n                        \"odds\": [{\"odds_decimal\": \"3.25\"}]\n                    }\n                ]\n            }\n        ]\n    }\n    mock_make_request.return_value = mock_api_response\n\n    # ACT\n    result = await adapter.fetch_races(today, AsyncMock())\n\n    # ASSERT\n    assert result is not None\n    assert result['source_info']['status'] == 'SUCCESS'\n    assert result['source_info']['races_fetched'] == 1\n\n    races = result['races']\n    assert len(races) == 1\n\n    race = races[0]\n    assert race.id == 'tra_12345'\n    assert race.venue == \"Newbury\"\n    assert race.race_number == 3\n    assert race.race_name == \"The Great Race\"\n    assert race.distance == \"1m 2f\"\n\n    assert len(race.runners) == 2\n\n    runner1 = race.runners[0]\n    assert runner1.name == \"Speedy Steed\"\n    assert runner1.number == 1\n    assert runner1.jockey == \"T. Rider\"\n    assert runner1.trainer == \"A. Trainer\"\n    assert runner1.odds[adapter.source_name].win == Decimal(\"5.50\")\n\n@pytest.mark.asyncio\n@patch('python_service.adapters.the_racing_api_adapter.TheRacingApiAdapter.make_request', new_callable=AsyncMock)\nasync def test_fetch_races_handles_empty_response(mock_make_request, mock_config):\n    \"\"\"\n    Tests that the adapter handles an API response with no racecards.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=mock_config)\n    today = date.today().strftime('%Y-%m-%d')\n    mock_make_request.return_value = {\"racecards\": []}\n\n    # ACT\n    result = await adapter.fetch_races(today, AsyncMock())\n\n    # ASSERT\n    assert result is not None\n    assert result['source_info']['status'] == 'SUCCESS'\n    assert result['source_info']['races_fetched'] == 0\n    assert result['source_info']['error_message'] == \"No racecards found in API response.\"\n    assert len(result['races']) == 0\n\n@pytest.mark.asyncio\nasync def test_fetch_races_handles_auth_failure(mock_config_no_key):\n    \"\"\"\n    Tests that the adapter returns a configuration error if the API key is not set.\n    \"\"\"\n    # ARRANGE\n    adapter = TheRacingApiAdapter(config=mock_config_no_key)\n    today = date.today().strftime('%Y-%m-%d')\n\n    # ACT\n    result = await adapter.fetch_races(today, AsyncMock())\n\n    # ASSERT\n    assert result is not None\n    assert result['source_info']['status'] == 'FAILED'\n    assert result['source_info']['races_fetched'] == 0\n    assert result['source_info']['error_message'] == \"ConfigurationError: THE_RACING_API_KEY not set\"\n    assert len(result['races']) == 0",
    "tests/test_analyzer.py": "import pytest\nfrom decimal import Decimal\nfrom datetime import datetime\nfrom python_service.models import Race, Runner, OddsData\nfrom python_service.analyzer import AnalyzerEngine, TrifectaAnalyzer, _get_best_win_odds\n\n# Helper to create runners for tests\ndef create_runner(number, odds_val=None, scratched=False):\n    odds_data = {}\n    if odds_val:\n        odds_data[\"TestOdds\"] = OddsData(win=Decimal(str(odds_val)), source=\"TestOdds\", last_updated=datetime.now())\n    return Runner(number=number, name=f\"Runner {number}\", odds=odds_data, scratched=scratched)\n\n@pytest.fixture\ndef sample_races_for_true_trifecta():\n    \"\"\"Provides a list of sample Race objects for the new 'True Trifecta' logic.\"\"\"\n    return [\n        # Race 1: Should PASS all criteria, will have a lower score\n        Race(\n            id=\"race_pass_1\", venue=\"Test Park\", race_number=1, start_time=datetime.now(), source=\"Test\",\n            runners=[\n                create_runner(1, 3.0), # Favorite\n                create_runner(2, 4.5), # Second Favorite\n                create_runner(3, 5.0),\n            ]\n        ),\n        # Race 2: Should FAIL (Field size too large)\n        Race(\n            id=\"race_fail_field_size\", venue=\"Test Park\", race_number=2, start_time=datetime.now(), source=\"Test\",\n            runners=[create_runner(i, 5.0 + i) for i in range(1, 12)] # 11 runners\n        ),\n        # Race 3: Should FAIL (Favorite odds too low)\n        Race(\n            id=\"race_fail_fav_odds\", venue=\"Test Park\", race_number=3, start_time=datetime.now(), source=\"Test\",\n            runners=[create_runner(1, 2.0), create_runner(2, 4.5)]\n        ),\n        # Race 4: Should FAIL (Second favorite odds too low)\n        Race(\n            id=\"race_fail_2nd_fav_odds\", venue=\"Test Park\", race_number=4, start_time=datetime.now(), source=\"Test\",\n            runners=[create_runner(1, 3.0), create_runner(2, 3.5)]\n        ),\n        # Race 5: Should also PASS and have a higher score than race_pass_1\n        Race(\n            id=\"race_pass_2\", venue=\"Test Park\", race_number=5, start_time=datetime.now(), source=\"Test\",\n            runners=[\n                create_runner(1, 4.0), # Favorite\n                create_runner(2, 6.0), # Second Favorite\n                create_runner(3, 8.0),\n                create_runner(4, 12.0),\n                create_runner(5, 15.0),\n            ]\n        ),\n    ]\n\ndef test_analyzer_engine_discovery():\n    \"\"\"Tests that the AnalyzerEngine correctly discovers the TrifectaAnalyzer.\"\"\"\n    engine = AnalyzerEngine()\n    assert 'trifecta' in engine.analyzers\n    assert engine.analyzers['trifecta'] == TrifectaAnalyzer\n\ndef test_analyzer_engine_get_analyzer():\n    \"\"\"Tests that the AnalyzerEngine can instantiate a specific analyzer.\"\"\"\n    engine = AnalyzerEngine()\n    analyzer = engine.get_analyzer('trifecta', max_field_size=8)\n    assert isinstance(analyzer, TrifectaAnalyzer)\n    assert analyzer.max_field_size == 8\n\ndef test_analyzer_engine_get_nonexistent_analyzer():\n    \"\"\"Tests that requesting a non-existent analyzer raises a ValueError.\"\"\"\n    engine = AnalyzerEngine()\n    with pytest.raises(ValueError, match=\"Analyzer 'nonexistent' not found.\"):\n        engine.get_analyzer('nonexistent')\n\ndef test_trifecta_analyzer_plugin_logic(sample_races_for_true_trifecta):\n    \"\"\"\n    Tests the TrifectaAnalyzer's scoring, sorting, and new response structure.\n    \"\"\"\n    engine = AnalyzerEngine()\n    analyzer = engine.get_analyzer('trifecta')  # Use default criteria\n\n    result = analyzer.qualify_races(sample_races_for_true_trifecta)\n\n    # 1. Verify the new response structure\n    assert isinstance(result, dict)\n    assert \"criteria\" in result\n    assert \"races\" in result\n    assert result['criteria']['max_field_size'] == 10\n\n    qualified_races = result['races']\n\n    # 2. Check that the correct number of races were qualified\n    assert len(qualified_races) == 2\n\n    # 3. Check that the scores have been assigned and are valid numbers\n    assert qualified_races[0].qualification_score is not None\n    assert qualified_races[1].qualification_score is not None\n    assert isinstance(qualified_races[0].qualification_score, float)\n\n    # 4. Check that the races are sorted by score in descending order\n    assert qualified_races[0].qualification_score > qualified_races[1].qualification_score\n    assert qualified_races[0].id == \"race_pass_2\"  # This race should have the higher score\n    assert qualified_races[1].id == \"race_pass_1\"\n\ndef test_get_best_win_odds_helper():\n    \"\"\"Tests the helper function for finding the best odds.\"\"\"\n    runner_with_odds = create_runner(1)\n    runner_with_odds.odds = {\n        \"SourceA\": OddsData(win=Decimal(\"3.0\"), source=\"A\", last_updated=datetime.now()),\n        \"SourceB\": OddsData(win=Decimal(\"2.5\"), source=\"B\", last_updated=datetime.now()),\n    }\n    assert _get_best_win_odds(runner_with_odds) == Decimal(\"2.5\")\n\n    runner_no_odds = create_runner(2)\n    assert _get_best_win_odds(runner_no_odds) is None\n\n    runner_no_win = create_runner(3)\n    runner_no_win.odds = {\"SourceA\": OddsData(win=None, source=\"A\", last_updated=datetime.now())}\n    assert _get_best_win_odds(runner_no_win) is None\n\n# Test case added by Operation: Resurrect and Modernize\nfrom python_service.models import Race, Runner\nimport datetime\n\ndef test_trifecta_analyzer_rejects_races_with_too_few_runners(trifecta_analyzer):\n    \"\"\"Ensure analyzer rejects races with < 3 runners for a trifecta.\"\"\"\n    race_with_two_runners = Race(\n        id='test_race_123',\n        venue='TEST',\n        race_number=1,\n        start_time=datetime.datetime.now(),\n        runners=[\n            Runner(number=1, name='Horse A', odds='2/1', scratched=False),\n            Runner(number=2, name='Horse B', odds='3/1', scratched=False)\n        ],\n        source='test'\n    )\n\n    is_qualified = trifecta_analyzer.is_race_qualified(race_with_two_runners)\n    assert not is_qualified, 'Trifecta analyzer should not qualify a race with only two runners.'\n",
    "tests/test_api.py": "# tests/test_api.py\nimport pytest\nimport aiosqlite\nfrom unittest.mock import patch, AsyncMock\nfrom datetime import datetime, date\nfrom decimal import Decimal\n\nfrom python_service.models import Race, Runner, OddsData, TipsheetRace\n\n# Note: The 'client' fixture is automatically available from tests/conftest.py\n\n@pytest.mark.asyncio\n@patch('python_service.engine.FortunaEngine.get_races', new_callable=AsyncMock)\nasync def test_get_races_endpoint_success(mock_get_races, client):\n    \"\"\"\n    SPEC: The /api/races endpoint should return data with a valid API key.\n    \"\"\"\n    # ARRANGE\n    today = date.today()\n    now = datetime.now()\n    mock_response_data = {\n        \"races\": [],\n        \"source_info\": []\n    }\n    mock_get_races.return_value = mock_response_data\n    headers = {\"X-API-Key\": \"test_api_key\"}\n\n    # ACT\n    response = client.get(f\"/api/races?date={today.isoformat()}\", headers=headers)\n\n    # ASSERT\n    assert response.status_code == 200\n    mock_get_races.assert_awaited_once()\n\nfrom fastapi.testclient import TestClient\n\n@pytest.mark.asyncio\nasync def test_get_tipsheet_endpoint_success(tmp_path):\n    \"\"\"\n    SPEC: The /api/tipsheet endpoint should return a list of tipsheet races from the database.\n    \"\"\"\n    db_path = tmp_path / \"test.db\"\n    post_time = datetime.now()\n\n    with patch('python_service.api.DB_PATH', db_path):\n        from python_service.api import app\n        with TestClient(app) as client:\n            async with aiosqlite.connect(db_path) as db:\n                await db.execute(\"\"\"\n                    CREATE TABLE tipsheet (\n                        race_id TEXT PRIMARY KEY,\n                        track_name TEXT,\n                        race_number INTEGER,\n                        post_time TEXT,\n                        score REAL,\n                        factors TEXT\n                    )\n                \"\"\")\n                await db.execute(\n                    \"INSERT INTO tipsheet VALUES (?, ?, ?, ?, ?, ?)\",\n                    (\"test_race_1\", \"Test Park\", 1, post_time.isoformat(), 85.5, \"{}\")\n                )\n                await db.commit()\n\n            # ACT\n            response = client.get(f\"/api/tipsheet?date={post_time.date().isoformat()}\")\n\n            # ASSERT\n            assert response.status_code == 200\n            response_data = response.json()\n            assert len(response_data) == 1\n            assert response_data[0][\"raceId\"] == \"test_race_1\"\n            assert response_data[0][\"score\"] == 85.5\n\n# --- Tests resurrected by Operation: The Great Resurrection ---\n\nfrom fastapi.testclient import TestClient\nfrom python_service.api import app\n\nclient = TestClient(app)\n\ndef test_health_check_unauthenticated():\n    \"\"\"Ensures the /health endpoint is accessible without an API key.\"\"\"\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    json_response = response.json()\n    assert json_response[\"status\"] == \"ok\"\n    assert \"timestamp\" in json_response\n\ndef test_api_key_authentication_failure():\n    \"\"\"Ensures that endpoints are protected and fail with an invalid API key.\"\"\"\n    response = client.get(\"/api/races/qualified/trifecta\", headers={\"X-API-KEY\": \"invalid_key\"})\n    assert response.status_code == 403\n    assert response.json() == {\"detail\": \"Invalid or missing API Key\"}\n\ndef test_api_key_authentication_missing():\n    \"\"\"Ensures that endpoints are protected and fail with a missing API key.\"\"\"\n    response = client.get(\"/api/races/qualified/trifecta\")\n    assert response.status_code == 403\n    assert response.json() == {\"detail\": \"Not authenticated\"}\n",
    "tests/test_engine.py": "import pytest\nfrom unittest.mock import AsyncMock, patch\nfrom datetime import datetime, date\nfrom decimal import Decimal\nimport fakeredis.aioredis\n\nfrom python_service.models import Race, Runner, OddsData\nfrom python_service.engine import OddsEngine\nfrom python_service.config import get_settings\nfrom python_service.adapters.base import BaseAdapter\n\ndef create_mock_race(source: str, venue: str, race_number: int, start_time: datetime, runners_data: list) -> Race:\n    \"\"\"Helper function to create a Race object for testing.\"\"\"\n    runners = []\n    for r_data in runners_data:\n        odds = {source: OddsData(win=Decimal(r_data[\"odds\"]), source=source, last_updated=datetime.now())}\n        runners.append(Runner(number=r_data[\"number\"], name=r_data[\"name\"], odds=odds))\n\n    return Race(\n        id=f\"test_{source}_{race_number}\",\n        venue=venue,\n        race_number=race_number,\n        start_time=start_time,\n        runners=runners,\n        source=source\n    )\n\n@pytest.fixture\ndef mock_engine() -> OddsEngine:\n    \"\"\"Provides an OddsEngine instance with a mock config.\"\"\"\n    return OddsEngine(config=get_settings())\n\n@pytest.mark.asyncio\n@patch('python_service.engine.OddsEngine._time_adapter_fetch', new_callable=AsyncMock)\nasync def test_engine_deduplicates_races_and_merges_odds(mock_time_adapter_fetch, mock_engine):\n    \"\"\"\n    SPEC: The OddsEngine's fetch_all_odds method should identify duplicate races\n    from different sources and merge their runner data, stacking the odds.\n    \"\"\"\n    # ARRANGE\n    test_time = datetime(2025, 10, 9, 14, 30)\n\n    source_a_race = create_mock_race(\"SourceA\", \"Test Park\", 1, test_time, [\n        {\"number\": 1, \"name\": \"Speedy\", \"odds\": \"5.0\"},\n        {\"number\": 2, \"name\": \"Steady\", \"odds\": \"10.0\"},\n    ])\n    source_b_race = create_mock_race(\"SourceB\", \"Test Park\", 1, test_time, [\n        {\"number\": 1, \"name\": \"Speedy\", \"odds\": \"5.5\"},\n        {\"number\": 3, \"name\": \"Newcomer\", \"odds\": \"15.0\"},\n    ])\n    other_race = create_mock_race(\"SourceC\", \"Another Place\", 2, test_time, [\n        {\"number\": 1, \"name\": \"Solo\", \"odds\": \"3.0\"}\n    ])\n\n    mock_time_adapter_fetch.side_effect = [\n        (\"SourceA\", {'races': [source_a_race], 'source_info': {'name': 'SourceA', 'status': 'SUCCESS', 'races_fetched': 1}}, 1.0),\n        (\"SourceB\", {'races': [source_b_race], 'source_info': {'name': 'SourceB', 'status': 'SUCCESS', 'races_fetched': 1}}, 1.0),\n        (\"SourceC\", {'races': [other_race], 'source_info': {'name': 'SourceC', 'status': 'SUCCESS', 'races_fetched': 1}}, 1.0),\n    ]\n\n    # ACT\n    today_str = date.today().strftime('%Y-%m-%d')\n    result = await mock_engine.fetch_all_odds(today_str)\n\n    # ASSERT\n    assert len(result['races']) == 2, \"Engine should have de-duplicated the races.\"\n\n    merged_race = next((r for r in result['races'] if r['venue'] == \"Test Park\"), None)\n    assert merged_race is not None, \"Merged race should be present in the results.\"\n    assert len(merged_race['runners']) == 3, \"Merged race should contain all unique runners.\"\n\n    runner1 = next((r for r in merged_race['runners'] if r['number'] == 1), None)\n    assert runner1 is not None\n    assert \"SourceA\" in runner1['odds']\n    assert \"SourceB\" in runner1['odds']\n    assert runner1['odds']['SourceA']['win'] == Decimal(\"5.0\")\n    assert runner1['odds']['SourceB']['win'] == Decimal(\"5.5\")\n\n    runner2 = next((r for r in merged_race['runners'] if r['number'] == 2), None)\n    assert runner2 is not None\n    assert \"SourceA\" in runner2['odds'] and \"SourceB\" not in runner2['odds']\n\n    runner3 = next((r for r in merged_race['runners'] if r['number'] == 3), None)\n    assert runner3 is not None\n    assert \"SourceB\" in runner3['odds'] and \"SourceA\" not in runner3['odds']\n\n\n@pytest.mark.asyncio\n@patch('python_service.engine.redis.from_url')\nasync def test_engine_caching_logic(mock_redis_from_url):\n    \"\"\"\n    SPEC: The OddsEngine should cache results in Redis.\n    1. On a cache miss, it should fetch from adapters and set the cache.\n    2. On a cache hit, it should return data from the cache without fetching from adapters.\n    \"\"\"\n    # ARRANGE\n    mock_redis_client = fakeredis.aioredis.FakeRedis(decode_responses=True)\n    mock_redis_from_url.return_value = mock_redis_client\n    await mock_redis_client.flushall()\n\n    engine = OddsEngine(config=get_settings())\n\n    today_str = date.today().strftime('%Y-%m-%d')\n    cache_key = f\"fortuna:races:{today_str}\"\n    test_time = datetime(2025, 10, 9, 15, 0)\n\n    mock_race = create_mock_race(\"TestSource\", \"Cache Park\", 1, test_time, [\n        {\"number\": 1, \"name\": \"Cachedy\", \"odds\": \"4.0\"}\n    ])\n\n    # Replace the engine's adapters with a single mock to isolate the test\n    mock_adapter = AsyncMock(spec=BaseAdapter)\n    mock_adapter.source_name = \"TestSource\"\n    mock_adapter.fetch_races.return_value = {\n        'races': [mock_race],\n        'source_info': {'name': 'TestSource', 'status': 'SUCCESS', 'races_fetched': 1}\n    }\n    engine.adapters = [mock_adapter]\n\n\n    # --- ACT 1: Cache Miss ---\n    result_miss = await engine.fetch_all_odds(today_str)\n\n    # --- ASSERT 1: Cache Miss ---\n    mock_adapter.fetch_races.assert_called_once()\n    cached_value = await mock_redis_client.get(cache_key)\n    assert cached_value is not None\n    assert len(result_miss['races']) == 1\n    assert result_miss['races'][0]['venue'] == \"Cache Park\"\n\n\n    # --- ACT 2: Cache Hit ---\n    mock_adapter.fetch_races.reset_mock()\n    result_hit = await engine.fetch_all_odds(today_str)\n\n    # --- ASSERT 2: Cache Hit ---\n    mock_adapter.fetch_races.assert_not_called()\n    assert len(result_hit['races']) == 1\n    assert result_hit['races'][0]['venue'] == \"Cache Park\"\n\n    assert result_hit['races'] == result_miss['races']\n    assert result_hit['sources'] == result_miss['sources']\n\n    await engine.close()",
    "uninstall_service.bat": "@echo off\nREM Stops and removes the Fortuna Faucet Windows Service.\n\necho Uninstalling Fortuna Faucet Windows Service...\n\nREM Activate venv to ensure python command works as expected\ncall .venv\\Scripts\\activate.bat\n\nREM Stop and remove the service\npython windows_service.py stop\npython windows_service.py remove\n\necho.\necho Service stopped and uninstalled successfully!\npause\n",
    "windows_service.py": "# windows_service.py\nimport win32serviceutil\nimport win32service\nimport win32event\nimport servicemanager\nimport socket\nimport sys\nimport os\nimport subprocess\nfrom pathlib import Path\n\nclass FortunaBackendService(win32serviceutil.ServiceFramework):\n    _svc_name_ = \"FortunaFaucetBackend\"\n    _svc_display_name_ = \"Fortuna Faucet Racing Analysis Service\"\n    _svc_description_ = \"Background service for continuous racing data monitoring.\"\n\n    def __init__(self, args):\n        win32serviceutil.ServiceFramework.__init__(self, args)\n        self.stop_event = win32event.CreateEvent(None, 0, 0, None)\n        self.backend_process = None\n        socket.setdefaulttimeout(60)\n\n    def SvcStop(self):\n        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)\n        win32event.SetEvent(self.stop_event)\n        if self.backend_process:\n            self.backend_process.terminate()\n\n    def SvcDoRun(self):\n        servicemanager.LogMsg(servicemanager.EVENTLOG_INFORMATION_TYPE, servicemanager.PYS_SERVICE_STARTED, (self._svc_name_, ''))\n        self.main()\n\n    def main(self):\n        install_dir = Path(__file__).parent.resolve()\n        venv_python = install_dir / \".venv\" / \"Scripts\" / \"python.exe\"\n        api_module_dir = install_dir / \"python_service\"\n\n        env = os.environ.copy()\n        env_file = install_dir / \".env\"\n        if env_file.exists():\n            with open(env_file) as f:\n                for line in f:\n                    if '=' in line and not line.startswith('#'):\n                        key, value = line.strip().split('=', 1)\n                        env[key] = value.strip('\\\"')\n\n        self.backend_process = subprocess.Popen(\n            [str(venv_python), \"-m\", \"uvicorn\", \"api:app\", \"--host\", \"127.0.0.1\", \"--port\", \"8000\"],\n            cwd=str(api_module_dir),\n            env=env\n        )\n\n        win32event.WaitForSingleObject(self.stop_event, win32event.INFINITE)\n\nif __name__ == '__main__':\n    if len(sys.argv) == 1:\n        servicemanager.Initialize()\n        servicemanager.PrepareToHostSingle(FortunaBackendService)\n        servicemanager.StartServiceCtrlDispatcher()\n    else:\n        win32serviceutil.HandleCommandLine(FortunaBackendService)\n"
}