{
    "filepath": "./paddock-parser-ng/src/paddock_parser/pipeline.py",
    "content": "import inspect\nimport logging\nimport asyncio\nfrom datetime import datetime\n\nfrom . import adapters\nfrom .analysis.scorer import RaceScorer\nfrom .adapters.base import BaseAdapter, BaseAdapterV3\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\n\ndef load_adapters():\n    \"\"\"\n    Dynamically loads all adapter classes from the adapters module.\n    \"\"\"\n    adapter_classes = []\n    for name, obj in inspect.getmembers(adapters, inspect.isclass):\n        if issubclass(obj, (BaseAdapter, BaseAdapterV3)) and obj not in (BaseAdapter, BaseAdapterV3):\n            adapter_classes.append(obj)\n    return adapter_classes\n\n\nasync def run_analysis_pipeline(args):\n    \"\"\"\n    Orchestrates the end-to-end pipeline for fetching, parsing, and scoring races.\n    \"\"\"\n    logging.info(\"--- Paddock Parser NG Pipeline Start ---\")\n\n    all_races = []\n    adapter_classes = load_adapters()\n    logging.info(f\"Found {len(adapter_classes)} adapters to run.\")\n\n    for adapter_class in adapter_classes:\n        adapter = adapter_class()\n        logging.info(f\"\\nRunning adapter: {adapter.SOURCE_ID}...\")\n\n        try:\n            normalized_races = []\n            if isinstance(adapter, BaseAdapterV3):\n                # V3 adapters have an async fetch method\n                races = await adapter.fetch()\n                normalized_races.extend(races)\n            elif isinstance(adapter, BaseAdapter):\n                # V1/V2 adapters have sync fetch_data/parse_data methods\n                raw_data = adapter.fetch_data()\n                normalized_races = adapter.parse_data(raw_data)\n\n            if normalized_races:\n                logging.info(f\"Parsed {len(normalized_races)} races from {adapter.SOURCE_ID}.\")\n                all_races.extend(normalized_races)\n            else:\n                logging.warning(f\"No races parsed for {adapter.SOURCE_ID}.\")\n\n        except Exception as e:\n            logging.error(f\"Adapter {adapter.SOURCE_ID} failed: {e}\", exc_info=True)\n            continue\n\n    if not all_races:\n        logging.info(\"\\nNo races were successfully parsed from any source.\")\n        logging.info(\"--- Pipeline End ---\")\n        return\n\n    # Filter races based on field size\n    if args.min_field_size > 1:\n        all_races = [r for r in all_races if r.number_of_runners and r.number_of_runners >= args.min_field_size]\n    if args.max_field_size:\n        all_races = [r for r in all_races if r.number_of_runners and r.number_of_runners <= args.max_field_size]\n\n    # Score the collected races\n    if not args.no_odds_mode:\n        logging.info(f\"\\nScoring {len(all_races)} races...\")\n        scorer = RaceScorer()\n        scored_races = []\n        for race in all_races:\n            score = scorer.score(race)\n            if score >= args.min_score:\n                scored_races.append({\"race\": race, \"score\": score})\n    else:\n        logging.info(\"\\n--no-odds-mode enabled, skipping scoring.\")\n        scored_races = [{\"race\": race, \"score\": 0} for race in all_races]\n\n    # Sort the results\n    logging.info(f\"Sorting results by {args.sort_by}...\")\n    reverse_sort = True\n    if args.sort_by == 'score':\n        sort_key = lambda x: x['score']\n    elif args.sort_by == 'field_size':\n        sort_key = lambda x: x['race'].number_of_runners or 0\n    elif args.sort_by == 'time':\n        reverse_sort = False\n        sort_key = lambda x: x['race'].post_time if x['race'].post_time else datetime.max\n    else:\n        logging.warning(f\"Invalid sort key '{args.sort_by}'. Defaulting to sort by score.\")\n        sort_key = lambda x: x['score']\n\n    sorted_races = sorted(scored_races, key=sort_key, reverse=reverse_sort)\n\n    # Limit the results\n    limited_races = sorted_races[:args.limit]\n\n    # Display the results\n    logging.info(f\"\\n--- Top {args.limit} Scored Races ---\")\n    for i, result in enumerate(limited_races):\n        race = result['race']\n        score = result['score']\n        logging.info(\n            f\"{i+1}. \"\n            f\"Track: {race.track_name}, \"\n            f\"Race: {race.race_number}, \"\n            f\"Runners: {race.number_of_runners}, \"\n            f\"Score: {score:.2f}\"\n        )\n\n    logging.info(\"\\n--- Pipeline End ---\")\n"
}