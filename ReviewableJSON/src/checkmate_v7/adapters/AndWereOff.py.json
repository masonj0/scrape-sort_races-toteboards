{
    "filepath": "./src/checkmate_v7/adapters/AndWereOff.py",
    "content": "# src/checkmate_v7/adapters/AndWereOff.py\n\nimport logging\nimport re\nfrom datetime import date, datetime, timezone\nfrom typing import List, Optional, Dict\nfrom io import StringIO\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom ..base import BaseAdapterV7, DefensiveFetcher\nfrom ..models import Race, Runner\nfrom ..settings import settings\n\ndef _convert_odds_to_float(odds_str: Optional[str]) -> Optional[float]:\n    if not odds_str or not isinstance(odds_str, str): return None\n    odds_str = odds_str.strip().upper()\n    if odds_str in ['SP', 'SCRATCHED']: return None\n    if odds_str in ['EVS', 'EVENS']: return 2.0\n    if '/' in odds_str:\n        try:\n            num, den = map(int, odds_str.split('/'))\n            return (num / den) + 1.0 if den != 0 else None\n        except (ValueError, ZeroDivisionError): return None\n    try: return float(odds_str)\n    except (ValueError, TypeError): return None\n\nclass SkySportsAdapter(BaseAdapterV7):\n    SOURCE_ID = \"skysports\"\n    BASE_URL = \"https://www.skysports.com\"\n\n    def fetch_races(self) -> List[Race]:\n        index_url = f\"{self.BASE_URL}/racing/racecards\"\n        index_html = self.fetcher.get(index_url, response_type='text')\n        if not index_html: return []\n        soup = BeautifulSoup(index_html, \"lxml\")\n        race_urls = [f\"{self.BASE_URL}{link['href']}\" for link in soup.select(\"a.sdc-site-racing-meetings__event-link[href]\")]\n        all_races = []\n        for url in race_urls[:5]: # Limit for speed\n            detail_html = self.fetcher.get(url, response_type='text')\n            if detail_html:\n                race = self._parse_race_details(detail_html, url)\n                if race: all_races.append(race)\n        return all_races\n\n    def _parse_race_details(self, html: str, url: str) -> Optional[Race]:\n        soup = BeautifulSoup(html, \"lxml\")\n        track_name = soup.select_one(\"h1.sdc-site-racing-header__title\").text.strip()\n        post_time_str = soup.select_one(\"span.sdc-site-racing-header__time\").text.strip()\n        post_time = datetime.combine(date.today(), datetime.strptime(post_time_str, \"%H:%M\").time())\n        runners = [Runner(name=item.select_one(\"h4 a\").text.strip(), program_number=int(item.select_one(\"div strong\").text.strip()), odds=_convert_odds_to_float(item.select_one(\".sdc-site-racing-card__betting-odds\").text.strip())) for item in soup.select(\"div.sdc-site-racing-card__item\") if item.select_one(\"h4 a\")]\n        if not runners: return None\n        return Race(race_id=f\"{self.SOURCE_ID}_{url.split('/')[-1]}\", track_name=track_name, post_time=post_time, runners=[r for r in runners if r.odds])\n\nclass AtTheRacesAdapter(BaseAdapterV7):\n    SOURCE_ID = \"attheraces\"\n    BASE_URL = \"https://www.attheraces.com\"\n\n    def fetch_races(self) -> List[Race]:\n        index_html = self.fetcher.get(f\"{self.BASE_URL}/racecards\", response_type='text')\n        if not index_html: return []\n        soup = BeautifulSoup(index_html, 'html.parser')\n        links = [{\"url\": self.BASE_URL + a['href'], \"track\": a.find_previous(\"h2\").text.strip().replace(\" Racecards\",\"\"), \"time\": a.select_one(\"span.h7\").text.strip()[:5]} for a in soup.select(\"a.a--plain[href*='/racecard/']\")]\n        all_races = []\n        for link in links[:5]:\n            html = self.fetcher.get(link[\"url\"], response_type='text')\n            if html:\n                race = self._parse_single_race(html, link)\n                if race: all_races.append(race)\n        return all_races\n\n    def _parse_single_race(self, html: str, details: Dict) -> Optional[Race]:\n        soup = BeautifulSoup(html, 'html.parser')\n        runners = [Runner(name=card.select_one(\".horse-name a\").text.strip(), program_number=int(card.select_one(\".runner-number\").text.strip()), odds=_convert_odds_to_float(card.select_one(\".odds\").text.strip())) for card in soup.select(\"div.runner-card\") if card.select_one(\".horse-name a\")]\n        if not runners: return None\n        return Race(race_id=f'{self.SOURCE_ID}_{details[\"url\"].split(\"/\")[-2]}_{details[\"url\"].split(\"/\")[-1]}', track_name=details['track'], runners=[r for r in runners if r.odds])\n\nclass BetfairDataScientistAdapter(BaseAdapterV7):\n    \"\"\"\n    Production adapter for Betfair Data Scientist API.\n    Fetches CSV data and converts to standardized Race objects.\n    \"\"\"\n    SOURCE_ID = \"betfair_data_scientist\"\n    BASE_URL = \"https://betfair-data-supplier.herokuapp.com/api/widgets/iggy-joey/datasets\"\n\n    def fetch_races(self) -> List[Race]:\n        \"\"\"Fetches and parses data from the Betfair Data Scientist API.\"\"\"\n        today = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n        url = f\"{self.BASE_URL}/?date={today}&presenter=RatingsPresenter&csv=true\"\n        logging.info(f\"Fetching Betfair CSV data from: {url}\")\n\n        csv_data = self.fetcher.get(url, response_type='text')\n        if not csv_data:\n            logging.warning(f\"{self.SOURCE_ID}: No CSV data returned.\")\n            return []\n\n        return self._parse_races(csv_data)\n\n    def _parse_races(self, csv_content: str) -> List[Race]:\n        \"\"\"Parses the CSV content from the API into a list of Race objects.\"\"\"\n        try:\n            data = StringIO(csv_content)\n            df = pd.read_csv(data, dtype={\"selection_id\": str})\n            df.rename(columns={\"meetings.races.runners.ratedPrice\": \"rating\"}, inplace=True)\n            df = df[[\"market_id\", \"selection_id\", \"rating\"]]\n\n            races = {}\n            for _, row in df.iterrows():\n                race_id = str(row[\"market_id\"])\n                if race_id not in races:\n                    races[race_id] = Race(\n                        race_id=race_id,\n                        track_name=\"Betfair Exchange\",\n                        race_number=None, # Not available in this data source\n                        runners=[],\n                        source=self.SOURCE_ID\n                    )\n\n                runner = Runner(\n                    name=str(row[\"selection_id\"]),\n                    program_number=None, # Not available in this data source\n                    odds=row[\"rating\"],\n                )\n                races[race_id].runners.append(runner)\n\n            return list(races.values())\n        except Exception as e:\n            logging.error(f\"{self.SOURCE_ID}: Failed to parse CSV data: {e}\", exc_info=True)\n            return []\n\nclass FanDuelApiAdapter(BaseAdapterV7):\n    SOURCE_ID = \"fanduel_api\"\n    API_URL = \"https://api.racing.fanduel.com/cosmo/v1/graphql\"\n    QUERY = {\"operationName\": \"GetRacingSchedule\", \"variables\": {\"input\": {\"product\": \"FAN_DUEL_RACING\", \"jurisdiction\": \"USA\"}}, \"query\": \"query GetRacingSchedule($input: RacingScheduleInput!) { racingSchedule(input: $input) { schedule { date tracks { id name races { id raceNumber postTime runners { id runnerNumber runnerName scratched } } } } } }\"}\n\n    def fetch_races(self) -> List[Race]:\n        data = self.fetcher.post(self.API_URL, json_data=self.QUERY, response_type='json')\n        if not data: return []\n        all_races = []\n        try:\n            for track in data.get(\"data\", {}).get(\"scheduleRaces\", []):\n                if not track: continue\n                track_name = track.get(\"id\", \"\").split(\"-\")[-1].replace(\"_\", \" \")\n                for race_info in track.get(\"races\", []):\n                    runners = [Runner(name=r.get(\"runnerName\"), program_number=r.get(\"programNumber\")) for r in race_info.get(\"runners\", []) if not r.get(\"scratched\")]\n                    all_races.append(Race(race_id=race_info.get(\"id\"), track_name=track_name, race_number=int(race_info.get(\"raceNumber\")), runners=runners))\n        except Exception as e: logging.error(f\"{self.SOURCE_ID}: Failed during parsing: {e}\")\n        return all_races\n\nclass TVGAdapter(BaseAdapterV7):\n    \"\"\"Adapter for the TVG.com mobile API.\"\"\"\n    SOURCE_ID = \"tvg\"\n    BASE_URL = \"https://mobile-api.tvg.com/api/mobile/races/today\"\n\n    def fetch_races(self) -> List[Race]:\n        \"\"\"Fetches today's races from the TVG mobile API.\"\"\"\n        logging.info(f\"Fetching races from {self.SOURCE_ID}\")\n        response_data = self.fetcher.get(self.BASE_URL, response_type='json')\n\n        if not response_data or 'races' not in response_data:\n            logging.warning(f\"{self.SOURCE_ID}: No 'races' key found in API response.\")\n            return []\n\n        return self._parse_races(response_data['races'])\n\n    def _parse_races(self, races_data: List[Dict]) -> List[Race]:\n        \"\"\"Parses the JSON race data into standardized Race objects.\"\"\"\n        all_races = []\n        for race_info in races_data:\n            try:\n                runners = []\n                for runner_info in race_info.get('runners', []):\n                    if runner_info.get('scratched'):\n                        continue\n\n                    odds_val = self._parse_odds(runner_info.get('odds'))\n                    if odds_val is None:\n                        continue # Skip runners without valid odds\n\n                    runners.append(Runner(\n                        name=runner_info.get('horseName', 'Unknown Horse'),\n                        program_number=runner_info.get('programNumber'),\n                        odds=odds_val\n                    ))\n\n                if not runners:\n                    continue\n\n                post_time = self._parse_time(race_info.get('postTime'))\n\n                race = Race(\n                    race_id=f\"tvg_{race_info.get('raceId')}\",\n                    track_name=race_info.get('trackName', 'Unknown Track'),\n                    race_number=race_info.get('raceNumber'),\n                    post_time=post_time,\n                    runners=runners,\n                    number_of_runners=len(runners),\n                    source=self.SOURCE_ID\n                )\n                all_races.append(race)\n            except Exception as e:\n                logging.warning(f\"Skipping malformed TVG race due to error: {e}\")\n                continue\n        return all_races\n\n    def _parse_odds(self, odds_data: Optional[Dict]) -> Optional[float]:\n        \"\"\"Parses the odds structure from the TVG API.\"\"\"\n        if not odds_data or odds_data.get('morningLine') is None:\n            return None\n        try:\n            # TVG odds can be fractional \"N/D\" or decimal\n            odds_str = odds_data['morningLine']\n            if '/' in odds_str:\n                num, den = map(int, odds_str.split('/'))\n                return (num / den) + 1.0\n            return float(odds_str)\n        except (ValueError, TypeError, ZeroDivisionError):\n            return None\n\n    def _parse_time(self, time_str: Optional[str]) -> Optional[datetime]:\n        \"\"\"Parses ISO 8601 timestamp.\"\"\"\n        if not time_str: return None\n        try:\n            # Example: \"2025-09-26T20:30:00Z\"\n            return datetime.fromisoformat(time_str.replace('Z', '+00:00'))\n        except ValueError:\n            return None\n\nclass OddsAPIAdapter(BaseAdapterV7):\n    \"\"\"Adapter for the-odds-api.com, an odds aggregator.\"\"\"\n    SOURCE_ID = \"odds_api\"\n    BASE_URL = \"https://api.the-odds-api.com/v4/sports/horse-racing/odds\"\n\n    def __init__(self, fetcher: DefensiveFetcher):\n        super().__init__(fetcher)\n        self.api_key = settings.ODDS_API_KEY\n        if not self.api_key:\n            logging.warning(f\"{self.SOURCE_ID}: No API key provided. Adapter will be disabled.\")\n\n    def fetch_races(self) -> List[Race]:\n        \"\"\"Fetches races from The Odds API if an API key is configured.\"\"\"\n        if not self.api_key:\n            return []\n\n        logging.info(f\"Fetching races from {self.SOURCE_ID}\")\n        params = {\n            'apiKey': self.api_key,\n            'regions': 'uk,us,au', # uk, us, eu, au\n            'markets': 'h2h', # h2h is win market\n            'oddsFormat': 'decimal',\n            'dateFormat': 'iso'\n        }\n        param_string = '&'.join([f'{k}={v}' for k, v in params.items()])\n        full_url = f\"{self.BASE_URL}?{param_string}\"\n\n        response_data = self.fetcher.get(full_url, response_type='json')\n\n        if not isinstance(response_data, list):\n            logging.warning(f\"{self.SOURCE_ID}: API did not return a list of races. Check your API key and usage limits.\")\n            return []\n\n        return self._parse_races(response_data)\n\n    def _parse_races(self, data: List[Dict]) -> List[Race]:\n        \"\"\"Parses the JSON response from The Odds API.\"\"\"\n        all_races = []\n        for race_data in data:\n            try:\n                bookmakers = race_data.get('bookmakers', [])\n                if not bookmakers: continue\n\n                # Find the bookmaker with the most complete market\n                best_market = max(bookmakers, key=lambda b: len(b.get('markets', [{}])[0].get('outcomes', [])), default={})\n                outcomes = best_market.get('markets', [{}])[0].get('outcomes', [])\n\n                runners = []\n                for runner_info in outcomes:\n                    odds = runner_info.get('price')\n                    if odds is None: continue\n                    runners.append(Runner(\n                        name=runner_info.get('name'),\n                        odds=float(odds)\n                    ))\n\n                if not runners: continue\n\n                post_time = self._parse_time(race_data.get('commence_time'))\n\n                race = Race(\n                    race_id=f\"oddsapi_{race_data.get('id')}\",\n                    track_name=race_data.get('sport_title', 'Unknown Track'),\n                    race_number=None, # Not provided\n                    post_time=post_time,\n                    runners=runners,\n                    number_of_runners=len(runners),\n                    source=self.SOURCE_ID\n                )\n                all_races.append(race)\n            except Exception as e:\n                logging.warning(f\"Skipping malformed Odds-API race due to error: {e}\")\n                continue\n        return all_races\n\n    def _parse_time(self, time_str: Optional[str]) -> Optional[datetime]:\n        if not time_str: return None\n        try:\n            return datetime.fromisoformat(time_str.replace('Z', '+00:00'))\n        except ValueError:\n            return None\n\nclass BetfairExchangeAdapter(BaseAdapterV7):\n    \"\"\"Adapter for the Betfair Exchange public API.\"\"\"\n    SOURCE_ID = \"betfair_exchange\"\n    BASE_URL = \"https://ero.betfair.com/www/sports/exchange/readonly/v1/bymarket\"\n\n    def fetch_races(self) -> List[Race]:\n        \"\"\"Fetches live racing markets from the Betfair Exchange.\"\"\"\n        logging.info(f\"Fetching races from {self.SOURCE_ID}\")\n        params = {\n            'alt': 'json',\n            'marketProjection': 'COMPETITION,EVENT,EVENT_TYPE,RUNNER_DESCRIPTION,RUNNER_METADATA,MARKET_START_TIME',\n            'types': 'MARKET_STATE,MARKET_RATES,MARKET_DESCRIPTION,EVENT,RUNNER_DESCRIPTION,RUNNER_STATE,RUNNER_EXCHANGE_PRICES_BEST',\n            'filter': 'eventTypeIds:7', # EventTypeId 7 is Horse Racing\n        }\n        # The API uses query parameters, so we build the URL manually\n        param_string = '&'.join([f'{k}={v}' for k, v in params.items()])\n        full_url = f\"{self.BASE_URL}?{param_string}\"\n\n        response_data = self.fetcher.get(full_url, response_type='json')\n\n        if not response_data or 'eventTypes' not in response_data:\n            logging.warning(f\"{self.SOURCE_ID}: No 'eventTypes' key found in API response.\")\n            return []\n\n        return self._parse_races(response_data)\n\n    def _parse_races(self, data: Dict) -> List[Race]:\n        \"\"\"Parses the complex JSON structure from the Betfair API.\"\"\"\n        all_races = []\n        try:\n            # The data is nested deep within the response\n            event_types = data.get('eventTypes', [])\n            if not event_types: return []\n\n            horse_racing_events = event_types[0].get('eventNodes', [])\n\n            for event_node in horse_racing_events:\n                event = event_node.get('event', {})\n                market_nodes = event_node.get('marketNodes', [])\n\n                for market_node in market_nodes:\n                    market = market_node.get('market', {})\n                    if market.get('marketType') != 'WIN':\n                        continue\n\n                    runners = []\n                    for runner_data in market_node.get('runners', []):\n                        if runner_data.get('state', {}).get('status') != 'ACTIVE':\n                            continue\n\n                        # Extract best available odds\n                        odds = None\n                        available_to_back = runner_data.get('exchange', {}).get('availableToBack', [])\n                        if available_to_back:\n                            odds = available_to_back[0].get('price')\n\n                        if odds is None:\n                            continue\n\n                        runners.append(Runner(\n                            name=runner_data.get('description', {}).get('runnerName', 'Unknown Horse'),\n                            program_number=runner_data.get('sortPriority'),\n                            odds=float(odds)\n                        ))\n\n                    if not runners:\n                        continue\n\n                    post_time = self._parse_time(market.get('marketStartTime'))\n\n                    race = Race(\n                        race_id=f\"bf_{market.get('marketId')}\",\n                        track_name=event.get('venue', 'Betfair Track'),\n                        race_number=None, # Not easily available\n                        post_time=post_time,\n                        runners=runners,\n                        number_of_runners=len(runners),\n                        source=self.SOURCE_ID\n                    )\n                    all_races.append(race)\n        except Exception as e:\n            logging.error(f\"Error parsing Betfair data structure: {e}\", exc_info=True)\n        return all_races\n\n    def _parse_time(self, time_str: Optional[str]) -> Optional[datetime]:\n        \"\"\"Parses ISO 8601 timestamp.\"\"\"\n        if not time_str: return None\n        try:\n            # Example: \"2025-09-26T20:30:00.000Z\"\n            return datetime.fromisoformat(time_str.replace('Z', '+00:00'))\n        except ValueError:\n            return None"
}