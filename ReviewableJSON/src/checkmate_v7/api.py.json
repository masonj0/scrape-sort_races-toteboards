{
    "filepath": "./src/checkmate_v7/api.py",
    "content": "\"\"\"\nCheckmate V7: `api.py` - THE CONDUCTOR\n\"\"\"\nfrom fastapi import FastAPI, BackgroundTasks, HTTPException\nfrom . import services\nimport numpy as np\nfrom scipy.stats import wilcoxon\n\ndef percentile_bootstrap_ci(data, n_bootstrap=1000, ci_level=0.95):\n    \"\"\"Calculate percentile bootstrap confidence interval for the mean.\"\"\"\n    if len(data) < 2:\n        return (np.nan, np.nan)\n    bootstrap_means = []\n    for _ in range(n_bootstrap):\n        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n        bootstrap_means.append(np.mean(bootstrap_sample))\n\n    lower_bound = np.percentile(bootstrap_means, (1 - ci_level) / 2 * 100)\n    upper_bound = np.percentile(bootstrap_means, (1 + ci_level) / 2 * 100)\n    return (lower_bound, upper_bound)\n\ndef wilcoxon_p_value(data):\n    \"\"\"Perform a one-sample Wilcoxon signed-rank test.\"\"\"\n    if len(data) < 10: # Not enough data for a meaningful test\n        return np.nan\n    # Test if the mean of the data is significantly different from zero\n    statistic, p_value = wilcoxon(data)\n    return p_value\n\nfrom . import logging_config\n\napp = FastAPI()\n\n@app.on_event(\"startup\")\ndef on_startup():\n    \"\"\"\n    Configures logging and overrides Uvicorn's default loggers\n    to use the new structured JSON format on application startup.\n    \"\"\"\n    logging_config.setup_logging()\n\n    # Reconfigure Uvicorn's loggers to use our new handler\n    # This ensures that access logs and server errors are also in JSON format\n    loggers_to_override = [\"uvicorn\", \"uvicorn.error\", \"uvicorn.access\"]\n    root_handlers = logging.getLogger().handlers\n\n    for logger_name in loggers_to_override:\n        uvicorn_logger = logging.getLogger(logger_name)\n        uvicorn_logger.handlers = root_handlers\n        uvicorn_logger.propagate = False\n\n@app.get(\"/\")\ndef root():\n    return {\"message\": \"Checkmate V7 API is running.\"}\n\n@app.post(\"/races/process\", status_code=202)\ndef process_race(race_url: str, background_tasks: BackgroundTasks):\n    \"\"\"Dispatches a background job to process a race.\"\"\"\n    background_tasks.add_task(services.process_race_for_prediction, race_url)\n    return {\"message\": \"Race processing job accepted.\"}\n\nfrom .models import PerformanceMetricsSchema, JoinORM, PredictionORM, PredictionSchema\nfrom .services import get_db_session\n\nfrom sqlalchemy.exc import SQLAlchemyError\nfrom sqlalchemy import text\nimport logging\nfrom typing import List\nfrom datetime import datetime, timezone\n\n@app.get(\"/predictions/active\", response_model=List[PredictionSchema])\ndef get_active_predictions():\n    \"\"\"Returns all predictions with a 'pending' status.\"\"\"\n    session = get_db_session()\n    try:\n        pending_preds = session.query(PredictionORM).filter(PredictionORM.status == 'pending').all()\n\n        results = []\n        for pred in pending_preds:\n            pred_schema = PredictionSchema.from_orm(pred)\n            if pred.race_local_datetime:\n                # Assume race_local_datetime is a naive datetime representing UTC\n                post_time_utc = pred.race_local_datetime.replace(tzinfo=timezone.utc)\n                now_utc = datetime.now(timezone.utc)\n                minutes_to_post = (post_time_utc - now_utc).total_seconds() / 60\n                pred_schema.minutes_to_post = minutes_to_post\n            results.append(pred_schema)\n\n        return results\n    except SQLAlchemyError as e:\n        logging.error(\"Database error while fetching active predictions\", extra={\"error\": str(e)})\n        raise HTTPException(status_code=500, detail=\"Database error\")\n    except Exception as e:\n        logging.error(\"An unexpected error occurred while fetching active predictions\", extra={\"error\": str(e)})\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n    finally:\n        if session:\n            session.close()\n\nfrom .models import RaceDataSchema, HorseSchema, Race, BaseModel\nfrom .logic import TrifectaAnalyzer\nimport asyncio\nfrom typing import Optional\n\n# --- Pydantic Schemas for API Responses ---\nclass AdapterStatusSchema(BaseModel):\n    adapter_id: str\n    status: str\n    races_found: int\n    error_message: Optional[str] = None\n    notes: Optional[str] = None\n    last_run: str\n\n# --- API Endpoints ---\n\n@app.get(\"/api/v1/adapters/status\", response_model=List[AdapterStatusSchema])\nasync def get_adapter_status():\n    \"\"\"\n    Returns the real-time status of each data adapter in the system.\n    \"\"\"\n    orchestrator = services.DataSourceOrchestrator(session=get_db_session())\n    _, statuses = await orchestrator.get_races()\n    return statuses\n\n@app.get(\"/api/v1/races/all\", response_model=List[RaceDataSchema])\nasync def get_all_races():\n    \"\"\"\n    The workhorse endpoint for the application. Fetches all race data,\n    analyzes it, and returns the enriched data.\n    \"\"\"\n    orchestrator = services.DataSourceOrchestrator(session=get_db_session())\n    analyzer = TrifectaAnalyzer()\n\n    # 1. Fetch all raw race data\n    # get_races now returns a tuple: (races, statuses)\n    raw_races, _ = orchestrator.get_races()\n\n    enriched_races = []\n    for raw_race in raw_races:\n        # 2. Map the simple `Race` object to the rich `RaceDataSchema`\n        # This is a critical step. We provide default/placeholder values for\n        # fields that are not available from the basic adapters.\n        horses_for_schema = [\n            HorseSchema(\n                id=f\"{raw_race.race_id}-{r.program_number}\",\n                name=r.name,\n                number=r.program_number or 0,\n                jockey=r.jockey or \"N/A\",\n                trainer=r.trainer or \"N/A\",\n                odds=r.odds or 0.0,\n                morningLine=0.0, # Placeholder\n                speed=0,         # Placeholder\n                class_rating=0,  # Placeholder\n                form=\"\",         # Placeholder\n                lastRaced=\"\"     # Placeholder\n            ) for r in raw_race.runners\n        ]\n\n        race_data = RaceDataSchema(\n            id=raw_race.race_id,\n            track=raw_race.track_name,\n            raceNumber=raw_race.race_number or 0,\n            postTime=raw_race.post_time.isoformat() if raw_race.post_time else \"\",\n            horses=horses_for_schema,\n            conditions=raw_race.race_type or \"Unknown\", # Using race_type as conditions\n            distance=\"N/A\", # Placeholder\n            surface=\"N/A\"   # Placeholder\n        )\n\n        # 3. Use the new `TrifectaAnalyzer` to score and qualify each race\n        analysis_result = analyzer.analyze_race(race_data)\n\n        # 4. Add the analysis results to the schema object\n        race_data.checkmateScore = analysis_result[\"checkmateScore\"]\n        race_data.qualified = analysis_result[\"qualified\"]\n        race_data.trifectaFactors = analysis_result[\"trifectaFactors\"]\n\n        enriched_races.append(race_data)\n\n    # 5. Return the complete list of enriched race data\n    return enriched_races\n\n\n@app.post(\"/api/v1/actions/refresh\")\ndef refresh_data():\n    \"\"\"\n    An endpoint to acknowledge a data refresh action. In a real system,\n    this would trigger a background task. For now, it returns a simple\n    confirmation message.\n    \"\"\"\n    return {\n        \"status\": \"acknowledged\",\n        \"message\": \"A data refresh can be triggered by hitting the primary data endpoints.\"\n    }\n\n\n@app.get(\"/performance\", response_model=PerformanceMetricsSchema)\ndef get_performance():\n    \"\"\"Returns a statistically rigorous performance report.\"\"\"\n    session = get_db_session()\n    try:\n        joins = session.query(JoinORM).filter_by(audit_status='completed').all()\n\n        if not joins or len(joins) < 2:\n            return PerformanceMetricsSchema(\n                totalBets=len(joins) if joins else 0,\n                wins=0,\n                winRate=0,\n                roi=0,\n                profit=0,\n                confidenceInterval=[0, 0],\n                sampleSize=len(joins) if joins else 0\n            )\n\n        pnl_data = [j.pnl_native for j in joins]\n        roi_data = [j.roi for j in joins]\n\n        total_bets = len(joins)\n        total_wins = sum(1 for pnl in pnl_data if pnl > 0)\n        win_rate = (total_wins / total_bets) * 100\n        net_profit = sum(pnl_data)\n        total_staked = sum([j.stake_used for j in joins])\n        roi_percent = (net_profit / total_staked) * 100 if total_staked > 0 else 0\n\n        ci = percentile_bootstrap_ci(roi_data)\n        p_val = wilcoxon_p_value(pnl_data)\n\n        return PerformanceMetricsSchema(\n            total_bets=total_bets,\n            win_rate=win_rate,\n            roi_percent=roi_percent,\n            net_profit=net_profit,\n            confidence_interval=[ci[0], ci[1]],\n            p_value=p_val if not np.isnan(p_val) else None,\n            sample_size=total_bets\n        )\n    except SQLAlchemyError as e:\n        logging.error(\"Database error while fetching performance metrics\", extra={\"error\": str(e)})\n        raise HTTPException(status_code=500, detail=\"Database error\")\n    except Exception as e:\n        logging.error(\"An unexpected error occurred while fetching performance metrics\", extra={\"error\": str(e)})\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n    finally:\n        if session:\n            session.close()\n\nfrom .models import HealthCheckResponse\nimport redis\n\nfrom . import config\n\n@app.get(\"/health\", response_model=HealthCheckResponse)\ndef get_health():\n    \"\"\"Returns the health status of the application's critical services.\"\"\"\n\n    # Check database health\n    db_status = \"ok\"\n    try:\n        session = get_db_session()\n        session.execute(text(\"SELECT 1\"))\n        session.close()\n    except Exception as e:\n        db_status = f\"error: {e}\"\n\n    # Check Celery (Redis) health\n    celery_status = \"ok\"\n    try:\n        r = redis.Redis.from_url(config.REDIS_URL, socket_connect_timeout=1)\n        r.ping()\n    except Exception as e:\n        celery_status = f\"error: {e}\"\n\n    return HealthCheckResponse(\n        status=\"ok\" if db_status == \"ok\" and celery_status == \"ok\" else \"error\",\n        database=db_status,\n        celery=celery_status\n    )\n"
}