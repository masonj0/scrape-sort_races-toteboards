{
    "filepath": "./src/paddock_parser/pipeline.py",
    "content": "import inspect\nimport logging\nfrom typing import List, Optional, Dict, Tuple\n\nfrom . import adapters\nfrom .scorer import score_races\nfrom .base import BaseAdapter, BaseAdapterV3, NormalizedRace, NormalizedRunner\nfrom .merger import smart_merge\nfrom .models import Race, Runner\n\n# The TerminalUI class is forward-declared using a string to avoid circular import.\nif False:\n    from .ui.terminal_ui import TerminalUI\n\ndef load_adapters(specific_source: str = None) -> List[type]:\n    \"\"\"Dynamically loads adapter classes from the adapters module.\"\"\"\n    adapter_classes = []\n    for name, obj in inspect.getmembers(adapters, inspect.isclass):\n        if issubclass(obj, (BaseAdapter, BaseAdapterV3)) and obj not in (BaseAdapter, BaseAdapterV3):\n            if specific_source and hasattr(obj, 'SOURCE_ID') and obj.SOURCE_ID != specific_source:\n                continue\n            adapter_classes.append(obj)\n    return adapter_classes\n\ndef _convert_to_model_race(norm_race: NormalizedRace, source: str) -> Race:\n    \"\"\"\n    Converts a NormalizedRace from the base model to a Race from the app model.\n    NOTE: This conversion is lossy for program_number, which is handled by a\n    workaround in the main pipeline logic.\n    \"\"\"\n    is_handicap = norm_race.race_type and \"handicap\" in norm_race.race_type.lower()\n    return Race(\n        race_id=norm_race.race_id,\n        venue=norm_race.track_name,\n        race_time=norm_race.post_time.strftime(\"%H:%M\") if norm_race.post_time else \"\",\n        race_number=norm_race.race_number,\n        number_of_runners=norm_race.number_of_runners,\n        is_handicap=is_handicap,\n        source=source,\n        runners=[Runner(name=r.name, odds=r.odds) for r in norm_race.runners]\n    )\n\ndef _convert_to_normalized_race(model_race: Race, prog_num_map: Dict[Tuple[str, str], int]) -> NormalizedRace:\n    \"\"\"Converts a Race from the app model back to a NormalizedRace for pipeline output.\"\"\"\n    from datetime import datetime, date\n    try:\n        post_time = datetime.combine(date.today(), datetime.strptime(model_race.race_time, \"%H:%M\").time())\n    except (ValueError, TypeError):\n        post_time = None\n\n    # Reconstruct NormalizedRunner with program_number from the map\n    runners = [\n        NormalizedRunner(\n            name=r.name,\n            odds=r.odds,\n            program_number=prog_num_map.get((model_race.race_id, r.name), i + 1) # Fallback to index\n        ) for i, r in enumerate(model_race.runners)\n    ]\n\n    # Fix for the number_of_runners data loss bug (handles case where value is 0)\n    num_runners = model_race.number_of_runners if model_race.number_of_runners is not None else len(runners)\n    race_type = \"Handicap\" if model_race.is_handicap else \"Unknown\"\n\n    return NormalizedRace(\n        race_id=model_race.race_id,\n        track_name=model_race.venue,\n        race_number=model_race.race_number,\n        post_time=post_time,\n        number_of_runners=num_runners,\n        race_type=race_type,\n        runners=runners,\n    )\n\nasync def run_pipeline(\n    min_runners: int,\n    time_window_minutes: int,\n    specific_source: str = None,\n    ui: Optional['TerminalUI'] = None\n) -> List[NormalizedRace]:\n    \"\"\"Orchestrates the end-to-end pipeline.\"\"\"\n    logging.info(\"--- Paddock Parser NG Pipeline Start ---\")\n\n    unmerged_races: List[Race] = []\n    prog_num_map: Dict[Tuple[str, str], int] = {}  # Map to preserve program numbers across lossy conversion\n    adapter_classes = load_adapters(specific_source)\n    races_per_adapter: Dict[str, int] = {}\n\n    if not adapter_classes:\n        logging.warning(\"No adapters found.\")\n        return []\n\n    if ui:\n        ui.start_fetching_progress(len(adapter_classes))\n\n    for adapter_class in adapter_classes:\n        adapter = adapter_class()\n        source_id = getattr(adapter, 'SOURCE_ID', 'Unknown')\n        logging.info(f\"Running adapter: {source_id}...\")\n\n        try:\n            normalized_races: List[NormalizedRace] = []\n            if isinstance(adapter, BaseAdapterV3):\n                races = await adapter.fetch()\n                normalized_races.extend(races)\n            elif isinstance(adapter, BaseAdapter):\n                raw_data = adapter.fetch_data()\n                normalized_races = adapter.parse_data(raw_data)\n\n            races_per_adapter[source_id] = len(normalized_races)\n\n            if normalized_races:\n                logging.info(f\"Parsed {len(normalized_races)} races from {source_id}.\")\n                # Convert to the application's Race model for merging\n                for norm_race in normalized_races:\n                    # Stash program numbers before they are lost in conversion\n                    for runner in norm_race.runners:\n                        if runner.program_number:\n                            prog_num_map[(norm_race.race_id, runner.name)] = runner.program_number\n                    unmerged_races.append(_convert_to_model_race(norm_race, source_id))\n            else:\n                logging.warning(f\"No races parsed for {source_id}.\")\n\n        except NotImplementedError:\n            logging.info(f\"Adapter {source_id} skipped: Not implemented for live fetching.\")\n        except Exception:\n            logging.error(f\"An error occurred in the '{source_id}' adapter. See details below.\", exc_info=True)\n        finally:\n            if ui:\n                ui.update_fetching_progress()\n\n    if ui:\n        ui.stop_fetching_progress()\n\n    logging.info(\"\\n--- Data Ingestion Summary ---\")\n    for source, count in races_per_adapter.items():\n        logging.info(f\"  - {source}: {count} races\")\n    logging.info(f\"Total races ingested: {len(unmerged_races)}\")\n\n    races_with_few_runners = [r for r in unmerged_races if r.number_of_runners and r.number_of_runners < 7]\n    logging.info(f\"Found {len(races_with_few_runners)} races with fewer than 7 runners.\")\n    logging.info(\"----------------------------\\n\")\n\n    if not unmerged_races:\n        logging.info(\"No races were successfully parsed from any source.\")\n        return []\n\n    # Merge the races\n    logging.info(f\"Merging {len(unmerged_races)} race records...\")\n    merged_model_races = smart_merge(unmerged_races)\n    logging.info(f\"Merged down to {len(merged_model_races)} unique races.\")\n\n    # Score the merged races\n    merged_model_races = score_races(merged_model_races)\n\n    # Filter based on min_runners\n    if min_runners > 1:\n        merged_model_races = [r for r in merged_model_races if r.number_of_runners >= min_runners]\n\n    # Convert back to NormalizedRace for final output, preserving the score\n    final_normalized_races = []\n    for race_model in merged_model_races:\n        norm_race = _convert_to_normalized_race(race_model, prog_num_map)\n        norm_race.score = getattr(race_model, 'score', 0.0)\n        norm_race.scores = getattr(race_model, 'scores', {})\n        final_normalized_races.append(norm_race)\n\n    # Filter by time window\n    if time_window_minutes > 0:\n        from datetime import datetime, timedelta\n        now = datetime.now()\n        time_limit = now + timedelta(minutes=time_window_minutes)\n        races_before_time_filter = len(final_normalized_races)\n        final_normalized_races = [\n            r for r in final_normalized_races if r.post_time and r.post_time > now and r.post_time <= time_limit\n        ]\n        races_after_time_filter = len(final_normalized_races)\n        logging.info(f\"Filtered {races_before_time_filter} races down to {races_after_time_filter} races in the next {time_window_minutes} minutes.\")\n\n    # Sort the final list by score\n    final_normalized_races.sort(key=lambda r: r.score or 0, reverse=True)\n\n    logging.info(\"--- Pipeline End ---\")\n    return final_normalized_races\n"
}