{
    "filepath": "src/paddock_parser/adapters/attheraces_adapter.py",
    "content": "import re\nfrom datetime import datetime\nfrom typing import Any, List, Dict\n\nfrom bs4 import BeautifulSoup\n\nfrom ..fetcher import get_page_content\nfrom ..base import BaseAdapterV3, NormalizedRace, NormalizedRunner\n\ndef _convert_odds_to_float(odds_str: str) -> float:\n    \"\"\"Converts odds string to a float. Handles 'EVS' and fractions.\"\"\"\n    if isinstance(odds_str, str):\n        odds_str = odds_str.strip().upper()\n        if odds_str == 'EVS':\n            return 2.0\n        if '/' in odds_str:\n            try:\n                num, den = map(int, odds_str.split('/'))\n                return (num / den) + 1.0\n            except (ValueError, ZeroDivisionError):\n                return 0.0\n    return 0.0\n\nclass AtTheRacesAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for attheraces.com.\n    \"\"\"\n    SOURCE_ID = 'attheraces'\n    BASE_URL = \"https://www.attheraces.com\"\n\n    def __init__(self, cache_dir: str = None):\n        super().__init__(cache_dir)\n\n    async def fetch(self) -> List[NormalizedRace]:\n        \"\"\"Fetches data from attheraces.com.\"\"\"\n        index_content = await get_page_content(f\"{self.BASE_URL}/racecards\")\n        race_details_list = self._get_race_details(index_content)\n\n        races = []\n        for race_details in race_details_list:\n            try:\n                race_content = await get_page_content(race_details[\"url\"])\n                race = self._parse_race(race_content, race_details)\n                if race:\n                    races.append(race)\n            except Exception:\n                continue\n        return races\n\n    def parse_races(self, html_content: str) -> List[NormalizedRace]:\n        \"\"\"This adapter is designed for live fetching, so offline parsing is not supported.\"\"\"\n        return []\n\n    def _get_race_details(self, html_content: str) -> List[Dict]:\n        \"\"\"\n        Parses the racecards index page to get the URLs and other details for each race.\n        \"\"\"\n        soup = BeautifulSoup(html_content, 'lxml')\n        races = []\n\n        for meeting_section in soup.select(\"section.panel\"):\n            course_name_tag = meeting_section.select_one(\"h2.h6\")\n            if not course_name_tag:\n                continue\n            course_name = course_name_tag.text.strip().replace(\" Racecards\", \"\")\n\n            for race_entry in meeting_section.select(\"div.meeting-list-entry\"):\n                race_link_tag = race_entry.select_one(\"a.a--plain\")\n                if not (race_link_tag and race_link_tag.has_attr('href')):\n                    continue\n\n                url = self.BASE_URL + race_link_tag['href']\n                race_number_tag = race_entry.select_one(\"span.post__number\")\n                race_number = int(race_number_tag.text.strip()) if race_number_tag else 0\n\n                h7_tag = race_entry.select_one(\"span.h7\")\n                if h7_tag:\n                    full_title = h7_tag.text.strip()\n                    time_match = re.search(r\"(\\d{2}:\\d{2})\", full_title)\n                    time = time_match.group(1) if time_match else \"\"\n                else:\n                    time = \"\"\n\n                races.append({\"course\": course_name, \"time\": time, \"url\": url, \"race_number\": race_number})\n        return races\n\n    def _parse_race(self, html_content: str, race_details: Dict) -> NormalizedRace:\n        soup = BeautifulSoup(html_content, 'lxml')\n\n        header_tag = soup.select_one(\"div.race-header h1\")\n        if not header_tag:\n            return None\n\n        header_text = header_tag.text.strip()\n        date_match = re.search(r'(\\d{2}\\s\\w{3}\\s\\d{4})', header_text)\n        date_str = date_match.group(1) if date_match else \"\"\n\n        post_time = None\n        if race_details[\"time\"] and date_str:\n            try:\n                dt_str = f\"{date_str} {race_details['time']}\"\n                post_time = datetime.strptime(dt_str, '%d %b %Y %H:%M')\n            except ValueError:\n                post_time = None\n\n        race_info_tag = soup.select_one(\"div.race-info div\")\n        race_type = race_info_tag.text.strip() if race_info_tag else \"Unknown\"\n\n        runners = []\n        for card in soup.select(\"div.runner-card\"):\n            horse_name_tag = card.select_one(\".horse-name a\")\n            if not horse_name_tag:\n                continue\n\n            odds_tag = card.select_one(\".odds\")\n\n            runners.append(\n                NormalizedRunner(\n                    name=horse_name_tag.text.strip(),\n                    odds=_convert_odds_to_float(odds_tag.text.strip() if odds_tag else \"\"),\n                    program_number=int(card.select_one(\".runner-number\").text.strip())\n                )\n            )\n\n        return NormalizedRace(\n            race_id=f\"{race_details['course'].replace(' ', '')}_{race_details['time'].replace(':', '')}\",\n            track_name=race_details['course'],\n            race_number=race_details['race_number'],\n            post_time=post_time,\n            race_type=race_type,\n            number_of_runners=len(runners),\n            runners=runners\n        )\n"
}