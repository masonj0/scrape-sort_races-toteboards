{
    "filepath": "./src/paddock_parser/adapters/equibase_adapter.py",
    "content": "#!/usr/bin/env python3\n\"\"\"\nA V3-compliant adapter for scraping race data from Equibase.\nThis is the first new adapter of the V4 Polyglot Renaissance.\nThe core logic is a Python translation of a modern, open-source JavaScript scraper.\n\"\"\"\nfrom datetime import datetime, date\nfrom paddock_parser.base import BaseAdapterV3\nfrom paddock_parser.models import NormalizedRace, NormalizedRunner\nfrom paddock_parser.fetcher import get_page_content\nfrom bs4 import BeautifulSoup\n\nclass EquibaseAdapter(BaseAdapterV3):\n    \"\"\"\n    An adapter for fetching and parsing data from www.equibase.com.\n    It targets the daily entries pages.\n    \"\"\"\n\n    BASE_URL = \"http://www.equibase.com\"\n\n    async def fetch(self, fetch_date: date) -> list[NormalizedRace]:\n        \"\"\" Fetches all race data for a given date from the entries page. \"\"\"\n        date_str = fetch_date.strftime('%m%d%y')\n        entries_url = f\"{self.BASE_URL}/entries/ENT_{date_str}.html?COUNTRY=USA\"\n\n        html_content = await get_page_content(entries_url)\n\n        if not html_content:\n            return []\n\n        return self.parse_races(html_content)\n\n    def parse_races(self, html_content: str) -> list[NormalizedRace]:\n        \"\"\" Parses the full HTML page of daily entries. \"\"\"\n        soup = BeautifulSoup(html_content, 'html.parser')\n        all_races = []\n\n        track_tables = soup.find_all('table', summary=lambda s: s and s.startswith('Track Abbr:'))\n\n        for track_table in track_tables:\n            try:\n                track_name = track_table.find('tr').find('strong').text.strip()\n                race_rows = track_table.find_all('tr', class_='entry')\n\n                for race_row in race_rows:\n                    links = race_row.find_all('a')\n                    if not links:\n                        continue\n\n                    race_number_str = links[0].text.strip()\n                    race_number = int(''.join(filter(str.isdigit, race_number_str)))\n\n                    # NOTE: A full implementation would require a second, asynchronous\n                    # fetch to the race detail page (links[1]['href']) to get runners.\n                    # For this first version, we prove the schedule parsing.\n                    all_races.append(NormalizedRace(\n                        track=track_name,\n                        race_number=race_number,\n                        race_time=datetime.now().replace(hour=0, minute=0, second=0, microsecond=0),\n                        runners=[NormalizedRunner(name=\"TBD\")]\n                    ))\n            except Exception as e:\n                print(f\"Skipping a malformed table/row in Equibase parse: {e}\")\n                continue\n\n        return all_races\n"
}