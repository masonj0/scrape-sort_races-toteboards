{
    "filepath": "src/paddock_parser/adapters/fanduel_graphql_adapter.py",
    "content": "from datetime import datetime\nfrom typing import Dict, List, Optional\n\nfrom ..sync_fetcher import post_page_content\nfrom ..base import BaseAdapterV3, NormalizedRace, NormalizedRunner\n\nclass FanDuelGraphQLAdapter(BaseAdapterV3):\n    \"\"\"\n    Adapter for the FanDuel GraphQL API.\n    This adapter is synchronous and uses the requests-based sync_fetcher.\n    \"\"\"\n    SOURCE_ID = \"fanduel\"\n    BASE_URL = \"https://sb-prod-df.sportsbook.fanduel.com/api/v2/horse-racing/races\"\n\n    def __init__(self, cache_dir: Optional[str] = None):\n        super().__init__(cache_dir)\n\n    async def fetch(self) -> List[NormalizedRace]:\n        \"\"\"\n        Fetches data from the FanDuel GraphQL API.\n        This is a synchronous operation wrapped in an async method.\n        \"\"\"\n        graphql_query = {\n            \"query\": \"\"\"\n                query AllRaces($first: Int!, $next: String) {\n                    allRaces(first: $first, after: $next) {\n                        edges {\n                            node {\n                                trackName\n                                raceNumber\n                                postTime\n                                runners {\n                                    runnerName\n                                    odds\n                                    scratched\n                                }\n                            }\n                        }\n                    }\n                }\n            \"\"\",\n            \"variables\": {\"first\": 100}\n        }\n\n        try:\n            raw_data = post_page_content(self.BASE_URL, post_data=graphql_query)\n            return self.parse_races(raw_data)\n        except Exception:\n            return []\n\n    def parse_races(self, raw_data: Dict) -> List[NormalizedRace]:\n        \"\"\"Parses the JSON response from the GraphQL API.\"\"\"\n        races = []\n\n        race_edges = raw_data.get(\"data\", {}).get(\"allRaces\", {}).get(\"edges\", [])\n        if not race_edges:\n            return []\n\n        for edge in race_edges:\n            node = edge.get(\"node\", {})\n            if not node:\n                continue\n\n            runners = []\n            for runner_data in node.get(\"runners\", []):\n                if runner_data.get('scratched'):\n                    continue\n\n                runners.append(\n                    NormalizedRunner(\n                        name=runner_data.get(\"runnerName\"),\n                        odds=self._to_float_odds(runner_data.get(\"odds\")),\n                        program_number=0\n                    )\n                )\n\n            post_time = self._to_datetime(node.get(\"postTime\"))\n\n            races.append(\n                NormalizedRace(\n                    race_id=f\"{node.get('trackName')}_{node.get('raceNumber')}\",\n                    track_name=node.get(\"trackName\"),\n                    race_number=node.get(\"raceNumber\"),\n                    post_time=post_time,\n                    number_of_runners=len(runners),\n                    runners=runners\n                )\n            )\n        return races\n\n    def _to_float_odds(self, odds_str: Optional[str]) -> Optional[float]:\n        if not odds_str or \"/\" not in odds_str:\n            return None\n        try:\n            num, den = map(int, odds_str.split('/'))\n            return (num / den) + 1.0\n        except (ValueError, ZeroDivisionError):\n            return None\n\n    def _to_datetime(self, timestamp_str: Optional[str]) -> Optional[datetime]:\n        if not timestamp_str:\n            return None\n        try:\n            return datetime.fromisoformat(timestamp_str.replace(\"Z\", \"+00:00\"))\n        except (ValueError, TypeError):\n            return None\n"
}