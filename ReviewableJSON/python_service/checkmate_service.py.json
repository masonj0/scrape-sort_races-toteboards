{
    "filepath": "./python_service/checkmate_service.py",
    "content": "# checkmate_service.py\n# The main service runner, upgraded to the final Endgame architecture.\n\nimport time\nimport logging\nimport sqlite3\nimport json\nimport os\nimport threading\nfrom datetime import datetime\nfrom .engine import SuperchargedOrchestrator, EnhancedTrifectaAnalyzer, Settings, Race\nfrom typing import List\n\nclass DatabaseHandler:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._setup_database()\n\n    def _get_connection(self):\n        return sqlite3.connect(self.db_path, timeout=10)\n\n    def _setup_database(self):\n        try:\n            # Construct robust paths to both schema files\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n            schema_path = os.path.join(base_dir, 'shared_database', 'schema.sql')\n            web_schema_path = os.path.join(base_dir, 'shared_database', 'web_schema.sql')\n\n            with open(schema_path, 'r') as f:\n                schema = f.read()\n            with open(web_schema_path, 'r') as f:\n                web_schema = f.read()\n\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.executescript(schema)\n                cursor.executescript(web_schema)\n                conn.commit()\n            self.logger.info(f\"Database schemas applied successfully from {schema_path} and {web_schema_path}.\")\n        except Exception as e:\n            self.logger.critical(f\"FATAL: Could not set up database from schema files: {e}\", exc_info=True)\n            raise\n\n    def update_races_and_status(self, races: List[Race], statuses: List[dict]):\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            for race in races:\n                cursor.execute(\"\"\"\n                    INSERT OR REPLACE INTO live_races\n                    (race_id, track_name, race_number, post_time, raw_data_json, checkmate_score, qualified, trifecta_factors_json, updated_at)\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\", (\n                    race.race_id, race.track_name, race.race_number, race.post_time,\n                    race.model_dump_json(), race.checkmate_score, race.is_qualified,\n                    race.trifecta_factors_json, datetime.now()\n                ))\n            for status in statuses:\n                cursor.execute(\"\"\"\n                    INSERT OR REPLACE INTO adapter_status (adapter_name, status, last_run, races_found, error_message, execution_time_ms)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\", (\n                    status.get('adapter_id'), status.get('status'), status.get('timestamp'),\n                    status.get('races_found'), status.get('error_message'), int(status.get('response_time', 0) * 1000)\n                ))\n\n            if races or statuses:\n                cursor.execute(\"INSERT INTO events (event_type, payload) VALUES (?, ?)\",\n                               ('RACES_UPDATED', json.dumps({'race_count': len(races)})))\n\n            conn.commit()\n        self.logger.info(f\"Database updated with {len(races)} races and {len(statuses)} adapter statuses.\")\n\nclass CheckmateBackgroundService:\n    def __init__(self):\n        self.settings = Settings()\n        self.db_handler = DatabaseHandler(os.path.join(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')), \"shared_database\", \"races.db\"))\n        self.orchestrator = SuperchargedOrchestrator(self.settings)\n        self.analyzer = EnhancedTrifectaAnalyzer(self.settings)\n        self.stop_event = threading.Event()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Supercharged background service starting continuous run.\")\n        while not self.stop_event.is_set():\n            self.logger.info(\"Starting advanced data collection and analysis cycle.\")\n            try:\n                races, statuses = self.orchestrator.get_races_parallel()\n                analyzed_races = [self.analyzer.analyze_race_advanced(race) for race in races]\n                self.db_handler.update_races_and_status(analyzed_races, statuses)\n            except Exception as e:\n                self.logger.critical(f\"FATAL error in main service loop: {e}\", exc_info=True)\n\n            self.stop_event.wait(interval_seconds)\n\n                    res = results_map[race.race_id]\n                    race.checkmate_score = res.get('checkmate_score')\n                    race.is_qualified = res.get('qualified')\n                    race.trifecta_factors_json = json.dumps(res.get('trifecta_factors'))\n            return races\n        except FileNotFoundError:\n            self.logger.warning(\"Rust engine not found. Falling back to Python analyzer.\")\n            return None\n        except (subprocess.CalledProcessError, json.JSONDecodeError, subprocess.TimeoutExpired) as e:\n            self.logger.error(f\"Rust engine execution failed: {e}. Falling back to Python analyzer.\")\n            return None\n\n    def _analyze_with_python(self, races: List[Race]) -> List[Race]:\n        self.logger.info(\"Performing analysis with internal Python engine.\")\n        return [self.python_analyzer.analyze_race(race, self.settings) for race in races]\n\n    def run_continuously(self, interval_seconds: int = 60):\n        self.logger.info(\"Background service thread starting continuous run.\")\n\n        while not self.stop_event.is_set():\n            try:\n                self.logger.info(\"Starting data collection and analysis cycle.\")\n                races, statuses = self.orchestrator.get_races()\n\n                analyzed_races = None\n                if os.path.exists(self.rust_engine_path):\n                    analyzed_races = self._analyze_with_rust(races)\n\n                if analyzed_races is None: # Fallback condition\n                    analyzed_races = self._analyze_with_python(races)\n\n                if analyzed_races: # Ensure we have something to update\n                    self.db_handler.update_races_and_status(analyzed_races, statuses)\n\n            except Exception as e:\n                self.logger.critical(f\"Unhandled exception in service loop: {e}\", exc_info=True)\n\n            self.logger.info(f\"Cycle complete. Sleeping for {interval_seconds} seconds.\")\n            self.stop_event.wait(interval_seconds)\n        self.logger.info(\"Background service run loop has terminated.\")\n\n\n    def start(self):\n        self.stop_event.clear()\n        self.thread = threading.Thread(target=self.run_continuously)\n        self.thread.daemon = True\n        self.thread.start()\n        self.logger.info(\"CheckmateBackgroundService started.\")\n\n    def stop(self):\n        self.stop_event.set()\n        if hasattr(self, 'thread') and self.thread.is_alive():\n            self.thread.join(timeout=10)\n        self.logger.info(\"CheckmateBackgroundService stopped.\")"
}