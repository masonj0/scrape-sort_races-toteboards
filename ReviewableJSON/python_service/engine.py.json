{
    "filepath": "python_service/engine.py",
    "content": "# python_service/engine.py\n\nimport logging\nfrom datetime import datetime, timedelta\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# Assuming adapters are in their own files now\nfrom .adapters.betfair_adapter import BetfairAdapter\nfrom .adapters.tvg_adapter import TVGAdapter\nfrom .adapters.racing_and_sports_adapter import RacingAndSportsAdapter\nfrom .adapters.pointsbet_adapter import PointsBetAdapter\n\nclass EngineManager:\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._adapters = {}\n        self._cache = {}\n        self._cache_ttl = timedelta(seconds=60)\n        self._initialize_adapters()\n\n    def _initialize_adapters(self):\n        self.logger.info(\"Initializing adapters...\")\n        # In a real system, these would be loaded dynamically\n        adapter_classes = {\n            'betfair': BetfairAdapter,\n            'tvg': TVGAdapter,\n            'racing_and_sports': RacingAndSportsAdapter,\n            'pointsbet': PointsBetAdapter\n        }\n        for name, AdapterClass in adapter_classes.items():\n            try:\n                self._adapters[name] = AdapterClass()\n                self.logger.info(f\"{name} adapter initialized.\")\n            except Exception as e:\n                self.logger.error(f\"Failed to initialize {name} adapter: {e}\")\n\n    def fetch_races(self):\n        \"\"\"Fetch races from all sources in parallel.\"\"\"\n        cache_key = \"all_races\"\n        if self._is_cache_valid(cache_key):\n            self.logger.info(\"Returning all races from cache.\")\n            return self._cache[cache_key][0]\n\n        self.logger.info(\"Fetching fresh race data in parallel...\")\n        all_races = []\n        with ThreadPoolExecutor(max_workers=len(self._adapters)) as executor:\n            future_to_adapter = {executor.submit(adapter.fetch_races): name for name, adapter in self._adapters.items()}\n            for future in as_completed(future_to_adapter):\n                adapter_name = future_to_adapter[future]\n                try:\n                    races = future.result(timeout=15) # 15-second timeout per adapter\n                    if races:\n                        all_races.extend(races)\n                    self.logger.info(f\"{adapter_name} fetched {len(races) if races else 0} races.\")\n                except Exception as e:\n                    self.logger.error(f\"Adapter {adapter_name} failed during fetch: {e}\")\n        \n        self._cache[cache_key] = (all_races, datetime.now())\n        return all_races\n\n    def get_adapter_status(self, adapter_name):\n        \"\"\"Get the real status of a specific adapter.\"\"\"\n        if adapter_name not in self._adapters:\n            return None\n        \n        adapter = self._adapters[adapter_name]\n        try:\n            # A lightweight test: can the adapter be initialized and maybe a health check method called?\n            # For this example, we'll just check if it's in the list.\n            # A real implementation would have a .healthcheck() method on the adapter.\n            return {\n                'name': adapter_name,\n                'status': 'healthy',\n                'last_checked': datetime.now().isoformat()\n            }\n        except Exception as e:\n            return {\n                'name': adapter_name,\n                'status': 'failed',\n                'error': str(e),\n                'last_checked': datetime.now().isoformat()\n            }\n    \n    def _is_cache_valid(self, key):\n        if key not in self._cache:\n            return False\n        _, timestamp = self._cache[key]\n        return (datetime.now() - timestamp) < self._cache_ttl"
}