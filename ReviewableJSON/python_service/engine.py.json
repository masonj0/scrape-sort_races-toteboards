{
    "filepath": "python_service/engine.py",
    "content": "#!/usr/bin/env python3\n# ==============================================================================\n# == Checkmate V8 - The Ultimate Engine (FINAL CORRECTED VERBATIM)\n# ==============================================================================\n\nimport logging\nimport json\nimport subprocess\nimport concurrent.futures\nimport time\nimport os\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Union, Dict\nfrom datetime import datetime\nfrom pydantic import BaseModel, Field\nfrom pydantic_settings import BaseSettings\nfrom bs4 import BeautifulSoup\n\n# --- Settings ---\nclass Settings(BaseSettings):\n    QUALIFICATION_SCORE: float = Field(default=75.0)\n    FIELD_SIZE_OPTIMAL_MIN: int = Field(default=4)\n    FIELD_SIZE_OPTIMAL_MAX: int = Field(default=6)\n    FIELD_SIZE_ACCEPTABLE_MIN: int = Field(default=7)\n    FIELD_SIZE_ACCEPTABLE_MAX: int = Field(default=8)\n    FIELD_SIZE_OPTIMAL_POINTS: int = Field(default=30)\n    FIELD_SIZE_ACCEPTABLE_POINTS: int = Field(default=10)\n    FIELD_SIZE_PENALTY_POINTS: int = Field(default=-20)\n    FAV_ODDS_POINTS: int = Field(default=30)\n    MAX_FAV_ODDS: float = Field(default=3.5)\n    SECOND_FAV_ODDS_POINTS: int = Field(default=40)\n    MIN_2ND_FAV_ODDS: float = Field(default=4.0)\n\n# --- Models ---\nclass Runner(BaseModel):\n    name: str\n    odds: Optional[float] = None\n\nclass Race(BaseModel):\n    race_id: str\n    track_name: str\n    race_number: Optional[int] = None\n    post_time: Optional[datetime] = None\n    runners: List[Runner]\n    source: Optional[str] = None\n    checkmate_score: Optional[float] = None\n    is_qualified: Optional[bool] = None\n    trifecta_factors_json: Optional[str] = None\n\n# --- Universal Helpers ---\ndef parse_odds_universal(odds_input: any) -> Optional[float]:\n    if not odds_input: return None\n    odds_str = str(odds_input).strip().upper()\n    if odds_str in ['SP', 'SCRATCHED', 'N/A', '']: return None\n    if odds_str in ['EVS', 'EVENS']: return 2.0\n    if odds_str.startswith(('+', '-')):\n        try:\n            american = int(odds_str)\n            if american > 0: return (american / 100) + 1\n            else: return (100 / abs(american)) + 1\n        except (ValueError, TypeError): return None\n    if '/' in odds_str:\n        try:\n            num, den = map(float, odds_str.split('/'))\n            return (num / den) + 1.0 if den != 0 else None\n        except (ValueError, ZeroDivisionError, TypeError): return None\n    try: return float(odds_str)\n    except (ValueError, TypeError): return None\n\ndef safe_parse_datetime(dt_input: any) -> Optional[datetime]:\n    if not dt_input: return None\n    dt_str = str(dt_input).strip()\n    try:\n        if 'Z' in dt_str: dt_str = dt_str.replace('Z', '+00:00')\n        return datetime.fromisoformat(dt_str)\n    except (ValueError, AttributeError): return None\n\n# --- CORE Components ---\nclass DefensiveFetcher:\n    def get(self, url: str, response_type: str = 'auto', headers: Optional[Dict[str, str]] = None) -> Union[dict, str, None]:\n        try:\n            command = [\"curl\", \"-s\", \"-L\", \"--tlsv1.2\", \"--http1.1\", \"--max-time\", \"15\"]\n            if headers: [command.extend([\"-H\", f\"{k}: {v}\"]) for k, v in headers.items()]\n            command.append(url)\n            result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=20)\n            if response_type == 'text': return result.stdout\n            try: return json.loads(result.stdout)\n            except json.JSONDecodeError: return result.stdout\n        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, Exception) as e:\n            logging.error(f\"Error fetching {url}: {e}\"); return None\n\nclass BaseAdapterV7(ABC):\n    def __init__(self, fetcher: DefensiveFetcher): self.fetcher = fetcher; self.logger = logging.getLogger(self.__class__.__name__)\n    @abstractmethod\n    def fetch_races(self) -> List[Race]: raise NotImplementedError\n\nclass TrifectaAnalyzer:\n    def analyze_race(self, race: Race, settings: Settings) -> Race:\n        score, factors = 0.0, {}\n        runners_with_odds = sorted([r for r in race.runners if r.odds], key=lambda r: r.odds)\n        num_runners = len(runners_with_odds)\n        if settings.FIELD_SIZE_OPTIMAL_MIN <= num_runners <= settings.FIELD_SIZE_OPTIMAL_MAX: score += settings.FIELD_SIZE_OPTIMAL_POINTS; factors['fieldSize'] = {'points': settings.FIELD_SIZE_OPTIMAL_POINTS, 'ok': True, 'reason': f\"Optimal size ({num_runners})\"}\n        elif settings.FIELD_SIZE_ACCEPTABLE_MIN <= num_runners <= settings.FIELD_SIZE_ACCEPTABLE_MAX: score += settings.FIELD_SIZE_ACCEPTABLE_POINTS; factors['fieldSize'] = {'points': settings.FIELD_SIZE_ACCEPTABLE_POINTS, 'ok': True, 'reason': f\"Acceptable size ({num_runners})\"}\n        else: score += settings.FIELD_SIZE_PENALTY_POINTS; factors['fieldSize'] = {'points': settings.FIELD_SIZE_PENALTY_POINTS, 'ok': False, 'reason': f\"Not ideal size ({num_runners})\"}\n        if num_runners >= 2:\n            fav_odds, sec_fav_odds = runners_with_odds[0].odds, runners_with_odds[1].odds\n            if fav_odds <= settings.MAX_FAV_ODDS: score += settings.FAV_ODDS_POINTS; factors['favoriteOdds'] = {'points': settings.FAV_ODDS_POINTS, 'ok': True, 'reason': f\"Fav odds OK ({fav_odds:.2f})\"}\n            else: factors['favoriteOdds'] = {'points': 0, 'ok': False, 'reason': f\"Fav odds too high ({fav_odds:.2f})\"}\n            if sec_fav_odds >= settings.MIN_2ND_FAV_ODDS: score += settings.SECOND_FAV_ODDS_POINTS; factors['secondFavoriteOdds'] = {'points': settings.SECOND_FAV_ODDS_POINTS, 'ok': True, 'reason': f\"2nd Fav OK ({sec_fav_odds:.2f})\"}\n            else: factors['secondFavoriteOdds'] = {'points': 0, 'ok': False, 'reason': f\"2nd Fav odds too low ({sec_fav_odds:.2f})\"}\n        race.checkmate_score = score; race.is_qualified = score >= settings.QUALIFICATION_SCORE; race.trifecta_factors_json = json.dumps(factors)\n        return race\n\n# --- CORE Adapters (COMPLETE AND VERBATIM) ---\nclass TVGAdapter(BaseAdapterV7):\n    SOURCE_ID = \"tvg\"\n    BASE_URL = \"https://mobile-api.tvg.com/api/mobile/races/today\"\n    def fetch_races(self) -> List[Race]:\n        self.logger.info(f\"Fetching from {self.BASE_URL}\")\n        response_data = self.fetcher.get(self.BASE_URL, response_type='json')\n        if not response_data or not isinstance(response_data, dict) or 'races' not in response_data: self.logger.warning(\"Invalid or empty response from TVG\"); return []\n        all_races = []\n        for race_info in response_data.get('races', []):\n            try:\n                runners = [Runner(name=r.get('horseName', 'Unknown'), odds=self._parse_tvg_odds(r.get('odds', {}).get('morningLine'))) for r in race_info.get('runners', []) if not r.get('scratched') and self._parse_tvg_odds(r.get('odds', {}).get('morningLine')) is not None]\n                if len(runners) < 3: continue\n                all_races.append(Race(race_id=f\"tvg_{race_info.get('raceId', 'unknown')}\", track_name=race_info.get('trackName', 'TVG Track'), race_number=race_info.get('raceNumber'), post_time=safe_parse_datetime(race_info.get('postTime')), runners=runners, source=self.SOURCE_ID))\n            except Exception as e: self.logger.warning(f\"Failed to parse TVG race: {e}\")\n        self.logger.info(f\"Successfully fetched {len(all_races)} races from TVG\"); return all_races\n    def _parse_tvg_odds(self, odds_data: any) -> Optional[float]:\n        if not odds_data: return None\n        try:\n            if isinstance(odds_data, str) and '/' in odds_data: num, den = map(int, odds_data.split('/')); return (num / den) + 1.0 if den != 0 else None\n            return parse_odds_universal(odds_data)\n        except (ValueError, TypeError, ZeroDivisionError): return None\n\nclass BetfairExchangeAdapter(BaseAdapterV7):\n    SOURCE_ID = \"betfair_exchange\"; BASE_URL = \"https://ero.betfair.com/www/sports/exchange/readonly/v1/bymarket\"\n    def fetch_races(self) -> List[Race]:\n        self.logger.info(\"Fetching from Betfair Exchange\")\n        params = {'alt': 'json', 'filter': 'canonical', 'maxResults': '25', 'rollupLimit': '2', 'types': 'EVENT,MARKET_DESCRIPTION,RUNNER_DESCRIPTION,RUNNER_EXCHANGE_PRICES_BEST,MARKET_STATE', 'marketProjection': 'EVENT,MARKET_START_TIME,RUNNER_DESCRIPTION', 'eventTypeIds': '7'}\n        url = f\"{self.BASE_URL}?{'&'.join(f'{k}={v}' for k, v in params.items())}\"\n        data = self.fetcher.get(url, response_type='json', headers={'Accept': 'application/json'})\n        if not data or not isinstance(data, dict): self.logger.warning(\"Invalid response from Betfair\"); return []\n        races = self._parse_betfair_data(data); self.logger.info(f\"Successfully fetched {len(races)} races from Betfair\"); return races\n    def _parse_betfair_data(self, data: dict) -> List[Race]:\n        races = []; event_types = data.get('eventTypes', []);\n        if not event_types: return races\n        try:\n            for event_node in event_types[0].get('eventNodes', []):\n                event = event_node.get('event', {})\n                for market_node in event_node.get('marketNodes', []):\n                    market = market_node.get('market', {})\n                    if market.get('marketType', '') != 'WIN': continue\n                    runners = [Runner(name=r.get('description', {}).get('runnerName', 'Unknown'), odds=r.get('exchange', {}).get('availableToBack', [{}])[0].get('price')) for r in market_node.get('runners', []) if r.get('state', {}).get('status') == 'ACTIVE']\n                    if len(runners) < 3: continue\n                    race_number = None\n                    event_name = event.get('eventName', '')\n                    if 'R' in event_name:\n                        try:\n                            race_number = int(event_name.split('R')[-1])\n                        except (ValueError, IndexError):\n                            pass\n                    races.append(Race(race_id=f\"betfair_{market.get('marketId', 'unknown')}\", track_name=event.get('venue', 'Betfair Exchange'), post_time=safe_parse_datetime(market.get('marketStartTime')), race_number=race_number, runners=runners, source=self.SOURCE_ID))\n        except Exception as e: self.logger.error(f\"Error parsing Betfair data: {e}\", exc_info=True)\n        return races\n\nclass PointsBetAdapter(BaseAdapterV7):\n    SOURCE_ID = \"pointsbet\"; BASE_URL = \"https://api.nj.pointsbet.com/api/v2/sports/horse-racing/events/upcoming?page=1\"\n    def fetch_races(self) -> List[Race]:\n        self.logger.info(\"Fetching from PointsBet\"); response_data = self.fetcher.get(self.BASE_URL, response_type='json')\n        if not response_data or not isinstance(response_data, dict): self.logger.warning(\"Invalid response from PointsBet\"); return []\n        events = response_data.get('events', []);\n        if not events: self.logger.warning(\"No events in PointsBet response\"); return []\n        races = []\n        for event in events:\n            try:\n                if not event.get('winPlaceOddsAvailable'): continue\n                runners = [Runner(name=o.get('name', 'Unknown'), odds=parse_odds_universal(o.get('price'))) for o in event.get('fixedPrice', {}).get('outcomes', []) if o.get('outcomeType') == 'Win']\n                if len(runners) < 3: continue\n                races.append(Race(race_id=f\"pointsbet_{event.get('key', 'unknown')}\", track_name=event.get('competitionName', 'Unknown Track'), race_number=event.get('eventNumber'), post_time=safe_parse_datetime(event.get('startsAt')), runners=runners, source=self.SOURCE_ID))\n            except Exception as e: self.logger.warning(f\"Failed to parse PointsBet event: {e}\")\n        self.logger.info(f\"Successfully fetched {len(races)} races from PointsBet\"); return races\n\n# --- RESURRECTED & MODERNIZED LEGACY ADAPTERS ---\nclass AtTheRacesAdapter(BaseAdapterV7):\n    SOURCE_ID = \"attheraces\"\n    def fetch_races(self) -> List[Race]:\n        self.logger.info(\"Fetching from AtTheRaces...\"); response_text = self.fetcher.get(\"https://www.attheraces.com/racecards\", response_type='text')\n        if not response_text: return []\n        soup = BeautifulSoup(response_text, 'lxml'); races = []\n        for card in soup.select('.racecard'):\n            try:\n                track = card.select_one('.track-name').text.strip(); time_str = card.select_one('.race-time').text.strip()\n                races.append(Race(race_id=f\"atr_{track.replace(' ','')}_{time_str}\", track_name=track, post_time=datetime.now(), runners=[], source=self.SOURCE_ID))\n            except Exception as e: self.logger.warning(f\"Failed to parse ATR card: {e}\")\n        self.logger.info(f\"Found {len(races)} race meetings from ATR.\"); return races\n\nclass RacingAndSportsAdapter(BaseAdapterV7):\n    SOURCE_ID = \"ras\"\n    def __init__(self, fetcher: DefensiveFetcher, api_key: Optional[str]): super().__init__(fetcher); self.api_key = api_key\n    def fetch_races(self) -> List[Race]:\n        if not self.api_key: self.logger.warning(\"RAS_API_KEY not configured. Skipping.\"); return []\n        self.logger.info(\"Fetching from RacingAndSports...\"); headers = {\"X-API-Key\": self.api_key}\n        meetings = self.fetcher.get(\"https://api.racingandsports.com.au/Meetings\", headers=headers)\n        if not meetings or not isinstance(meetings, list): return []\n        races = []\n        for meeting in meetings[:5]:\n            try: races.append(Race(race_id=f\"ras_{meeting['MeetingID']}\", track_name=meeting.get('TrackName', 'Unknown RAS Track'), post_time=datetime.now(), runners=[], source=self.SOURCE_ID))\n            except Exception as e: self.logger.warning(f\"Failed to parse RAS meeting: {e}\")\n        self.logger.info(f\"Found {len(races)} race meetings from RAS.\"); return races\n\n# --- The Ultimate DataSourceOrchestrator ---\nclass DataSourceOrchestrator:\n    def __init__(self):\n        self.fetcher = DefensiveFetcher(); self.logger = logging.getLogger(self.__class__.__name__)\n        self.adapters: List[BaseAdapterV7] = self._initialize_adapters()\n    def _initialize_adapters(self) -> List[BaseAdapterV7]:\n        instances = [TVGAdapter(self.fetcher), PointsBetAdapter(self.fetcher), BetfairExchangeAdapter(self.fetcher), AtTheRacesAdapter(self.fetcher), RacingAndSportsAdapter(self.fetcher, api_key=os.getenv(\"RAS_API_KEY\"))]\n        self.logger.info(f\"Initialized {len(instances)} total adapters for global coverage.\"); return instances\n    def _fetch_from_adapter(self, adapter: BaseAdapterV7) -> tuple[list[Race], dict]:\n        adapter_id = adapter.__class__.__name__; start_time = time.time()\n        status = {\"adapter_id\": adapter_id, \"timestamp\": datetime.now(), \"status\": \"FAILURE\", \"races_found\": 0, \"response_time\": 0.0, \"error_message\": None}\n        try: races = adapter.fetch_races(); status[\"status\"] = \"SUCCESS\"; status[\"races_found\"] = len(races); return races, status\n        except Exception as e: self.logger.error(f\"Adapter {adapter_id} failed: {e}\", exc_info=True); status[\"error_message\"] = str(e); return [], status\n        finally: status[\"response_time\"] = time.time() - start_time\n    def get_races(self) -> tuple[list[Race], list[dict]]:\n        self.logger.info(f\"Starting concurrent fetch from {len(self.adapters)} adapters...\"); all_races, all_statuses = [], []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.adapters)) as executor:\n            future_to_adapter = {executor.submit(self._fetch_from_adapter, adapter): adapter for adapter in self.adapters}\n            for future in concurrent.futures.as_completed(future_to_adapter):\n                try: races, status = future.result(); all_races.extend(races); all_statuses.append(status)\n                except Exception as e: self.logger.critical(f\"Future for adapter {future_to_adapter[future].__class__.__name__} failed: {e}\")\n        self.logger.info(f\"Concurrent fetch complete. Total races: {len(all_races)}\"); return all_races, all_statuses"
}