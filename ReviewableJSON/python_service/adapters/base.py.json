{
    "filepath": "python_service/adapters/base.py",
    "content": "# ==============================================================================\n# == Base Module for Adapters\n# ==============================================================================\n# This module provides the foundational, shared components for all adapters,\n# including data models, the base class, and the resilient fetcher.\n# ==============================================================================\n\nimport logging\nimport json\nimport subprocess\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Union, Dict\nfrom datetime import datetime\nfrom pydantic import BaseModel, Field\n\n# --- Finalized Data Models ---\n\nclass Runner(BaseModel):\n    name: str\n    odds: Optional[float] = None\n\nclass Race(BaseModel):\n    race_id: str\n    track_name: str\n    race_number: Optional[int] = None\n    post_time: Optional[datetime] = None\n    runners: List[Runner]\n    source: Optional[str] = None\n    checkmate_score: Optional[float] = None\n    is_qualified: Optional[bool] = None\n    trifecta_factors_json: Optional[str] = None\n    analysis_details: Optional[str] = None # For advanced analysis\n\n# --- Resilient Fetcher ---\nclass DefensiveFetcher:\n    def get(self, url: str, headers: Optional[Dict[str, str]] = None) -> Union[dict, str, None]:\n        \"\"\"\n        Executes a curl command to fetch data from a URL, providing a resilient\n        and environment-independent way to make HTTP requests.\n        \"\"\"\n        try:\n            command = [\"curl\", \"-s\", \"-L\", \"--tlsv1.2\", \"--http1.1\"]\n            if headers:\n                for key, value in headers.items():\n                    command.extend([\"-H\", f\"{key}: {value}\"])\n            command.append(url)\n\n            result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=15)\n            response_text = result.stdout\n\n            try:\n                # Attempt to parse as JSON first\n                return json.loads(response_text)\n            except json.JSONDecodeError:\n                # Fallback to returning raw text if not valid JSON\n                logging.warning(f\"Failed to decode JSON from {url}, returning raw text.\")\n                return response_text\n        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:\n            logging.error(f\"CRITICAL: curl GET failed for {url}. Details: {e}\")\n            return None\n\n# --- Abstract Base Adapter ---\nclass BaseAdapterV7(ABC):\n    \"\"\"\n    The abstract base class for all V7+ adapters. It requires a fetcher\n    and provides a consistent interface for the orchestrator.\n    \"\"\"\n    # The SOURCE_ID should be a unique identifier for each adapter implementation.\n    SOURCE_ID: str = \"base_adapter\"\n\n    def __init__(self, fetcher: DefensiveFetcher):\n        self.fetcher = fetcher\n\n    @abstractmethod\n    def fetch_races(self) -> List[Race]:\n        \"\"\"\n        The core method for an adapter. It should fetch data from its source\n        and return a list of standardized Race objects.\n        \"\"\"\n        raise NotImplementedError"
}