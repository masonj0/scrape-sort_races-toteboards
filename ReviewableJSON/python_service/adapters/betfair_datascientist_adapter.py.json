{
    "file_path": "python_service/adapters/betfair_datascientist_adapter.py",
    "content": "# python_service/adapters/betfair_datascientist_adapter.py\n\nfrom datetime import datetime\nfrom io import StringIO\nfrom typing import Any\nfrom typing import List\n\nimport pandas as pd\nimport requests\nimport structlog\n\nfrom ..models import Race\nfrom ..models import Runner\nfrom ..utils.text import normalize_course_name\nfrom .base_v3 import BaseAdapterV3\n\n\nclass BetfairDataScientistAdapter(BaseAdapterV3):\n    ADAPTER_NAME = \"BetfairDataScientist\"\n\n    def __init__(self, model_name: str, url: str, enabled: bool = True, priority: int = 100, config=None):\n        source_name = f\"{self.ADAPTER_NAME}_{model_name}\"\n        super().__init__(source_name=source_name, base_url=url)\n        self.model_name = model_name\n        self.url = url\n        self._enabled = enabled\n        self._priority = priority\n        self.config = config\n\n    async def _fetch_data(self, date: str) -> Any:\n        if not self._enabled:\n            self.logger.debug(f\"Adapter '{self.source_name}' is disabled. Skipping.\")\n            return None\n\n        try:\n            full_url = self._build_url(date)\n            self.logger.info(f\"Fetching data from {full_url}\")\n            response = await asyncio.to_thread(requests.get, full_url)\n            response.raise_for_status()\n            return StringIO(response.text)\n        except Exception as e:\n            self.logger.error(f\"An unexpected error in {self.source_name}: {e}\", exc_info=True)\n            return None\n\n    def _parse_races(self, raw_data: Any) -> List[Race]:\n        df = pd.read_csv(raw_data)\n        df = df.rename(\n            columns={\n                \"meetings.races.bfExchangeMarketId\": \"market_id\",\n                \"meetings.races.runners.bfExchangeSelectionId\": \"selection_id\",\n                \"meetings.races.runners.ratedPrice\": \"rated_price\",\n                \"meetings.races.raceName\": \"race_name\",\n                \"meetings.name\": \"meeting_name\",\n                \"meetings.races.raceNumber\": \"race_number\",\n                \"meetings.races.runners.runnerName\": \"runner_name\",\n                \"meetings.races.runners.clothNumber\": \"saddle_cloth\",\n            }\n        )\n        races = []\n        for market_id, group in df.groupby(\"market_id\"):\n            race_info = group.iloc[0]\n            runners = [\n                Runner(\n                    name=str(row.get(\"runner_name\")),\n                    number=int(row.get(\"saddle_cloth\", 0)),\n                    odds=float(row.get(\"rated_price\", 0.0)),\n                )\n                for _, row in group.iterrows()\n            ]\n            race = Race(\n                id=str(market_id),\n                venue=normalize_course_name(str(race_info.get(\"meeting_name\", \"\"))),\n                race_number=int(race_info.get(\"race_number\", 0)),\n                start_time=datetime.now(),\n                runners=runners,\n                source=self.source_name,\n            )\n            races.append(race)\n        self.logger.info(f\"Normalized {len(races)} races from {self.model_name}.\")\n        return races\n\n    def _build_url(self, date: str) -> str:\n        return f\"{self.url}{date}&presenter=RatingsPresenter&csv=true\"\n"
}