{
    "file_path": "convert_to_json.py",
    "content": "# convert_to_json.py\n# This script now contains the full, enlightened logic to handle all manifest formats and path styles.\n\nimport json\nimport os\nimport re\nimport sys\nfrom multiprocessing import Process, Queue\n\n# --- Configuration ---\nMANIFEST_FILES = ['MANIFEST2.md', 'MANIFEST3.md']\nOUTPUT_DIR = 'ReviewableJSON'\nFILE_PROCESSING_TIMEOUT = 10\n\n# --- ENLIGHTENED PARSING LOGIC (V2) ---\ndef extract_and_normalize_path(line: str) -> str | None:\n    \"\"\"\n    Extracts a file path from a line, handling multiple formats, and normalizes it.\n    Handles:\n    - Markdown links: `* [display](path)`\n    - Plain paths in backticks: ``- `path.py` - description``\n    - Plain paths with list markers: `- path/to/file.py`\n    \"\"\"\n    line = line.strip()\n    if not line or line.startswith('#'):\n        return None\n\n    # 1. Check for Markdown link format\n    md_match = re.search(r'\\[.*\\]\\((https?://[^\\)]+)\\)', line)\n    if md_match:\n        path = md_match.group(1)\n    else:\n        # 2. Check for paths in backticks\n        bt_match = re.search(r'`([^`]+)`', line)\n        if bt_match:\n            path = bt_match.group(1)\n        else:\n            # 3. Assume plain path, stripping list markers\n            path = re.sub(r'^[*-]\\s*', '', line).split(' ')[0]\n\n    # --- Path Standardization ---\n    if not path or not ('.' in path or '/' in path):\n        return None # Not a valid path\n\n    # If it's a full raw GitHub URL, extract the local path\n    if path.startswith('https://raw.githubusercontent.com/'):\n        path = '/'.join(path.split('/main/')[1:])\n\n    # Final check for valid file extensions or structure\n    if not re.search(r'(\\.[a-zA-Z0-9]+$)|(^[\\w/]+$)', path):\n        return None\n\n    return path.strip()\n\n# --- SANDBOXED FILE READ (Unchanged) ---\ndef _sandboxed_file_read(file_path, q):\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        q.put({\"file_path\": file_path, \"content\": content})\n    except Exception as e:\n        q.put({\"error\": str(e)})\n\ndef convert_file_to_json_sandboxed(file_path):\n    q = Queue()\n    p = Process(target=_sandboxed_file_read, args=(file_path, q))\n    p.start()\n    p.join(timeout=FILE_PROCESSING_TIMEOUT)\n    if p.is_alive():\n        p.terminate()\n        p.join()\n        return {\"error\": f\"Timeout: File processing took longer than {FILE_PROCESSING_TIMEOUT} seconds.\"}\n    if not q.empty():\n        return q.get()\n    return {\"error\": \"Unknown error in sandboxed read process.\"}\n\n# --- Main Orchestrator ---\ndef main():\n    print(f\"\\n{'='*60}\\nStarting IRONCLAD JSON backup process... (Enlightened Scribe Edition)\\n{'='*60}\")\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    all_local_paths = []\n    for manifest in MANIFEST_FILES:\n        print(f\"--> Parsing manifest: {manifest}\")\n        if not os.path.exists(manifest):\n            print(f\"    [WARNING] Manifest not found: {manifest}\")\n            continue\n\n        with open(manifest, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n\n        paths_found = 0\n        for line in lines:\n            path = extract_and_normalize_path(line)\n            if path:\n                all_local_paths.append(path)\n                paths_found += 1\n        print(f\"    --> Found {paths_found} valid file paths.\")\n\n    if not all_local_paths:\n        print(\"\\n[FATAL] No valid file paths found in any manifest. Aborting.\")\n        sys.exit(1)\n\n    unique_local_paths = sorted(list(set(all_local_paths)))\n    print(f\"\\nFound a total of {len(unique_local_paths)} unique files to process.\")\n    processed_count, failed_count = 0, 0\n\n    for local_path in unique_local_paths:\n        print(f\"\\nProcessing: {local_path}\")\n        json_data = convert_file_to_json_sandboxed(local_path)\n        if json_data and \"error\" not in json_data:\n            output_path = os.path.join(OUTPUT_DIR, local_path + '.json')\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(json_data, f, indent=4)\n            print(f\"    [SUCCESS] Saved backup to {output_path}\")\n            processed_count += 1\n        else:\n            error_msg = json_data.get(\"error\", \"Unknown error\") if json_data else \"File not found\"\n            print(f\"    [ERROR] Failed to process {local_path}: {error_msg}\")\n            failed_count += 1\n\n    print(f\"\\n{'='*60}\\nBackup process complete.\\nSuccessfully processed: {processed_count}/{len(unique_local_paths)}\\nFailed/Skipped: {failed_count}\\n{'='*60}\")\n\n    if failed_count > 0:\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()"
}