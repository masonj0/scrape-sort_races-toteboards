{
    "filepath": "./checkmate_web/engine.py",
    "content": "# engine.py\n# Upgraded with Historian Schema for Race Results\n\nimport logging\nimport json\nimport subprocess\nimport concurrent.futures\nfrom abc import ABC, abstractmethod\nfrom typing import List, Union, Optional, Dict\nfrom datetime import date, datetime, timedelta\nfrom pydantic_settings import BaseSettings\nfrom pydantic import BaseModel, Field\nfrom bs4 import BeautifulSoup\n\n# --- Professional Settings Management ---\nclass Settings(BaseSettings):\n    QUALIFICATION_SCORE: float = Field(default=75.0)\n    FIELD_SIZE_OPTIMAL_MIN: int = Field(default=4)\n    FIELD_SIZE_OPTIMAL_MAX: int = Field(default=6)\n    FIELD_SIZE_ACCEPTABLE_MIN: int = Field(default=7)\n    FIELD_SIZE_ACCEPTABLE_MAX: int = Field(default=8)\n    FIELD_SIZE_OPTIMAL_POINTS: int = Field(default=30)\n    FIELD_SIZE_ACCEPTABLE_POINTS: int = Field(default=10)\n    FIELD_SIZE_PENALTY_POINTS: int = Field(default=-20)\n    FAV_ODDS_POINTS: int = Field(default=30)\n    MAX_FAV_ODDS: float = Field(default=3.5)\n    SECOND_FAV_ODDS_POINTS: int = Field(default=40)\n    MIN_2ND_FAV_ODDS: float = Field(default=4.0)\n\n# --- Models ---\nclass Runner(BaseModel):\n    name: str\n    odds: Optional[float] = None\n    program_number: Optional[int] = None\n\nclass Race(BaseModel):\n    race_id: str\n    track_name: str\n    race_number: Optional[int] = None\n    post_time: Optional[datetime] = None\n    runners: List[Runner]\n    source: Optional[str] = None\n\nclass HorseSchema(BaseModel):\n    name: str\n    number: Optional[int] = None\n    odds: Optional[float] = None\n\nclass RaceDataSchema(BaseModel):\n    id: str\n    track: str\n    raceNumber: Optional[int] = None\n    postTime: Optional[str] = None\n    horses: List[HorseSchema]\n\n# --- New Historian Schema ---\nclass RunnerResult(BaseModel):\n    name: str\n    finishing_position: int\n    program_number: Optional[int] = None\n    odds: Optional[float] = None\n\nclass RaceResult(BaseModel):\n    race_id: str\n    track_name: str\n    race_number: int\n    race_date: date\n    results: List[RunnerResult]\n    source: str\n\n# --- Base Fetcher & Adapters ---\nclass DefensiveFetcher:\n    def get(self, url: str, response_type: str = 'auto', headers: Optional[Dict[str, str]] = None) -> Union[dict, str, None]:\n        try:\n            command = [\"curl\", \"-s\", \"-L\", \"--tlsv1.2\", \"--http1.1\"]\n            if headers:\n                for key, value in headers.items():\n                    command.extend([\"-H\", f\"{key}: {value}\"])\n            command.append(url)\n\n            result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=15)\n            response_text = result.stdout\n\n            if response_type == 'text':\n                return response_text\n\n            try:\n                return json.loads(response_text)\n            except json.JSONDecodeError:\n                logging.warning(f\"Failed to decode JSON from {url}\")\n                return response_text # Return text as fallback\n        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:\n            logging.error(f\"CRITICAL: curl GET failed for {url}. Details: {e}\")\n            return None\n\nclass BaseAdapterV7(ABC):\n    def __init__(self, defensive_fetcher: DefensiveFetcher):\n        self.fetcher = defensive_fetcher\n    @abstractmethod\n    def fetch_races(self) -> List[Race]:\n        raise NotImplementedError\n\nclass BaseResultsAdapterV1(ABC):\n    def __init__(self, defensive_fetcher: DefensiveFetcher):\n        self.fetcher = defensive_fetcher\n    @abstractmethod\n    def fetch_results(self) -> List[RaceResult]:\n        raise NotImplementedError\n\ndef _convert_odds_to_float(odds_str: Optional[Union[str, float]]) -> Optional[float]:\n    if isinstance(odds_str, float): return odds_str\n    if not odds_str or not isinstance(odds_str, str): return None\n    odds_str = odds_str.strip().upper()\n    if odds_str in ['SP', 'SCRATCHED']: return None\n    if odds_str in ['EVS', 'EVENS']: return 2.0\n    if '/' in odds_str:\n        try:\n            num, den = map(int, odds_str.split('/'))\n            return (num / den) + 1.0 if den != 0 else None\n        except (ValueError, ZeroDivisionError): return None\n    try: return float(odds_str)\n    except (ValueError, TypeError): return None\n\n# # --- Race Data Adapters ---\nclass TVGAdapter(BaseAdapterV7):\n    SOURCE_ID = \"tvg\"\n    BASE_URL = \"https://mobile-api.tvg.com/api/mobile/races/today\"\n    def fetch_races(self) -> List[Race]:\n        response_data = self.fetcher.get(self.BASE_URL, response_type='json')\n        if not response_data or 'races' not in response_data: return []\n        all_races = []\n        for race_info in response_data.get('races', []):\n            try:\n                runners = [Runner(name=r.get('horseName', 'N/A'), program_number=r.get('programNumber'), odds=self._parse_odds(r.get('odds'))) for r in race_info.get('runners', []) if not r.get('scratched') and self._parse_odds(r.get('odds')) is not None]\n                if not runners: continue\n                all_races.append(Race(race_id=f\"tvg_{race_info.get('raceId')}\", track_name=race_info.get('trackName', 'N/A'), race_number=race_info.get('raceNumber'), post_time=datetime.fromisoformat(race_info.get('postTime').replace('Z', '+00:00')) if race_info.get('postTime') else None, runners=runners, source=self.SOURCE_ID))\n            except Exception: continue\n        return all_races\n\n    def _parse_odds(self, odds_data: Optional[Dict]) -> Optional[float]:\n        if not odds_data or odds_data.get('morningLine') is None: return None\n        try:\n            num, den = map(int, odds_data['morningLine'].split('/'))\n            return (num / den) + 1.0\n        except (ValueError, TypeError, ZeroDivisionError): return None\n\n\nclass BetfairExchangeAdapter(BaseAdapterV7):\n    SOURCE_ID = \"betfair_exchange\"\n\n    def fetch_races(self) -> List[Race]:\n        races = []\n        endpoint = \"https://ero.betfair.com/www/sports/exchange/readonly/v1/bymarket?alt=json&filter=canonical&maxResults=25&rollupLimit=2&types=EVENT,MARKET_DESCRIPTION,RUNNER_DESCRIPTION,RUNNER_EXCHANGE_PRICES_BEST,MARKET_STATE&marketProjection=EVENT,MARKET_START_TIME,RUNNER_DESCRIPTION&eventTypeIds=7\"\n        try:\n            data = self.fetcher.get(endpoint, response_type='json', headers={'Accept': 'application/json'})\n            if data:\n                parsed_races = self._parse_betfair_races(data)\n                if parsed_races:\n                    races.extend(parsed_races)\n        except Exception as e:\n            logging.warning(f\"Betfair endpoint failed: {e}\")\n        for race in races: race.source = self.SOURCE_ID\n        return races\n\n    def _parse_betfair_races(self, data: dict) -> List[Race]:\n        races = []\n        try:\n            event_nodes = data.get('eventTypes', [{}]).get('eventNodes', [])\n            for event_node in event_nodes:\n                event = event_node.get('event', {})\n                for market_node in event_node.get('marketNodes', []):\n                    market = market_node.get('market', {})\n                    if market.get('marketType', '') != 'WIN': continue\n                    runners = []\n                    for runner in market_node.get('runners', []):\n                        if runner.get('state', {}).get('status') != 'ACTIVE': continue\n                        odds = None\n                        if 'exchange' in runner:\n                            available_to_back = runner['exchange'].get('availableToBack', [])\n                            if available_to_back: odds = available_to_back[0].get('price')\n                        runners.append(Runner(name=runner.get('description', {}).get('runnerName', 'Unknown'), program_number=runner.get('sortPriority'), odds=odds))\n                    if len(runners) >= 3:\n                        start_time = None\n                        time_field = market.get('marketStartTime')\n                        if time_field:\n                            try: start_time = datetime.fromisoformat(time_field.replace('Z', '+00:00'))\n                            except: pass\n                        race = Race(race_id=f\"betfair_{market.get('marketId', 'unknown')}\", track_name=event.get('venue', 'Betfair Exchange'), post_time=start_time, race_number=int(event.get('eventName', '0').split('R')[-1]) if 'R' in event.get('eventName', '') else None, runners=runners)\n                        races.append(race)\n        except Exception as e: logging.error(f\"Error parsing Betfair data structure: {e}\")\n        return races\n\nclass PointsBetAdapter(BaseAdapterV7):\n    SOURCE_ID = \"pointsbet\"\n    BASE_URL = \"https://api.nj.pointsbet.com/api/v2/sports/horse-racing/events/upcoming?page=1\"\n\n    def fetch_races(self) -> List[Race]:\n        response_data = self.fetcher.get(self.BASE_URL, response_type='json')\n        if not response_data or not response_data.get('events'):\n            return []\n\n        races = []\n        for event in response_data['events']:\n            try:\n                if not event.get('winPlaceOddsAvailable'):\n                    continue\n\n                runners = []\n                for outcome in event.get('fixedPrice', {}).get('outcomes', []):\n                    if outcome.get('outcomeType') != 'Win':\n                        continue\n                    runners.append(Runner(\n                        name=outcome.get('name', 'Unknown'),\n                        odds=_convert_odds_to_float(outcome.get('price'))\n                    ))\n\n                if len(runners) < 3:\n                    continue\n\n                start_time = datetime.fromisoformat(event['startsAt'].replace('Z', '+00:00')) if event.get('startsAt') else None\n\n                race = Race(\n                    race_id=f\"pointsbet_{event.get('key', 'unknown')}\",\n                    track_name=event.get('competitionName', 'Unknown Track'),\n                    race_number=event.get('eventNumber'),\n                    post_time=start_time,\n                    runners=runners,\n                    source=self.SOURCE_ID\n                )\n                races.append(race)\n            except Exception as e:\n                logging.warning(f\"Skipping malformed PointsBet event: {e}\")\n                continue\n        return races\n\n# --- NEW: Race Results Adapters ---\nclass TVGResultsAdapter(BaseResultsAdapterV1):\n    SOURCE_ID = \"tvg_results\"\n    BASE_URL = \"https://mobile-api.tvg.com/api/mobile/results/today\"\n\n    def fetch_results(self) -> List[RaceResult]:\n        response_data = self.fetcher.get(self.BASE_URL, response_type='json')\n        if not response_data or 'results' not in response_data:\n            return []\n\n        all_results = []\n        for result_info in response_data['results']:\n            try:\n                runner_results = []\n                for runner_data in result_info.get('runners', []):\n                    if not runner_data.get('finishPosition'): continue\n                    runner_results.append(RunnerResult(\n                        name=runner_data.get('horseName', 'Unknown'),\n                        finishing_position=runner_data['finishPosition'],\n                        program_number=runner_data.get('programNumber'),\n                        odds=_convert_odds_to_float(runner_data.get('winOdds', {}).get('decimal'))\n                    ))\n\n                if not runner_results: continue\n\n                all_results.append(RaceResult(\n                    race_id=f\"tvg_{result_info.get('raceId')}\",\n                    track_name=result_info.get('trackName', 'Unknown Track'),\n                    race_number=result_info.get('raceNumber'),\n                    race_date=date.today(),\n                    results=runner_results,\n                    source=self.SOURCE_ID\n                ))\n            except Exception as e:\n                logging.warning(f\"Skipping malformed TVG result: {e}\")\n                continue\n        return all_results\n\n# --- Trifecta Analyzer ---\nclass TrifectaAnalyzer:\n    def analyze_race(self, race: RaceDataSchema, settings: Settings) -> dict:\n        score = 0\n        trifecta_factors = {}\n        horses_with_odds = sorted([h for h in race.horses if h.odds], key=lambda h: h.odds)\n        num_runners = len(horses_with_odds)\n\n        if settings.FIELD_SIZE_OPTIMAL_MIN <= num_runners <= settings.FIELD_SIZE_OPTIMAL_MAX:\n            points, ok, reason = settings.FIELD_SIZE_OPTIMAL_POINTS, True, f\"Optimal field size ({num_runners})\"\n        elif settings.FIELD_SIZE_ACCEPTABLE_MIN <= num_runners <= settings.FIELD_SIZE_ACCEPTABLE_MAX:\n            points, ok, reason = settings.FIELD_SIZE_ACCEPTABLE_POINTS, True, f\"Acceptable field size ({num_runners})\"\n        else:\n            points, ok, reason = settings.FIELD_SIZE_PENALTY_POINTS, False, f\"Field size not ideal ({num_runners})\"\n        score += points\n        trifecta_factors[\"fieldSize\"] = {\"points\": points, \"ok\": ok, \"reason\": reason}\n\n        if num_runners >= 2:\n            fav, sec_fav = horses_with_odds[0], horses_with_odds[1]\n            if fav.odds <= settings.MAX_FAV_ODDS:\n                points, ok, reason = settings.FAV_ODDS_POINTS, True, f\"Favorite odds OK ({fav.odds:.2f})\"\n            else:\n                points, ok, reason = 0, False, f\"Favorite odds too high ({fav.odds:.2f})\"\n            score += points\n            trifecta_factors[\"favoriteOdds\"] = {\"points\": points, \"ok\": ok, \"reason\": reason}\n\n            if sec_fav.odds >= settings.MIN_2ND_FAV_ODDS:\n                points, ok, reason = settings.SECOND_FAV_ODDS_POINTS, True, f\"2nd Favorite OK ({sec_fav.odds:.2f})\"\n            else:\n                points, ok, reason = 0, False, f\"2nd Favorite odds too low ({sec_fav.odds:.2f})\"\n            score += points\n            trifecta_factors[\"secondFavoriteOdds\"] = {\"points\": points, \"ok\": ok, \"reason\": reason}\n\n        return {\"qualified\": score >= settings.QUALIFICATION_SCORE, \"checkmateScore\": score, \"trifectaFactors\": trifecta_factors}\n\n# --- Orchestrators ---\nPRODUCTION_ADAPTERS = [TVGAdapter, BetfairExchangeAdapter, PointsBetAdapter]\nRESULTS_ADAPTERS = [TVGResultsAdapter]\n\nclass DataSourceOrchestrator:\n    def __init__(self):\n        self.fetcher = DefensiveFetcher()\n        self.adapters: List[BaseAdapterV7] = [Adapter(self.fetcher) for Adapter in PRODUCTION_ADAPTERS]\n\n    def _fetch_from_adapter(self, adapter: BaseAdapterV7):\n        adapter_id = adapter.__class__.__name__\n        try:\n            races = adapter.fetch_races()\n            notes = f\"Successfully parsed {len(races)} races.\" if races else \"No upcoming races found.\"\n            status = {\"adapter_id\": adapter_id, \"status\": \"OK\", \"races_found\": len(races), \"notes\": notes, \"error_message\": None}\n            return races, status\n        except Exception as e:\n            error_message = str(e)\n            status = {\"adapter_id\": adapter_id, \"status\": \"ERROR\", \"error_message\": error_message, \"races_found\": 0}\n            return [], status\n\n    def get_races(self) -> tuple[list[Race], list[dict]]:\n        all_races, statuses = [], []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.adapters)) as executor:\n            future_to_adapter = {executor.submit(self._fetch_from_adapter, adapter): adapter for adapter in self.adapters}\n            for future in concurrent.futures.as_completed(future_to_adapter):\n                try:\n                    races, status = future.result()\n                    if races:\n                        all_races.extend(races)\n                    statuses.append(status)\n                except Exception as e:\n                    adapter = future_to_adapter[future]\n                    adapter_id = adapter.__class__.__name__\n                    statuses.append({\"adapter_id\": adapter_id, \"status\": \"ERROR\", \"error_message\": str(e), \"races_found\": 0})\n        return all_races, statuses\nclass ResultsOrchestrator:\n    def __init__(self):\n        self.fetcher = DefensiveFetcher()\n        self.adapters: List[BaseResultsAdapterV1] = [Adapter(self.fetcher) for Adapter in RESULTS_ADAPTERS]\n\n    def _fetch_from_adapter(self, adapter: BaseResultsAdapterV1):\n        adapter_id = adapter.__class__.__name__\n        try:\n            results = adapter.fetch_results()\n            notes = f\"Successfully parsed {len(results)} results.\" if results else \"No results found.\"\n            status = {\"adapter_id\": adapter_id, \"status\": \"OK\", \"results_found\": len(results), \"notes\": notes}\n            return results, status\n        except Exception as e:\n            status = {\"adapter_id\": adapter_id, \"status\": \"ERROR\", \"error_message\": str(e), \"results_found\": 0}\n            return [], status\n\n    def get_results(self) -> tuple[list[RaceResult], list[dict]]:\n        all_results, statuses = [], []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.adapters)) as executor:\n            future_to_adapter = {executor.submit(self._fetch_from_adapter, adapter): adapter for adapter in self.adapters}\n            for future in concurrent.futures.as_completed(future_to_adapter):\n                try:\n                    results, status = future.result()\n                    if results: all_results.extend(results)\n                    statuses.append(status)\n                except Exception as e:\n                    adapter_id = future_to_adapter[future].__class__.__name__\n                    statuses.append({\"adapter_id\": adapter_id, \"status\": \"ERROR\", \"error_message\": str(e), \"results_found\": 0})\n        return all_results, statuses\n"
}